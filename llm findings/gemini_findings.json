[
  {
    "id": "CRIT-01",
    "title": "Tunnel Uses init_net -- Namespace Escape",
    "category": "security",
    "severity": "S0",
    "confidence": "high",
    "impact": "Complete network namespace isolation bypass. Container escape for network traffic. Attacker in a restricted namespace can reach any host reachable from the root namespace.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "err = sock_create_kern(&init_net, family, SOCK_STREAM, IPPROTO_TCP,\n                       &sock);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "The tunnel subsystem creates TCP sockets in `init_net` (the root network namespace) regardless of which namespace the calling QUIC connection belongs to. This is a namespace escape vulnerability. A user in a container or non-root network namespace who can open a QUIC tunnel will have TCP connections created in the host's root namespace, bypassing all network namespace isolation including firewall rules, routing policies, and network access controls.",
    "fix_suggestion": "Use the network namespace from the QUIC connection's socket (`sock_net(conn->sk)`) instead of `&init_net`. Pass the correct `struct net *` through the client and tunnel structures.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_SECURITY_NETLINK_LB.md"
  },
  {
    "id": "CRIT-02",
    "title": "SSRF via IPv4-Mapped IPv6 Addresses Bypasses Address Filtering",
    "category": "security",
    "severity": "S0",
    "confidence": "high",
    "impact": "Full SSRF bypass. Attacker can connect to localhost services, cloud metadata endpoints (169.254.169.254), and internal networks via the tunnel.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (ipv6_addr_loopback(&addr6) ||\n    ipv6_addr_is_multicast(&addr6) ||\n    ipv6_addr_type(&addr6) & IPV6_ADDR_LINKLOCAL) {\n    return -EACCES;\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "The IPv6 address filter does not check for IPv4-mapped IPv6 addresses (`::ffff:127.0.0.1`), IPv4-compatible IPv6 addresses (`::127.0.0.1`), 6to4 addresses that embed private IPv4 ranges, or Teredo addresses. An attacker can use `::ffff:127.0.0.1` to connect to localhost, or `::ffff:10.0.0.1` to reach RFC 1918 private networks, completely bypassing the SSRF protections.",
    "fix_suggestion": "Add checks for `ipv6_addr_v4mapped()`, `ipv6_addr_is_isatap()`, private RFC 1918 ranges within mapped addresses, and the unspecified address (`::` / `in6addr_any`). Also check for `::ffff:169.254.169.254` (cloud metadata).\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_SECURITY_NETLINK_LB.md"
  },
  {
    "id": "CRIT-03",
    "title": "Missing RFC 1918 / Private Network Filtering in IPv4 SSRF Checks",
    "category": "security",
    "severity": "S0",
    "confidence": "high",
    "impact": "SSRF to internal networks, cloud metadata endpoints, and management interfaces.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (ipv4_is_loopback(addr4) ||\n    ipv4_is_multicast(addr4) ||\n    ipv4_is_lbcast(addr4) ||\n    ipv4_is_zeronet(addr4)) {\n    return -EACCES;\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "The IPv4 SSRF filter does not block RFC 1918 private addresses (10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16), link-local (169.254.0.0/16 including the cloud metadata endpoint 169.254.169.254), or other reserved ranges. A remote attacker controlling QUIC stream data can instruct the VPS to connect to internal infrastructure services.",
    "fix_suggestion": "Add checks for `ipv4_is_private_10()`, `ipv4_is_private_172()`, `ipv4_is_private_192()`, `ipv4_is_linklocal_169()`, and other reserved ranges per RFC 5737 (192.0.2.0/24, 198.51.100.0/24, 203.0.113.0/24).\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_SECURITY_NETLINK_LB.md"
  },
  {
    "id": "CRIT-04",
    "title": "Load Balancer Plaintext Mode Exposes Server ID",
    "category": "security",
    "severity": "S0",
    "confidence": "high",
    "impact": "Server ID disclosure to any on-path observer. Enables targeted attacks against specific backend servers, load balancer topology mapping, and connection tracking/correlation.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "case TQUIC_LB_MODE_PLAINTEXT:\n    memcpy(cid->payload, plaintext, payload_len);\n    break;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "In plaintext mode (`encryption_key == NULL`), the server ID is embedded directly in the connection ID without any obfuscation. Any network observer can extract the server ID by reading bytes from the CID. The draft-ietf-quic-load-balancers specification explicitly warns that plaintext mode is only for testing and MUST NOT be used in production. There is no runtime warning or compile-time guard against this.",
    "fix_suggestion": "Log a `pr_warn_once()` when plaintext mode is selected. Consider requiring `CAP_NET_ADMIN` to create plaintext configs, or removing plaintext mode entirely. At minimum, add a prominent `IS THIS REALLY WHAT YOU WANT` style warning.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_SECURITY_NETLINK_LB.md"
  },
  {
    "id": "HIGH-01",
    "title": "Function Pointer Stored in skb->cb Without Validation",
    "category": "security",
    "severity": "S1",
    "confidence": "high",
    "impact": "If `skb->cb` is corrupted (by another network layer or a bug), calling the stored function pointer leads to arbitrary code execution in kernel context.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "/* Store send function in skb->cb */\n*(unsigned long *)skb->cb = (unsigned long)send_fn;\n\n/* Later, retrieve and call */\nvoid (*send_fn)(struct sk_buff *) =\n    (void (*)(struct sk_buff *))(*(unsigned long *)skb->cb);\nsend_fn(skb);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "Function pointers are stored in `skb->cb` (the control buffer) and later retrieved and called without validation. The `skb->cb` area is 48 bytes and is used by multiple layers; if any intermediate processing corrupts or overwrites `cb[0]`, an attacker could achieve code execution. The check `if (skb->cb[0])` at line 71 treats cb[0] as a boolean but the actual pointer starts at `*(unsigned long *)skb->cb` -- a nonzero cb[0] byte does not guarantee a valid function pointer. Furthermore, the decoy traffic code at line 533 writes `'D', 'E', 'C', 'O', 'Y'` into cb, which would be interpreted as a garbage function pointer if the SKB were accidentally passed through the send path.",
    "fix_suggestion": "Do not store raw function pointers in `skb->cb`. Instead, use a dedicated structure with a magic number for validation, or use a callback registration mechanism that does not rely on `skb->cb`.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_SECURITY_NETLINK_LB.md"
  },
  {
    "id": "HIGH-02",
    "title": "No CAP_NET_ADMIN Check for Tunnel Creation",
    "category": "security",
    "severity": "S1",
    "confidence": "high",
    "impact": "Unprivileged users can open arbitrary TCP connections via the tunnel mechanism, potentially circumventing local firewall rules and creating unauthorized network flows.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "struct tquic_tunnel *tquic_tunnel_create(struct tquic_client *client,\n                                         struct tquic_stream *stream,\n                                         const u8 *header_data,\n                                         size_t header_len)"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "`tquic_tunnel_create()` and `tquic_tunnel_create_tproxy()` do not perform any capability checks. Any process that can open a QUIC stream can instruct the kernel to create outbound TCP connections to arbitrary destinations (subject to the incomplete SSRF filter). Tunnel creation should require `CAP_NET_ADMIN` or at minimum `CAP_NET_RAW`.",
    "fix_suggestion": "Add `capable(CAP_NET_ADMIN)` check at the entry point of tunnel creation, or ensure the calling path enforces this.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_SECURITY_NETLINK_LB.md"
  },
  {
    "id": "HIGH-03",
    "title": "Load Balancer Encryption Key Not Zeroized on Destroy",
    "category": "security",
    "severity": "S1",
    "confidence": "high",
    "impact": "Encryption key material remains in freed memory, potentially recoverable via heap spraying or other memory disclosure techniques.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "void tquic_lb_config_destroy(struct tquic_lb_config *cfg)\n{\n    if (!cfg)\n        return;\n\n    if (cfg->aes_tfm)\n        crypto_free_sync_skcipher(cfg->aes_tfm);\n\n    kmem_cache_free(lb_config_cache, cfg);\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "The AES-128 encryption key stored in `cfg->encryption_key[16]` is not zeroized before the config structure is freed. The SLAB allocator may reuse this memory for other allocations, potentially exposing the key material through information disclosure vulnerabilities in other subsystems. The `server_id` is also not zeroized.",
    "fix_suggestion": "Add `memzero_explicit(cfg->encryption_key, sizeof(cfg->encryption_key))` and `memzero_explicit(cfg->server_id, sizeof(cfg->server_id))` before `kmem_cache_free()`.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_SECURITY_NETLINK_LB.md"
  },
  {
    "id": "HIGH-04",
    "title": "Constant-Time CID Validation Has Branching on Lengths",
    "category": "security",
    "severity": "S1",
    "confidence": "high",
    "impact": "Potential out-of-bounds read if `cid_len != expected_len`. The timing variation from branches may leak length information.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "bool tquic_ct_validate_cid(const u8 *cid, size_t cid_len,\n                           const u8 *expected, size_t expected_len)\n{\n    ...\n    /* Compare lengths without branching */\n    len_match = !(cid_len ^ expected_len);\n\n    /* Use the larger length to ensure constant-time */\n    max_len = cid_len > expected_len ? cid_len : expected_len;\n    if (max_len > sizeof(dummy_buf))\n        max_len = sizeof(dummy_buf);\n    ...\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "Despite the comment \"without branching,\" the ternary `cid_len > expected_len ? cid_len : expected_len` is a branch on secret data. The comparison `max_len > sizeof(dummy_buf)` is also a branch. More critically, `tquic_ct_memcmp(cid, expected, max_len)` reads `max_len` bytes from both `cid` and `expected`, but if `cid_len < max_len`, this is an out-of-bounds read. The function assumes both buffers are at least `max_len` bytes, which is not guaranteed.",
    "fix_suggestion": "Read exactly `min(cid_len, expected_len)` bytes with bounds checking, use `ct_select` for branchless max, and ensure both buffers are adequately sized or copy to fixed-size local buffers first.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_SECURITY_NETLINK_LB.md"
  },
  {
    "id": "HIGH-05",
    "title": "Unbounded Connection Creation via Netlink",
    "category": "security",
    "severity": "S1",
    "confidence": "high",
    "impact": "Denial of service via kernel memory exhaustion by creating millions of connection info objects.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "conn = tquic_conn_lookup(net, conn_id);\nif (!conn) {\n    conn = tquic_conn_info_create(net, conn_id);\n    if (!conn)\n        return -ENOMEM;\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "In `tquic_nl_cmd_path_add()`, a new connection is automatically created if the specified `conn_id` does not exist. There is no limit on the number of connections that can be created per namespace. While paths per connection are limited to 256, an attacker with `CAP_NET_ADMIN` can create unlimited connection objects by varying `conn_id`, leading to kernel memory exhaustion.",
    "fix_suggestion": "Add a per-namespace limit on the number of connections (e.g., via an `atomic_t conn_count` in `struct tquic_net`).\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_SECURITY_NETLINK_LB.md"
  },
  {
    "id": "HIGH-06",
    "title": "Timing Normalization Can Block in Packet Processing Path",
    "category": "security",
    "severity": "S1",
    "confidence": "high",
    "impact": "Kernel panic if called from softirq context. Denial of service via intentional latency injection (attacker sends many packets, each causing 2ms delay on the receiver).",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (delay_us <= 10) {\n    udelay(delay_us);\n} else if (delay_us <= 1000) {\n    usleep_range(delay_us, delay_us + 10);\n} else {\n    msleep(delay_us / 1000);\n    ...\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "`tquic_timing_normalize_process()` is called during incoming packet processing (`tquic_exfil_process_incoming`). The function uses `usleep_range()` and `msleep()` which sleep and can only be called from process context. If called from softirq/BH context (typical for incoming packet processing), this will cause a BUG or schedule-while-atomic panic. Even if called from process context, blocking for up to 2ms per packet at PARANOID level is a denial-of-service amplifier.",
    "fix_suggestion": "Never sleep in packet processing paths. Use `udelay()` only for very short delays, or defer processing to a workqueue. Add a `might_sleep()` annotation and ensure callers are in sleepable context.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_SECURITY_NETLINK_LB.md"
  },
  {
    "id": "MED-01",
    "title": "Decoy Packet Size Calculation Can Underflow",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "Potential large memory allocation attempt (though allocation will fail). If MTU is exactly 64, `rand_val % 1` = 0, so `decoy_size = 64`, which is correct. Values below 64 are the problem.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "decoy_size = 64 + (rand_val % (shaper->mtu - 64 + 1));",
        "if (mtu < 64) mtu = 64;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "If `shaper->mtu` is set to a value less than 64 (e.g., via `tquic_traffic_shaper_set_mtu()` with no lower bound check), `shaper->mtu - 64 + 1` wraps around to a very large number due to unsigned arithmetic (both are `u32`). This would produce a decoy_size of up to ~4GB, and `alloc_skb()` with such a size would fail, but the modulo of a random u32 by a near-u32-max value could still produce very large sizes.",
    "fix_suggestion": "Add minimum MTU validation in `tquic_traffic_shaper_set_mtu()`:\n```c\nif (mtu < 64) mtu = 64;\n```\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_SECURITY_NETLINK_LB.md"
  },
  {
    "id": "MED-02",
    "title": "Load Balancer Feistel Network Half-Length Overlap",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "For `len > 30` (which is rejected by the `len > 32` check), the round number would overwrite data, causing decryption to fail. With current bounds (`len <= 32`, `half_len <= 16`), the last byte of `right` at index 15 can be overwritten. For `len = 31`, `half_len = 16`, and `right` has 15 bytes with `right[15]` being zero-pad, so `tmp[15] = round` overwrites zero-pad -- but for `len = 32`, both halves are 16 bytes, and `tmp[15] = round` overwrites `right[15]`, a real data byte.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "half_len = (len + 1) / 2;\nmemcpy(left, plaintext, half_len);\nmemcpy(right, plaintext + half_len, len - half_len);\n...\ntmp[15] = round;  /* Include round number */"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "When `len` is odd, `half_len > len - half_len`, so the left and right halves overlap by one byte in the middle of the plaintext. This is handled correctly for the Feistel network itself, but `tmp[15] = round` could overwrite meaningful data if `half_len > 15`. Given `TQUIC_LB_CID_PAYLOAD_MAX = 19`, `half_len` can be up to 10 (for len=19), so `tmp[15]` is always in the zero-padded area. However, if the function is called with `len > 30`, `half_len = 16` and `memcpy(tmp, right, half_len)` fills all 16 bytes, then `tmp[15] = round` overwrites the last byte of actual data.",
    "fix_suggestion": "Use a separate byte position for the round number that does not conflict with data, or XOR the round number rather than overwriting.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_SECURITY_NETLINK_LB.md"
  },
  {
    "id": "MED-03",
    "title": "Sysctl Variables Lack Range Validation",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "Invalid configuration states. Not exploitable for code execution but can disable security protections or cause unexpected behavior.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "static int exfil_protection_level = TQUIC_EXFIL_LEVEL_MEDIUM;\nstatic int exfil_timing_delay_us = TQUIC_EXFIL_DELAY_MEDIUM_MAX_US;\nstatic int exfil_padding_strategy = TQUIC_PAD_RANDOM;\nstatic int exfil_pad_probability = TQUIC_PAD_PROBABILITY_DEFAULT;\nstatic int exfil_spin_mode = TQUIC_SPIN_RANDOM_PROB;\nstatic int exfil_jitter_min_us = TQUIC_JITTER_DEFAULT_MIN_US;\nstatic int exfil_jitter_max_us = TQUIC_JITTER_DEFAULT_MAX_US;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "These module parameters are exposed via sysctl but no sysctl table with `.extra1`/`.extra2` range validation is registered anywhere in the code. The sysctl accessor functions cast these raw `int` values to enum types without range checking. A root user could set `exfil_protection_level = 99`, and the switch statements in the set_level functions would fall through without setting any delay values, potentially leaving the normalizer in an inconsistent state.",
    "fix_suggestion": "Register a proper sysctl table with `proc_dointvec_minmax` handlers and range limits, or add range validation in the accessor functions.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_SECURITY_NETLINK_LB.md"
  },
  {
    "id": "MED-04",
    "title": "Netlink Path Dump Reads conn_id on Every Iteration",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "Low -- no actual reference leak, but redundant work on each iteration.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (!attrs[TQUIC_NL_ATTR_CONN_ID]) {\n    NL_SET_ERR_MSG(cb->extack, \"Connection ID required\");\n    return -EINVAL;\n}\n\nctx->conn_id = nla_get_u64(attrs[TQUIC_NL_ATTR_CONN_ID]);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "In `tquic_nl_cmd_path_dump()`, the connection ID is re-read from attributes on every dump iteration (netlink dump callbacks are called repeatedly). The `ctx->conn_id` is overwritten each time. This is a correctness issue rather than a security issue, but if the attributes could theoretically change between calls (they cannot in current genetlink), it could cause confusion. More importantly, the `tquic_conn_lookup()` takes a reference on each call but only releases it once at the end, so if the dump callback is called N times for a large path list, N-1 reference increments are leaked.\n\nActually, examining more carefully: each dump call does `tquic_conn_lookup` (refcount_inc) and `tquic_nl_conn_put` (refcount_dec) in a single call, so the refcount is balanced per call. This is correct.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_SECURITY_NETLINK_LB.md"
  },
  {
    "id": "MED-05",
    "title": "Load Balancer Nonce Counter Wraps Without Re-keying",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "After counter wrap or module reload, CID collisions could allow connection correlation by a passive observer.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "spin_lock(&cfg->lock);\ncounter = cfg->nonce_counter++;\nspin_unlock(&cfg->lock);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "The nonce counter is a `u64` that increments monotonically. While a 64-bit counter will not wrap in practice for a single config lifetime, the counter is initialized with a random value (`get_random_bytes`), so depending on the starting value, it could wrap sooner than expected. More concerning: in AES-ECB single-pass mode, if the same nonce is reused (due to wrap or counter reset after module reload), the same server_id + nonce pair produces the same CID, breaking unlinkability.",
    "fix_suggestion": "Detect counter wrap and refuse to generate nonces, or use a larger state that combines counter with additional randomness.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_SECURITY_NETLINK_LB.md"
  },
  {
    "id": "MED-06",
    "title": "Tunnel Port Allocation Unsigned Underflow",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "None (correctly handled by bounds check), but defense-in-depth could be improved.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "bit = ntohs(port) - ntohs(client->port_range_start);\nif (bit >= TQUIC_PORTS_PER_CLIENT)\n    return;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "The variable `bit` is `unsigned long`. If `ntohs(port) < ntohs(client->port_range_start)`, the subtraction wraps to a very large positive value. The `>= TQUIC_PORTS_PER_CLIENT` check catches this case correctly (the wrapped value will be much larger than 1000), so the function returns safely. However, this relies on unsigned wrap behavior and would be clearer with an explicit check.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_SECURITY_NETLINK_LB.md"
  },
  {
    "id": "MED-07",
    "title": "Exfil Context set_level Destroys and Reinitializes Without Lock",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "Use-after-free, double-free, or crash if the protection level is changed while packets are being processed.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "void tquic_exfil_ctx_set_level(struct tquic_exfil_ctx *ctx,\n                               enum tquic_exfil_protection_level level)\n{\n    ...\n    /* Reinitialize shaper and spin with new level */\n    tquic_traffic_shaper_destroy(&ctx->shaper);\n    tquic_traffic_shaper_init(&ctx->shaper, level);\n\n    tquic_spin_randomizer_destroy(&ctx->spin_rand);\n    tquic_spin_randomizer_init(&ctx->spin_rand, level);\n\n    tquic_packet_jitter_destroy(&ctx->jitter);\n    tquic_packet_jitter_init(&ctx->jitter, level);\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "The context has a `spinlock_t lock` field, but `tquic_exfil_ctx_set_level()` does not acquire it. Destroying and reinitializing the shaper, spin randomizer, and jitter while other threads may be using them (via `tquic_exfil_process_outgoing`) creates a use-after-free / use-during-reinit race condition. The shaper's batch queue, hrtimer, and decoy work are destroyed and reinitialized without synchronization.",
    "fix_suggestion": "Acquire `ctx->lock` around the destroy/init sequence, or use RCU to swap in a new configuration atomically.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_SECURITY_NETLINK_LB.md"
  },
  {
    "id": "LOW-01",
    "title": "Duplicate MODULE_DESCRIPTION/MODULE_LICENSE in quic_exfil.c",
    "category": "security",
    "severity": "S3",
    "confidence": "high",
    "impact": "None (build warning only).\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "MODULE_DESCRIPTION(\"TQUIC QUIC-Exfil Mitigation (draft-iab-quic-exfil)\");\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Linux Foundation\");"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "The MODULE_DESCRIPTION, MODULE_LICENSE, and MODULE_AUTHOR macros are declared twice in the same file. This is a code quality issue that may cause build warnings.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_SECURITY_NETLINK_LB.md"
  },
  {
    "id": "LOW-02",
    "title": "Netlink Events Do Not Include Timestamp",
    "category": "security",
    "severity": "S3",
    "confidence": "high",
    "impact": "Reduced observability, no security impact.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "Netlink event notifications for path up/down/change/migration do not include a kernel timestamp. Userspace tools cannot determine the exact time of events, making debugging and correlation with other log sources difficult.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_SECURITY_NETLINK_LB.md"
  },
  {
    "id": "LOW-03",
    "title": "Volatile Qualifiers in Constant-Time Functions May Be Insufficient",
    "category": "security",
    "severity": "S3",
    "confidence": "high",
    "impact": "Timing side-channel may still be exploitable despite the `volatile` annotation, particularly on architectures with speculative execution.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "const volatile unsigned char *aa = a;\nconst volatile unsigned char *bb = b;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "The `volatile` qualifier prevents the compiler from optimizing away reads, but does not prevent speculative execution or microarchitectural side channels. Modern compilers and CPUs may still optimize the loop or execute it speculatively in ways that leak timing information. The kernel provides `crypto_memneq()` for this purpose, which uses architecture-specific barriers.",
    "fix_suggestion": "Use `crypto_memneq()` from `<crypto/algapi.h>` instead of a custom implementation.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_SECURITY_NETLINK_LB.md"
  },
  {
    "id": "LOW-04",
    "title": "Load Balancer Stack Buffers for Feistel Not Zeroized on Error",
    "category": "security",
    "severity": "S3",
    "confidence": "high",
    "impact": "Minor information disclosure risk in specialized attack scenarios.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "The `left[16]`, `right[16]`, `tmp[16]`, and `round_out[16]` buffers in `tquic_lb_encrypt_four_pass()` and `tquic_lb_decrypt_four_pass()` are not zeroized on error return paths. While stack memory is less persistent than heap, in a kernel with KASAN or stack reuse, residual plaintext/key-derived data could be observable.",
    "fix_suggestion": "Add `memzero_explicit()` calls in error paths and at function exit.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_SECURITY_NETLINK_LB.md"
  },
  {
    "id": "LOW-05",
    "title": "Netlink Family Exported as EXPORT_SYMBOL_GPL",
    "category": "security",
    "severity": "S3",
    "confidence": "high",
    "impact": "Other kernel modules could send spoofed TQUIC events to userspace listeners.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "EXPORT_SYMBOL_GPL(tquic_genl_family);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "Exporting the entire `genl_family` structure allows other modules to directly manipulate the netlink family or send events on its behalf. This is unusual; typically only specific helper functions are exported.",
    "fix_suggestion": "Export only the specific notification helper functions, not the family structure itself.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_SECURITY_NETLINK_LB.md"
  },
  {
    "id": "CRIT-01",
    "title": "tquic_send_connection_close() -- SKB leak and unencrypted packet on header failure",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Information disclosure of unencrypted QUIC frame content. An\nattacker who causes header building to fail (e.g., via DCID corruption) can\nreceive raw unencrypted frame bytes on the wire.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (header_len > 0)\n    skb_put_data(skb, header, header_len);\n}\n\nskb_put_data(skb, buf, ctx.offset);\nkfree(buf);\n\nreturn tquic_output_packet(conn, path, skb);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Add `if (header_len < 0) { kfree_skb(skb); kfree(buf); return header_len; }` before the `skb_put_data` calls.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_ERROR_PATH_AUDIT.md"
  },
  {
    "id": "CRIT-02",
    "title": "tquic_conn_server_accept() -- err_free leaks registered CIDs, work items, timers, crypto state",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Memory leak of CID entries, crypto state, potential use-after-free\nif work items fire after `cs` is freed. An attacker sending crafted Initial\npackets that trigger partial failure can leak kernel memory on every attempt.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "conn->state_machine = cs;  // set BEFORE error paths below\n\n// ... tquic_conn_add_remote_cid, tquic_conn_add_local_cid, crypto_init ...\n\nerr_free:\n    kfree(cs);\n    conn->state_machine = NULL;\n    return -EINVAL;",
        "err_free_crypto:\n    tquic_crypto_free(conn->crypto_state);\n    conn->crypto_state = NULL;\nerr_free_cids:\n    /* remove added CIDs */\nerr_free_cs:\n    skb_queue_purge(&cs->zero_rtt_buffer);\n    kfree(cs);\n    conn->state_machine = NULL;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Create incremental error labels:\n```\nerr_free_crypto:\n    tquic_crypto_free(conn->crypto_state);\n    conn->crypto_state = NULL;\nerr_free_cids:\n    /* remove added CIDs */\nerr_free_cs:\n    skb_queue_purge(&cs->zero_rtt_buffer);\n    kfree(cs);\n    conn->state_machine = NULL;\n```\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_ERROR_PATH_AUDIT.md"
  },
  {
    "id": "CRIT-03",
    "title": "tquic_conn_server_accept() -- overrides actual error code with -EINVAL",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Misreported error codes; callers may retry operations that should\nnot be retried (ENOMEM vs EINVAL).",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "err_free:\n    kfree(cs);\n    conn->state_machine = NULL;\n    return -EINVAL;  // BUG: discards actual 'ret' value"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Change to `return ret;`",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_ERROR_PATH_AUDIT.md"
  },
  {
    "id": "HIGH-01",
    "title": "FEC encoder repair symbol generation -- partial resource leak on kzalloc failure",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Memory leak under memory pressure in GFP_ATOMIC context (common\nunder network load). Repeated leaks can lead to OOM.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "for (i = 0; i < num_repair; i++) {\n    repair_sym = kzalloc(sizeof(*repair_sym), GFP_ATOMIC);\n    if (!repair_sym) {\n        kfree(repair_bufs[i]);\n        continue;    // BUG: leaks remaining repair_bufs[i+1..num_repair-1]\n    }\n    repair_sym->data = repair_bufs[i];\n    ...\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** After the loop, iterate remaining entries and free any\n`repair_bufs[i]` that were not successfully adopted by a `repair_sym`.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_ERROR_PATH_AUDIT.md"
  },
  {
    "id": "HIGH-02",
    "title": "FEC decoder recovery -- partial recovery leaks on kzalloc failure",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Memory leak under GFP_ATOMIC pressure.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "for (i = 0; i < num_erasures; i++) {\n    symbol = kzalloc(sizeof(*symbol), GFP_ATOMIC);\n    if (!symbol) {\n        kfree(recovered[i]);\n        continue;    // BUG: same pattern as encoder\n    }\n    symbol->data = recovered[i];\n    ...\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_ERROR_PATH_AUDIT.md"
  },
  {
    "id": "HIGH-03",
    "title": "reed_solomon.c -- four-allocation group without individual NULL checks",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "decode_matrix = kmalloc_array(num_erasures, num_erasures, GFP_ATOMIC);\ninv_matrix = kmalloc_array(num_erasures, num_erasures, GFP_ATOMIC);\nsyndrome = kmalloc_array(num_erasures, max_len, GFP_ATOMIC);\nrepair_used = kmalloc_array(num_erasures, sizeof(int), GFP_ATOMIC);\n\nif (!decode_matrix || !inv_matrix || !syndrome || !repair_used) {\n    ret = -ENOMEM;\n    goto out;\n}",
        "out:\n    kfree(decode_matrix);\n    kfree(inv_matrix);\n    kfree(syndrome);\n    kfree(repair_used);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_ERROR_PATH_AUDIT.md"
  },
  {
    "id": "HIGH-04",
    "title": "tquic_zerocopy_sendmsg -- uarg leak on partial send",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Data corruption in the stream -- a subsequent successful send\nwill transmit data from the failed partial send interleaved with new data.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "while (copied < len) {\n    new_skb = alloc_skb(0, GFP_KERNEL);\n    if (!new_skb) {\n        err = -ENOMEM;\n        goto out_err;\n    }\n    ...\n    skb_queue_tail(&stream->send_buf, new_skb);\n    copied += chunk;\n}\n...\nout_err:\n    if (uarg && !msg->msg_ubuf)\n        net_zcopy_put(uarg);\n    return err;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** On the error path, dequeue and free all SKBs added during\nthis call, or commit the partial send as successful (return `copied` instead\nof error if `copied > 0`).\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_ERROR_PATH_AUDIT.md"
  },
  {
    "id": "HIGH-05",
    "title": "Missing kfree_sensitive for key material in crypto/handshake.c extensions buffer",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Key material may remain in freed slab memory.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "extensions = kzalloc(2048, GFP_KERNEL);\n...\nhs->key_share.public_key = kzalloc(32, GFP_KERNEL);\nhs->key_share.private_key = kzalloc(32, GFP_KERNEL);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_ERROR_PATH_AUDIT.md"
  },
  {
    "id": "HIGH-06",
    "title": "tquic_output.c:tquic_xmit -- pkt_num consumed but not tracked on send failure",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Packet number gaps without corresponding tracked sent packets can\ncause the peer's loss detection to trigger spurious retransmissions or\nconnection timeout.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "ret = tquic_output_packet(conn, path, skb);\nif (ret < 0)\n    break;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_ERROR_PATH_AUDIT.md"
  },
  {
    "id": "MED-01",
    "title": "tquic_cid_pool_init -- timer initialized but not cancelled on later failure",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Low in practice (timer never armed), but violates cleanup contract.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "pool = kzalloc(sizeof(*pool), GFP_KERNEL);\n...\nINIT_WORK(&pool->rotation_work, tquic_cid_rotation_work);\ntimer_setup(&pool->rotation_timer, tquic_cid_rotation_timer_cb, 0);\n...\nentry = kzalloc(sizeof(*entry), GFP_KERNEL);\nif (!entry) {\n    kfree(pool);   // BUG: timer and work not cancelled\n    return -ENOMEM;\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Call `del_timer_sync(&pool->rotation_timer)` before `kfree(pool)`.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_ERROR_PATH_AUDIT.md"
  },
  {
    "id": "MED-02",
    "title": "tquic_main.c init/exit -- conditional cleanup mismatch for NAPI/io_uring",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [
        "err_netlink:"
      ],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "// Init:\n#if IS_ENABLED(CONFIG_TQUIC_NAPI)\n    err = tquic_napi_subsys_init();\n    if (err)\n        goto err_napi;\n#endif\n\n#if IS_ENABLED(CONFIG_TQUIC_IO_URING)\n    err = tquic_io_uring_init();\n    if (err)\n        goto err_io_uring;\n#endif\n\n// Error path:\nerr_netlink:\n#if IS_ENABLED(CONFIG_TQUIC_IO_URING)\n    tquic_io_uring_exit();\nerr_io_uring:\n#endif\n#if IS_ENABLED(CONFIG_TQUIC_NAPI)\n    tquic_napi_subsys_exit();\nerr_napi:\n#endif"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_ERROR_PATH_AUDIT.md"
  },
  {
    "id": "MED-03",
    "title": "tquic_conn_create -- loss_detection_init failure doesn't clean up timers",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Safe currently but fragile; any future code between timer_setup\nand the goto could arm timers, creating use-after-free.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "// Initialize timers (lines 495-501)\ntimer_setup(&conn->timers[TQUIC_TIMER_LOSS], ...);\ntimer_setup(&conn->timers[TQUIC_TIMER_ACK], ...);\n// ... 7 timers total\n\n// Initialize work queues (lines 504-506)\nINIT_WORK(&conn->tx_work, ...);\nINIT_WORK(&conn->rx_work, ...);\nINIT_WORK(&conn->close_work, ...);\n\n// Loss detection init\nif (tquic_loss_detection_init(conn) < 0)\n    goto err_free_pn_spaces;\n\nerr_free_pn_spaces:\n    kfree(conn->pn_spaces);\nerr_free_scid:\n    tquic_cid_entry_destroy(scid_entry);\nerr_free_conn:\n    kfree(conn);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_ERROR_PATH_AUDIT.md"
  },
  {
    "id": "MED-04",
    "title": "cert_verify.c parse_san_extension -- error code not propagated",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Misreported error codes.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "err_free:\n    {\n        u32 j;\n        for (j = 0; j < name_count; j++)\n            kfree(names[j]);\n        kfree(names);\n        for (j = 0; j < addr_count; j++)\n            kfree(ips[j]);\n    }\n    kfree(ips);\n    kfree(ip_lengths);\n    return -ENOMEM;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_ERROR_PATH_AUDIT.md"
  },
  {
    "id": "MED-05",
    "title": "tquic_output_flush -- spin_unlock_bh after acquiring spin_lock_bh, but lock dropped mid-loop",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Potential use-after-free if stream or path is destroyed while\nlock is dropped. Requires concurrent connection teardown to exploit.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "/* Release lock while sending (may sleep in crypto) */\nspin_unlock_bh(&conn->lock);\n\n/* Assemble and send packet */\nsend_skb = tquic_assemble_packet(conn, path, -1, pkt_num, &frames);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_ERROR_PATH_AUDIT.md"
  },
  {
    "id": "MED-06",
    "title": "tquic_handshake.c tquic_start_handshake -- hs freed with memzero_explicit but no kfree_sensitive",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** No practical impact, but inconsistent with the rest of the\ncodebase which uses `kfree_sensitive` for crypto structures.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "err_free:\n    tsk->handshake_state = NULL;\n    memzero_explicit(hs, sizeof(*hs));\n    kfree(hs);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_ERROR_PATH_AUDIT.md"
  },
  {
    "id": "MED-07",
    "title": "tquic_retry.c -- integrity_aead_lock held across AEAD operations",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Denial of service under high connection rate -- serialized retry\nprocessing becomes a bottleneck.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "mutex_lock(&integrity_aead_lock);\naead = tquic_retry_get_integrity_aead(version);\n...\nret = crypto_aead_encrypt(req);\n...\nout_unlock:\n    mutex_unlock(&integrity_aead_lock);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_ERROR_PATH_AUDIT.md"
  },
  {
    "id": "LOW-01",
    "title": "Consistent use of kfree_sensitive for key material -- GOOD",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_ERROR_PATH_AUDIT.md"
  },
  {
    "id": "LOW-02",
    "title": "tquic_timer_state_alloc -- cleanup loop is correct",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_ERROR_PATH_AUDIT.md"
  },
  {
    "id": "LOW-03",
    "title": "tquic_pacing_cleanup -- correct ordering",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "hrtimer_cancel(&pacing->timer);\ncancel_work_sync(&pacing->work);\nskb_queue_purge(&pacing->queue);\nkfree(pacing);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_ERROR_PATH_AUDIT.md"
  },
  {
    "id": "LOW-04",
    "title": "tquic_timer_state_free -- thorough and correct",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_ERROR_PATH_AUDIT.md"
  },
  {
    "id": "LOW-05",
    "title": "tquic_main.c init -- correct cascading cleanup",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_ERROR_PATH_AUDIT.md"
  },
  {
    "id": "LOW-06",
    "title": "tquic_conn_destroy -- thorough cleanup",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_ERROR_PATH_AUDIT.md"
  },
  {
    "id": "LOW-07",
    "title": "bench/benchmark.c -- kvmalloc used correctly with kvfree",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_ERROR_PATH_AUDIT.md"
  },
  {
    "id": "CRIT-01-OTH",
    "title": "ECF Scheduler Declares Lock But Never Uses It",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** On 32-bit architectures, u64 `inflight_bytes` writes are non-atomic, producing torn values. On 64-bit, concurrent read-modify-write (`+=` and `-=`) without atomics causes lost updates. Path state corruption leads to wildly incorrect completion time estimates, causing traffic to be sent on the wrong path (potentially a congested or failed path).",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "// ecf_sched_data has spinlock_t lock -- never acquired\nstatic int ecf_get_path(...) {\n    // NO lock\n    ps = ecf_find_path_state(sd, path->path_id);\n    if (!ps) {\n        ps = ecf_alloc_path_state(sd, path->path_id); // modifies sd->paths[]\n    }\n    // reads ps->inflight_bytes, ps->send_rate -- concurrently modified by ecf_ack_received\n}\n\nstatic void ecf_packet_sent(...) {\n    // NO lock\n    ps->inflight_bytes += sent_bytes; // races with ecf_ack_received\n}\n\nstatic void ecf_ack_received(...) {\n    // NO lock\n    ps->inflight_bytes -= acked_bytes; // races with ecf_packet_sent\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `ecf_sched_data` declares `spinlock_t lock` but no function ever calls `spin_lock_irqsave()`. Every function that reads or writes `sd->paths[]`, `sd->current_path_id`, and `sd->path_switches` does so without synchronization. The send path (`ecf_get_path`), ACK processing (`ecf_ack_received`), loss detection (`ecf_loss_detected`), packet sent notification (`ecf_packet_sent`), and path management (`ecf_path_added`, `ecf_path_removed`) all run concurrently.",
    "fix_suggestion": "** Wrap all accesses to `sd->paths[]` and `sd->current_path_id` in `spin_lock_irqsave(&sd->lock, flags)` / `spin_unlock_irqrestore(&sd->lock, flags)`.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_SCHEDULERS_AUDIT.md"
  },
  {
    "id": "CRIT-02-OTH",
    "title": "BLEST Inconsistent Locking -- 3 of 6 Callbacks Lack Lock",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** `blest_ack_received()` modifies `inflight_bytes` and `send_rate` that `blest_get_path()` reads under lock. The locked reader sees inconsistent state (e.g., inflight updated but send_rate not yet). `blest_path_removed()` setting `valid=false` without lock means `blest_get_path()` could return a path whose state was just invalidated.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "// blest_ack_received -- NO LOCK\nstatic void blest_ack_received(...) {\n    ps = blest_find_path_state(sd, path->path_id);  // reads sd->paths[]\n    ps->inflight_bytes -= acked_bytes;               // modifies ps\n    ps->rtt_us = path->cc.smoothed_rtt_us;           // modifies ps\n    ps->send_rate = path->cc.bandwidth;              // modifies ps\n}\n\n// blest_path_removed -- NO LOCK\nstatic void blest_path_removed(...) {\n    ps = blest_find_path_state(sd, path->path_id);\n    ps->valid = false;        // races with blest_get_path reading valid\n    sd->current_path_id = TQUIC_INVALID_PATH_ID;\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** BLEST's `blest_get_path()` and `blest_packet_sent()` correctly acquire `sd->lock`. However, `blest_path_removed()`, `blest_ack_received()`, and `blest_loss_detected()` modify the same shared state (`sd->paths[]`, `sd->current_path_id`) without holding the lock.",
    "fix_suggestion": "** Add `spin_lock_irqsave(&sd->lock, flags)` to `blest_path_removed()`, `blest_ack_received()`, and `blest_loss_detected()`.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_SCHEDULERS_AUDIT.md"
  },
  {
    "id": "CRIT-03-OTH",
    "title": "Redundant Scheduler Dedup Uses Only 8 Bits of Sequence Number",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** After sending 256 unique packets, the dedup window is full and every new packet has a 100% collision rate with an existing entry. This causes **all subsequent packets to be dropped as duplicates**, completely breaking the connection. Even before the window is full, there is a `filled_entries/256` probability of false positive per packet.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "seq_byte = (u8)(seq & 0xFF);\n\nfor (i = 0; i < 256; i++) {\n    if (rd->dedup_window[i] == seq_byte)\n        return true;  /* False positive: seq 0 and seq 256 both map to 0 */\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The deduplication window truncates the 64-bit QUIC sequence number to 8 bits: `seq_byte = (u8)(seq & 0xFF)`. It then searches a 256-byte window for a match. This means any two packets whose sequence numbers differ by a multiple of 256 will collide, causing legitimate unique packets to be falsely identified as duplicates and dropped.",
    "fix_suggestion": "** Use a proper bitmap or hash table keyed on the full 64-bit sequence number, or at minimum use a larger hash with a rolling window.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_SCHEDULERS_AUDIT.md"
  },
  {
    "id": "CRIT-04",
    "title": "QPACK Decoder Stack Buffer Overflow via Large Headers",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "char name_buf[QPACK_MAX_HEADER_NAME_LEN];   /* 256 bytes on stack */\nchar value_buf[QPACK_MAX_HEADER_VALUE_LEN];  /* 8192 bytes on stack */"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The QPACK decoder allocates 256 + 8192 = 8448 bytes on the kernel stack for header name and value buffers. In the decoder's `qpack_decoder_process_encoder_stream` function, these same stack buffers are used in a loop processing potentially many encoder instructions. The kernel stack is typically 8KB (THREAD_SIZE on x86) or 16KB. With 8448 bytes of local buffers plus the function's stack frame, call chain overhead, and interrupt frames, this is at or beyond the kernel stack limit.",
    "fix_suggestion": "** Replace stack buffers with heap allocation (kmalloc with GFP_ATOMIC). The value_buf alone at 8192 bytes is dangerously large for kernel stack. Alternatively, reduce QPACK_MAX_HEADER_VALUE_LEN and allocate from a slab cache.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HTTP3_STREAMS_AUDIT.md"
  },
  {
    "id": "CRIT-05",
    "title": "WebTransport Close Capsule Large Stack Allocation",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "u8 buf[128 + WEBTRANSPORT_MAX_URL_LEN];  /* 128 + 8192 = 8320 bytes */"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The WebTransport session close function allocates a buffer of 8320 bytes on the kernel stack. This is similar to CRIT-04 and creates a stack overflow risk.",
    "fix_suggestion": "** Use heap allocation (kmalloc/kzalloc) for this buffer.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HTTP3_STREAMS_AUDIT.md"
  },
  {
    "id": "CRIT-06",
    "title": "tquic_stream_sendmsg Writes to Stream Without Connection Refcount on Stream",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** While `tquic_stream_sendmsg` takes a connection refcount via `tquic_conn_get(conn)`, the stream pointer `ss->stream` itself has no refcount protection. Between the time `ss->stream` is read and the time stream operations are performed (send_buf access, send_offset update, flow control checks), the stream could be freed by another thread closing the stream socket concurrently (e.g., from a different file descriptor pointing to the same socket).\n\nThe code accesses `stream->state`, `stream->send_offset`, `stream->max_send_data`, `stream->send_buf` and more without any lock protecting the stream pointer validity.",
    "fix_suggestion": "** Stream objects need reference counting. The stream_sock should hold a reference to the stream. Only when both the tree reference and the socket reference are dropped should the stream be freed.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HTTP3_STREAMS_AUDIT.md"
  },
  {
    "id": "CRIT-07",
    "title": "Priority PRIORITY_UPDATE Parsing Off-by-Two in Loop Bound",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "for (i = 0; i < pf_len - 2; i++) {\n    if (pf_start[i] == 'u' && pf_start[i + 1] == '=') {"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** When `pf_len` is 0 or 1, the expression `pf_len - 2` wraps around to a very large value because `pf_len` is `int` (len - offset). If `pf_len` is 0, `pf_len - 2 = -2` which as a signed int would make the loop not execute. However, if `pf_len` is 1, `pf_len - 2 = -1`, and the loop condition `i < -1` is false for i=0, so this is safe for signed int. BUT: the access `pf_start[i + 2]` at line 633 accesses beyond the buffer when `i + 2 >= pf_len`. When `pf_len = 3`, `i` can be 0, and `pf_start[2]` is valid, but `pf_start[i+2]` with i=0 is index 2 which is the last valid byte (pf_len=3, indices 0-2). This is borderline safe but the loop bound should be `pf_len - 2` should exclude `i + 2 >= pf_len` accesses more carefully. More importantly, the `i` token check at line 637 accesses `pf_start[i]` which can be at index `pf_len - 3` but checks nothing after it.\n\nAfter further analysis, the signed integer arithmetic appears safe for small positive values and negative values. However, the function does not validate that the priority field value conforms to Structured Fields (RFC 8941) format, accepting arbitrary byte sequences from the network. An attacker could craft a priority field that sets urgency to attacker-chosen values. While urgency is clamped to 0-7 by the `>= '0' && <= '7'` check, the `incremental` flag is set to true whenever ANY byte in the field equals `'i'`, which is overly permissive.",
    "fix_suggestion": "** Implement proper Structured Field Dictionary parsing per RFC 8941. Validate the priority field value format strictly.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HTTP3_STREAMS_AUDIT.md"
  },
  {
    "id": "HIGH-01-OTH",
    "title": "Function Pointer Stored in skb->cb Without Validation",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Potential arbitrary kernel code execution if `skb->cb` is corrupted by another networking layer. The check `if (skb->cb[0])` only verifies the first byte is non-zero, not that the pointer is valid.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "/* Store send function in skb->cb */\n*(unsigned long *)skb->cb = (unsigned long)send_fn;",
        "if (skb->cb[0]) {\n    void (*send_fn)(struct sk_buff *) =\n        (void (*)(struct sk_buff *))\n        (*(unsigned long *)skb->cb);\n    send_fn(skb);  /* <-- calling unvalidated function pointer */\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The exfiltration protection code stores function pointers in `skb->cb` (the control buffer) and later retrieves and calls them without any validation. The `skb->cb` field is 48 bytes and is used by multiple layers of the networking stack. If any other code modifies `skb->cb` between the store and the load, the function pointer could be corrupted, leading to arbitrary code execution.\n\n**Code (quic_exfil.c:270-271, storing):**\n```c\n/* Store send function in skb->cb */\n*(unsigned long *)skb->cb = (unsigned long)send_fn;\n```\n\n**Code (quic_exfil.c:71-75, loading and calling):**\n```c\nif (skb->cb[0]) {\n    void (*send_fn)(struct sk_buff *) =\n        (void (*)(struct sk_buff *))\n        (*(unsigned long *)skb->cb);\n    send_fn(skb);  /* <-- calling unvalidated function pointer */\n}\n```",
    "fix_suggestion": "** Use a unique magic value alongside the function pointer to validate integrity before calling. Better yet, do not store function pointers in `skb->cb` -- instead use a dedicated hash table keyed by skb pointer or use `skb->destructor` with a wrapper. At minimum, add a bounds check that the function pointer falls within kernel text section (`__is_kernel_text()`).\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_MASQUE_TUNNEL_AUDIT.md"
  },
  {
    "id": "HIGH-02-OTH",
    "title": "Integer Overflow in iovec Total Length Calculation",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Heap buffer overflow leading to kernel memory corruption and potential code execution. The severity depends on whether this code path is reachable from userspace on 32-bit architectures.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "/* Calculate total length */\nfor (i = 0; i < iovcnt; i++)\n    total_len += iov[i].iov_len;  /* <-- can overflow on 32-bit */\n\nif (total_len > TQUIC_CONNECT_UDP_MAX_PAYLOAD)\n    return -EMSGSIZE;\n\n/* Allocate and copy to contiguous buffer */\nbuf = kmalloc(total_len, GFP_KERNEL);  /* small due to overflow */\nif (!buf)\n    return -ENOMEM;\n\nfor (i = 0; i < iovcnt; i++) {\n    memcpy(buf + offset, iov[i].iov_base, iov[i].iov_len);  /* heap overflow */\n    offset += iov[i].iov_len;\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The `tquic_connect_udp_sendv()` function sums `iov_len` values from a caller-provided iovec array into a `size_t` without checking for integer overflow. If the sum wraps around, a small buffer is allocated but large memcpy operations follow.\n\n**Code (connect_udp.c:1028-1041):**\n```c\n/* Calculate total length */\nfor (i = 0; i < iovcnt; i++)\n    total_len += iov[i].iov_len;  /* <-- can overflow on 32-bit */\n\nif (total_len > TQUIC_CONNECT_UDP_MAX_PAYLOAD)\n    return -EMSGSIZE;\n\n/* Allocate and copy to contiguous buffer */\nbuf = kmalloc(total_len, GFP_KERNEL);  /* small due to overflow */\nif (!buf)\n    return -ENOMEM;\n\nfor (i = 0; i < iovcnt; i++) {\n    memcpy(buf + offset, iov[i].iov_base, iov[i].iov_len);  /* heap overflow */\n    offset += iov[i].iov_len;\n}\n```",
    "fix_suggestion": "** Use `check_add_overflow()` or manually check for overflow: `if (total_len + iov[i].iov_len < total_len) return -EOVERFLOW;` within the accumulation loop.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_MASQUE_TUNNEL_AUDIT.md"
  },
  {
    "id": "HIGH-03-OTH",
    "title": "Incomplete SSRF Protection in TCP-over-QUIC Tunnel",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** SSRF to internal RFC1918 services and cloud metadata endpoints. While less severe than CRITICAL-01 (some addresses are blocked), this still allows attacking most internal infrastructure.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (ipv4_is_loopback(addr4) ||\n    ipv4_is_multicast(addr4) ||\n    ipv4_is_lbcast(addr4) ||\n    ipv4_is_zeronet(addr4)) {\n    return -EACCES;\n}\n/* MISSING: ipv4_is_private_10, ipv4_is_private_172, ipv4_is_private_192 */\n/* MISSING: link-local (169.254.0.0/16) including cloud metadata */"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The tunnel header parser blocks loopback, multicast, broadcast, and zeronet for IPv4, plus loopback, multicast, and link-local for IPv6. However, it fails to block RFC1918 private addresses (10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16), the cloud metadata address (169.254.169.254), and IPv4-mapped IPv6 addresses (::ffff:127.0.0.1).\n\n**Code (tquic_tunnel.c:164-169):**\n```c\nif (ipv4_is_loopback(addr4) ||\n    ipv4_is_multicast(addr4) ||\n    ipv4_is_lbcast(addr4) ||\n    ipv4_is_zeronet(addr4)) {\n    return -EACCES;\n}\n/* MISSING: ipv4_is_private_10, ipv4_is_private_172, ipv4_is_private_192 */\n/* MISSING: link-local (169.254.0.0/16) including cloud metadata */\n```",
    "fix_suggestion": "** Add checks for all private ranges. Use `ipv4_is_private_10()`, `ipv4_is_private_172()`, `ipv4_is_private_192()` (or the unified `ipv4_is_private()` if available in the kernel version). Add link-local check. For IPv6, add check for IPv4-mapped addresses: `ipv6_addr_v4mapped()` and then validate the embedded IPv4 address.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_MASQUE_TUNNEL_AUDIT.md"
  },
  {
    "id": "HIGH-04-OTH",
    "title": "Weak CID Hash Function Enables Hash Flooding",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Algorithmic complexity denial-of-service. A remote attacker can make every CID lookup O(n), exhausting server CPU.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "static inline u32 cid_hash_key(const u8 *cid, u8 len)\n{\n    u32 hash = 0;\n    int i;\n\n    for (i = 0; i < len; i++)\n        hash = (hash * 31) + cid[i];\n\n    return hash;\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The CID hash table uses a trivially predictable hash function (`hash = hash * 31 + byte`). An attacker can compute CID values that all hash to the same bucket, degrading the hash table to a linked list and causing O(n) lookup time.\n\n**Code (quic_proxy.c:145-154):**\n```c\nstatic inline u32 cid_hash_key(const u8 *cid, u8 len)\n{\n    u32 hash = 0;\n    int i;\n\n    for (i = 0; i < len; i++)\n        hash = (hash * 31) + cid[i];\n\n    return hash;\n}\n```",
    "fix_suggestion": "** Use `jhash()` or `siphash()` with a per-proxy random key initialized at proxy creation time. SipHash is specifically designed to be resistant to hash-flooding attacks.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_MASQUE_TUNNEL_AUDIT.md"
  },
  {
    "id": "HIGH-05-OTH",
    "title": "Race Condition in Idle Timer Connection Processing",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Use-after-free in kernel context, potentially exploitable for privilege escalation.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "spin_unlock_bh(&proxy->lock);\n\n/* Process removals outside lock */\nlist_for_each_entry_safe(pconn, tmp, &to_remove, list) {\n    list_del(&pconn->list);\n    tquic_quic_proxy_deregister_conn(pconn, QUIC_PROXY_DEREG_TIMEOUT, 0);\n    proxied_conn_put(pconn);  /* <-- pconn may already be freed by concurrent path */\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The idle timer callback collects connections to remove into a local list while holding `proxy->lock`, then releases the lock and processes removals outside the lock. Between the unlock and the deregistration call, another thread could concurrently access or modify the same connection.\n\n**Code (quic_proxy.c:417-424):**\n```c\nspin_unlock_bh(&proxy->lock);\n\n/* Process removals outside lock */\nlist_for_each_entry_safe(pconn, tmp, &to_remove, list) {\n    list_del(&pconn->list);\n    tquic_quic_proxy_deregister_conn(pconn, QUIC_PROXY_DEREG_TIMEOUT, 0);\n    proxied_conn_put(pconn);  /* <-- pconn may already be freed by concurrent path */\n}\n```",
    "fix_suggestion": "** Hold a reference count on each connection while it is in the `to_remove` list (which appears to be partially done via `proxied_conn_put`). Ensure CID hash removal happens atomically with the list removal under the proxy lock, so no new lookups can find the connection after it is selected for removal.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_MASQUE_TUNNEL_AUDIT.md"
  },
  {
    "id": "HIGH-06-OTH",
    "title": "const-Correctness Violation in Proxy Packet Decode",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Use-after-free if the input buffer is freed before the capsule's packet pointer is used. Data corruption if the caller modifies data through the cast-away const pointer. This is a latent bug that becomes exploitable depending on the lifetime management of the input buffer.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "capsule->packet = (u8 *)(buf + offset);  /* discards const from buf */"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The packet decoder stores a pointer into the input buffer as a mutable `u8 *`, discarding the `const` qualifier. If the caller frees or reuses the input buffer, the capsule structure holds a dangling pointer. The caller may also inadvertently modify protocol data through this non-const pointer.\n\n**Code (quic_proxy_capsules.c:686):**\n```c\ncapsule->packet = (u8 *)(buf + offset);  /* discards const from buf */\n```",
    "fix_suggestion": "** Either copy the packet data into a separately allocated buffer, or declare `capsule->packet` as `const u8 *` and ensure all consumers respect const correctness.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_MASQUE_TUNNEL_AUDIT.md"
  },
  {
    "id": "HIGH-07",
    "title": "atomic_sub on sk_rmem_alloc Incompatible with refcount_t",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "atomic_sub(skb->truesize, &sk->sk_rmem_alloc);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** Modern kernels (6.x) changed `sk_rmem_alloc` from `atomic_t` to `refcount_t`. Direct `atomic_sub` on a `refcount_t` will either fail to compile or cause undefined behavior. The tquic_stream.c file (socket layer) correctly uses `skb_set_owner_r/skb_set_owner_w` and destructor-based accounting, but the core/stream.c file uses raw `atomic_sub` in three places.",
    "fix_suggestion": "** Use `skb_set_owner_r()` for receive buffers and let the destructor handle accounting, consistent with the tquic_stream.c approach.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HTTP3_STREAMS_AUDIT.md"
  },
  {
    "id": "HIGH-08",
    "title": "tquic_stream_send_allowed Missing Underflow Check",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "stream_limit = stream->max_send_data - stream->send_offset;\n...\nconn_limit = mgr->max_data_remote - mgr->data_sent;",
        "if (stream->send_offset >= stream->max_send_data) { blocked; return 0; }\nstream_limit = stream->max_send_data - stream->send_offset;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** These subtractions assume `max_send_data >= send_offset` and `max_data_remote >= data_sent`. If due to a bug or race condition `send_offset > max_send_data`, the subtraction wraps to a very large u64 value, effectively disabling flow control for this stream.",
    "fix_suggestion": "** Add underflow guards:\n```c\nif (stream->send_offset >= stream->max_send_data) { blocked; return 0; }\nstream_limit = stream->max_send_data - stream->send_offset;\n```\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HTTP3_STREAMS_AUDIT.md"
  },
  {
    "id": "HIGH-09",
    "title": "tquic_stream_recv_data Potential Integer Overflow in Flow Control Check",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (offset + skb->len > stream->max_recv_data) {\n    ...\n}\nif (mgr->data_received + skb->len > mgr->max_data_local) {\n    ...\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `offset` is u64, `skb->len` is unsigned int. The addition `offset + skb->len` can overflow if offset is near U64_MAX. While practically unlikely (offsets should be much smaller), the flow_control.c implementation at line 697-699 correctly checks for this: `if (length > U64_MAX - offset) return -EOVERFLOW;`. This check is missing in core/stream.c.",
    "fix_suggestion": "** Add overflow check before the addition: `if (skb->len > U64_MAX - offset) return -EOVERFLOW;`\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HTTP3_STREAMS_AUDIT.md"
  },
  {
    "id": "HIGH-10",
    "title": "tquic_stream_socket_create Double-Free on fd Failure",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "fd = tquic_sock_map_fd(sock, O_CLOEXEC);\nif (fd < 0) {\n    /* Note: tquic_sock_map_fd calls sock_release on failure */\n    tquic_stream_remove_from_conn(conn, stream);\n    kfree(ss);\n    tquic_stream_free(stream);\n    return fd;\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The comment says `tquic_sock_map_fd` calls `sock_release` on failure, but examining the function at lines 213-231, `sock_release` is only called when `get_unused_fd_flags` fails (line 219). When `sock_alloc_file` fails (line 224), `sock_release` is NOT called -- only `put_unused_fd` is called. This means the socket `sock` leaks in the `sock_alloc_file` failure path.\n\nAdditionally, `sock->sk->sk_user_data` was already set to `ss` at line 591. If `sock_release` does get called, it may invoke the socket's `release` callback (`tquic_stream_release`) which accesses `ss` which contains a pointer to `stream`. Then the code below also frees both `ss` and `stream`, creating a double-free.",
    "fix_suggestion": "** Set `sk_user_data` to NULL before calling `tquic_sock_map_fd`, or set it only after successful fd allocation. Fix the `sock_alloc_file` failure path to release the socket.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HTTP3_STREAMS_AUDIT.md"
  },
  {
    "id": "HIGH-11",
    "title": "h3_control_recv_frame Does Not Parse Frame Payloads",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "case H3_FRAME_SETTINGS:\n    pr_debug(\"h3: received SETTINGS frame\\n\");\n    /* Parse settings - implementation would extract parameters */\n    break;\ncase H3_FRAME_GOAWAY:\n    pr_debug(\"h3: received GOAWAY frame\\n\");\n    /* Parse stream ID from GOAWAY */\n    break;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The control stream frame handler receives frame type and payload data but does NOT actually parse any of the payloads. SETTINGS, GOAWAY, MAX_PUSH_ID, and CANCEL_PUSH are all logged but ignored. This means:\n1. No SETTINGS are applied from the peer.\n2. GOAWAY is silently ignored (no graceful shutdown).\n3. MAX_PUSH_ID limits are not enforced.\n4. CANCEL_PUSH has no effect.",
    "fix_suggestion": "** Implement actual parsing and processing for each frame type in this handler.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HTTP3_STREAMS_AUDIT.md"
  },
  {
    "id": "HIGH-12",
    "title": "tquic_stream_count_by_type O(n) Scan for Critical Stream Enforcement",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** Counting streams by type requires iterating ALL streams in the connection under spinlock. This is used to enforce the \"one control stream per endpoint\" rule. With many streams, this becomes a DoS vector where an attacker opening many streams makes the type-count check progressively slower, holding the connection lock for extended periods.",
    "fix_suggestion": "** Maintain per-type counters in the connection structure, incrementing/decrementing on stream creation/destruction.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HTTP3_STREAMS_AUDIT.md"
  },
  {
    "id": "MED-01-OTH",
    "title": "`tquic_sock_setsockopt()` Reads `int` for Some Options But Accepts `optlen >= sizeof(int)` Without Capping",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Potential buffer overflow if `psk_identity` field in `tquic_sock` is smaller than 64 bytes.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (optlen < sizeof(int))\n        return -EINVAL;\n\n    if (copy_from_sockptr(&val, optval, sizeof(val)))\n        return -EFAULT;",
        "if (optlen < 1 || optlen > 64)\n        return -EINVAL;\n    if (copy_from_sockptr(identity, optval, optlen))\n        return -EFAULT;\n    lock_sock(sk);\n    memcpy(tsk->psk_identity, identity, optlen);\n    tsk->psk_identity_len = optlen;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** This correctly copies only `sizeof(int)` bytes regardless of optlen. The initial `optlen` check is correct. However, for string-type options like `TQUIC_SCHEDULER` (line 840), `TQUIC_CONGESTION` (line 899), `TQUIC_PSK_IDENTITY` (line 942), and `TQUIC_EXPECTED_HOSTNAME` (line 1185), the code validates optlen against the respective maximum but uses `optlen` directly as copy length. This is correct since `copy_from_sockptr` with the right length handles bounds.\n\nHowever, for `TQUIC_PSK_IDENTITY` (line 942-956):\n```c\n    if (optlen < 1 || optlen > 64)\n        return -EINVAL;\n    if (copy_from_sockptr(identity, optval, optlen))\n        return -EFAULT;\n    lock_sock(sk);\n    memcpy(tsk->psk_identity, identity, optlen);\n    tsk->psk_identity_len = optlen;\n```\n\nThe stack buffer `identity` is 64 bytes, and `optlen` is validated to be <= 64. But the `tsk->psk_identity` buffer size must also be >= 64. If not, this is an overflow. This requires verifying the struct definition.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_SOCKET_NETLINK_MIGRATION_AUDIT.md"
  },
  {
    "id": "MED-02-OTH",
    "title": "`tquic_path_compute_score()` Integer Overflow in Score Calculation",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Path selection uses wrong score, potentially migrating to a worse path. Low direct security impact but could be used to force migration to an attacker-controlled path.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "u64 score = 1000000;\n\n    if (stats->rtt_smoothed > 0)\n        score = score * 1000 / stats->rtt_smoothed;\n\n    if (stats->bandwidth > 0)\n        score = (score * stats->bandwidth) >> 20;\n\n    /* ... */\n    score = score * path->weight;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `score * stats->bandwidth` can overflow u64 if bandwidth is large (e.g., 10 Gbps = 10^10). After the RTT division, score could be up to ~10^9 (for 1us RTT), and bandwidth * 10^9 = 10^19, which fits in u64 (max 1.8*10^19). But with higher bandwidth values or lower RTTs, overflow is possible.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_SOCKET_NETLINK_MIGRATION_AUDIT.md"
  },
  {
    "id": "MED-03-OTH",
    "title": "`tquic_path_is_degraded()` Division by Zero Possible",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Failure to detect path degradation, preventing automatic migration when needed.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (stats->tx_packets > 100) {\n        loss_rate = (stats->lost_packets * 100) / stats->tx_packets;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** Although `tx_packets > 100` guards against zero division, if `lost_packets` is very large (close to U64_MAX), `lost_packets * 100` overflows u64. With `lost_packets` > U64_MAX/100, the overflow produces a small value, causing the check to miss actual high loss.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_SOCKET_NETLINK_MIGRATION_AUDIT.md"
  },
  {
    "id": "MED-04-OTH",
    "title": "PSK Identity Logged with `tquic_dbg()` -- Sensitive Data in Kernel Logs",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Information disclosure of the expected hostname in kernel logs. In multi-tenant environments, this could leak which service a connection is targeting.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "tquic_dbg(\"PSK identity set (%d bytes)\\n\", optlen);",
        "tquic_dbg(\"Expected hostname set to '%s'\\n\", hostname);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** While this only logs the length, the `TQUIC_EXPECTED_HOSTNAME` option at line 1202 logs the actual hostname:\n```c\n    tquic_dbg(\"Expected hostname set to '%s'\\n\", hostname);\n```",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_SOCKET_NETLINK_MIGRATION_AUDIT.md"
  },
  {
    "id": "MED-05-OTH",
    "title": "`tquic_nl_cmd_path_dump()` Incorrect Cast of `cb->ctx`",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Stack buffer overflow if struct grows beyond `cb->ctx` size. Currently safe but fragile.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "struct tquic_dump_ctx *ctx = (struct tquic_dump_ctx *)cb->ctx;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `cb->ctx` is a fixed-size array (`long[6]`). The code casts it to `struct tquic_dump_ctx *` which contains `u64 conn_id` and `int idx`. This is a common kernel pattern but relies on `sizeof(struct tquic_dump_ctx) <= sizeof(cb->ctx)`. If `tquic_dump_ctx` grows, this will silently overflow.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_SOCKET_NETLINK_MIGRATION_AUDIT.md"
  },
  {
    "id": "MED-06-OTH",
    "title": "`tquic_migrate_validate_all_additional()` Lock Drop/Reacquire Pattern",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Kernel crash or UAF when concurrent address removal occurs during validation sweep.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "spin_lock_bh(&remote_addrs->lock);\n    list_for_each_entry(entry, &remote_addrs->addresses, list) {\n        if (entry->validated || !entry->active)\n            continue;\n\n        spin_unlock_bh(&remote_addrs->lock);\n\n        /* Create probe path */\n        probe_path = tquic_path_create(conn, &local_addr, &entry->addr);\n        /* ... */\n\n        spin_lock_bh(&remote_addrs->lock);\n    }\n    spin_unlock_bh(&remote_addrs->lock);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** After dropping the lock, `entry` may have been freed or the list modified. When the lock is reacquired, `list_for_each_entry` continues with the stale `entry->list.next` pointer. This is a use-after-free if entries are removed between unlock and reacquire.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_SOCKET_NETLINK_MIGRATION_AUDIT.md"
  },
  {
    "id": "MED-07-OTH",
    "title": "`tquic_sendmsg_datagram()` Allocates Kernel Buffer Sized by User-Controlled `len`",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Local DoS via memory exhaustion. Unprivileged user can trigger large kernel allocations.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (len > conn->datagram.max_send_size)\n        return -EMSGSIZE;\n\n    buf = kmalloc(len, GFP_KERNEL);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `len` comes from the sendmsg `size_t` parameter. It is bounded by `max_send_size`, but `max_send_size` is negotiated from the peer's transport parameter. If the peer advertises a very large max_datagram_frame_size (up to 2^62 per QUIC spec), this could attempt a huge allocation.\n\nIn practice, the kernel's `kmalloc` would fail for extremely large sizes, but values in the range of several MB could succeed and cause memory pressure.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_SOCKET_NETLINK_MIGRATION_AUDIT.md"
  },
  {
    "id": "MED-08",
    "title": "tquic_fc_reserve_credit Does Not Actually Reserve",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "int tquic_fc_reserve_credit(..., u64 bytes)\n{\n    tquic_fc_get_credit(fc, stream, &credit);\n    if (bytes > credit.effective_credit)\n        return -ENOSPC;\n    return 0;  /* \"Credit will be committed when transmission succeeds\" */\n}\n\nvoid tquic_fc_release_credit(...)\n{\n    /* This is a no-op in our implementation */\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The reserve/commit/release pattern is a classic TOCTOU. `reserve_credit` checks if credit is available but does not atomically deduct it. Between reserve and commit, another thread can consume the same credit. The release function is a no-op, meaning a failed transmission after reserve never returns the credit (though since reserve didn't deduct, this is consistent but broken).",
    "fix_suggestion": "** Implement actual atomic reservation by deducting credit in reserve and adding back in release.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HTTP3_STREAMS_AUDIT.md"
  },
  {
    "id": "MED-09",
    "title": "tquic_stream_write Holds mgr->lock for Entire Copy Loop",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The stream write function holds `mgr->lock` (a spinlock) for the entire duration of data copying, which includes `copy_from_iter` (which may fault on user pages). Holding a spinlock while potentially faulting on user pages is unsafe -- it can cause deadlocks when the page fault handler needs to acquire the same lock or sleep for I/O.",
    "fix_suggestion": "** Copy data to a pre-allocated buffer outside the lock, then enqueue under the lock. Or use a mutex instead of spinlock for the write path.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HTTP3_STREAMS_AUDIT.md"
  },
  {
    "id": "MED-10",
    "title": "kmem_cache Names Not Unique Per Connection",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "mgr->stream_cache = kmem_cache_create(\"tquic_stream_ext\", ...);\nmgr->gap_cache = kmem_cache_create(\"tquic_stream_gap\", ...);\nmgr->chunk_cache = kmem_cache_create(\"tquic_recv_chunk\", ...);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** Each stream manager creates kmem_caches with identical names. If multiple connections exist simultaneously, `kmem_cache_create` will return the existing cache with the same name (or NULL on some configurations). This means all connections share the same slab cache, which is actually fine for memory efficiency but means `kmem_cache_destroy` in one connection's teardown will destroy the cache while other connections still use it.",
    "fix_suggestion": "** Use `KMEM_CACHE` macro or create caches at module init time (shared across all connections), not per-connection. Or use unique names with connection ID suffix.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HTTP3_STREAMS_AUDIT.md"
  },
  {
    "id": "MED-11",
    "title": "h3_stream_recv_headers Does Not Validate payload_len Against H3_MAX_FRAME_PAYLOAD_SIZE",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (payload_len > len)\n    return -ENOBUFS;\nret = tquic_stream_recv(h3s->base, buf, payload_len);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The function checks that `payload_len <= len` (caller's buffer size) but does not validate against any maximum frame payload size. If the caller passes a large buffer, an attacker can force a very large read. The `payload_len` comes directly from the network frame header.",
    "fix_suggestion": "** Add: `if (payload_len > H3_MAX_FRAME_PAYLOAD_SIZE) return -EMSGSIZE;`\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HTTP3_STREAMS_AUDIT.md"
  },
  {
    "id": "MED-12",
    "title": "tquic_stream_trigger_output Inflight Underflow",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "inflight = path->stats.tx_bytes - path->stats.acked_bytes;\ncan_send = (inflight < path->stats.cwnd);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** If `acked_bytes > tx_bytes` due to a bug or race, `inflight` wraps to a very large u64 value, and `can_send` becomes false. This is a fail-safe (transmission stops) but could cause a permanent stall if the invariant is violated.",
    "fix_suggestion": "** Add underflow guard: `inflight = (path->stats.tx_bytes > path->stats.acked_bytes) ? path->stats.tx_bytes - path->stats.acked_bytes : 0;`\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HTTP3_STREAMS_AUDIT.md"
  },
  {
    "id": "MED-13",
    "title": "WebTransport Session Refcount Not Checked After Accept",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `webtransport_accept` returns a session pointer after incrementing the refcount, but there is no corresponding `webtransport_session_put` documented in all code paths where the session is used. Missing put calls lead to reference count leaks and memory leaks.",
    "fix_suggestion": "** Audit all callers of session-returning functions and ensure every get has a matching put.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HTTP3_STREAMS_AUDIT.md"
  },
  {
    "id": "MED-14",
    "title": "tquic_stream_memory_pressure Frees Without ext Cleanup",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (stream->state == TQUIC_STREAM_CLOSED) {\n    tquic_stream_remove(mgr, stream);\n    /* ... purge buffers ... */\n    kfree(stream);  /* ext is NOT freed! */\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** During memory pressure cleanup, closed streams are freed but `stream->ext` (extended state) is not freed via `tquic_stream_ext_free`. This leaks the extended state memory (including any recv_chunks, gaps, and queued frames).",
    "fix_suggestion": "** Add `tquic_stream_ext_free(mgr, stream->ext);` before `kfree(stream);`.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HTTP3_STREAMS_AUDIT.md"
  },
  {
    "id": "MED-15",
    "title": "h3_stream_recv_data frame_hdr Buffer Partial Read",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "ret = tquic_stream_recv(h3s->base, frame_hdr, sizeof(frame_hdr));\nif (ret <= 0)\n    return ret ? ret : -EAGAIN;\nhdr_len = h3_parse_frame_header(frame_hdr, ret, &frame_type, &payload_len);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `tquic_stream_recv` may return fewer bytes than `sizeof(frame_hdr)` (16 bytes). The parse function receives `ret` as the buffer length, which could be as small as 1 byte. If `h3_parse_frame_header` does not properly handle very short buffers, it could read uninitialized stack data from `frame_hdr`.",
    "fix_suggestion": "** Validate that `ret >= 2` (minimum varint frame header) before calling the parser, or zero-initialize `frame_hdr`.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HTTP3_STREAMS_AUDIT.md"
  },
  {
    "id": "MED-16",
    "title": "tquic_stream_sendfile Reads Only Into First Page",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "ret = kernel_read(file, page_address(pages[0]), chunk, offset);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The function allocates `nr_pages` pages but reads file data only into `pages[0]`. When `chunk > PAGE_SIZE`, data is read beyond the first page's allocation into adjacent memory, causing a heap buffer overflow.",
    "fix_suggestion": "** Read into each page individually, or allocate a contiguous buffer. The current code only works correctly when `chunk <= PAGE_SIZE`.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HTTP3_STREAMS_AUDIT.md"
  },
  {
    "id": "LOW-01-OTH",
    "title": "Missing Error Check for init_net Reference",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The code uses `&init_net` directly without checking if it is still valid. While `init_net` is a global that exists for the kernel lifetime, this pattern makes it impossible to later add proper namespace support without auditing every callsite.",
    "fix_suggestion": "** Store the network namespace reference at module load time and add a helper function that returns the appropriate namespace.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_MASQUE_TUNNEL_AUDIT.md"
  },
  {
    "id": "LOW-02-OTH",
    "title": "Duplicate MODULE_DESCRIPTION in quic_exfil.c",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The MODULE_DESCRIPTION, MODULE_LICENSE, and MODULE_AUTHOR macros are duplicated at lines 1684-1686 and 1763-1765. While not a security issue, duplicate module metadata can cause build warnings with some kernel configurations.\n\n---",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_MASQUE_TUNNEL_AUDIT.md"
  },
  {
    "id": "LOW-03-OTH",
    "title": "Context Set Level Does Not Check init Return Values",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "tquic_traffic_shaper_destroy(&ctx->shaper);\ntquic_traffic_shaper_init(&ctx->shaper, level);  /* return value ignored */\n\ntquic_spin_randomizer_destroy(&ctx->spin_rand);\ntquic_spin_randomizer_init(&ctx->spin_rand, level);  /* return value ignored */"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `tquic_exfil_ctx_set_level()` destroys and reinitializes the shaper, spin randomizer, and jitter subsystems but does not check the return values of the `_init()` calls. If initialization fails, the context is left in a partially initialized state.\n\n**Code (quic_exfil.c:1457-1464):**\n```c\ntquic_traffic_shaper_destroy(&ctx->shaper);\ntquic_traffic_shaper_init(&ctx->shaper, level);  /* return value ignored */\n\ntquic_spin_randomizer_destroy(&ctx->spin_rand);\ntquic_spin_randomizer_init(&ctx->spin_rand, level);  /* return value ignored */\n```",
    "fix_suggestion": "** Check return values and either revert to the previous level or mark the context as failed.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_MASQUE_TUNNEL_AUDIT.md"
  },
  {
    "id": "LOW-04-OTH",
    "title": "Workqueue Not Validated Before Use",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "** If module init fails partially, packets may be silently dropped (queued but never sent, leaking memory via the skb).",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `tquic_timing_normalize_send()` checks `if (exfil_wq)` before queuing work, but silently drops the packet if the workqueue is NULL (not initialized or destroyed). The packet is queued to `delay_queue` but never sent.",
    "fix_suggestion": "** If `exfil_wq` is NULL, either send the packet immediately (bypassing timing normalization) or return an error so the caller can handle it.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_MASQUE_TUNNEL_AUDIT.md"
  },
  {
    "id": "LOW-05-OTH",
    "title": "`tquic_server_check_path_recovery()` Uses `goto restart` Pattern",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "** CPU soft-lockup in pathological cases. Low practical risk.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The `goto restart` pattern drops the lock, calls `tquic_path_start_validation()`, then restarts the entire iteration. If path recovery triggers for multiple paths, this could loop many times. In pathological cases (paths rapidly toggling between UNAVAILABLE and another state), this could loop indefinitely.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_SOCKET_NETLINK_MIGRATION_AUDIT.md"
  },
  {
    "id": "LOW-06-OTH",
    "title": "CID Table Initialization Not Thread-Safe",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "** Theoretical race during module initialization. Very low practical risk.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "static bool cid_table_initialized;  // not atomic\n\n    if (cid_table_initialized) {\n        ret = rhashtable_insert_fast(...);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `cid_table_initialized` is a plain `bool` checked without barriers. If a connection is created before the CID table initialization completes, the `cid_table_initialized` check could read a stale `false` even after initialization, skipping rhashtable registration. In practice, module init runs before any connections are possible, so this is theoretical.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_SOCKET_NETLINK_MIGRATION_AUDIT.md"
  },
  {
    "id": "LOW-07-OTH",
    "title": "`tquic_cid_retire()` Sends RETIRE_CONNECTION_ID After Retirement",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "** Protocol violation -- sending unexpected RETIRE_CONNECTION_ID frame could confuse the peer or cause connection closure.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** After retiring a local CID (which the peer requested to retire), the code sends `tquic_send_retire_connection_id()`. But RFC 9000 says RETIRE_CONNECTION_ID is sent by the peer to request retirement of a CID *we* issued. When we receive it, we retire our CID and optionally issue a new one. We should NOT send back RETIRE_CONNECTION_ID -- that would be us asking the peer to retire a CID they issued, which is a different operation.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_SOCKET_NETLINK_MIGRATION_AUDIT.md"
  },
  {
    "id": "LOW-08",
    "title": "h3_varint_len Defined Multiple Times as Static",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `h3_varint_len` is defined as a static function in http3_request.c but also exists in http3_frame.c and http3_stream.c. Multiple static definitions of the same function across files increases binary size and maintenance burden.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HTTP3_STREAMS_AUDIT.md"
  },
  {
    "id": "LOW-09",
    "title": "tquic_stream_manager_destroy Does Not Free Extended State for All Streams",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** While `tquic_stream_ext_free(mgr, stream->ext)` is called during manager destruction, if `stream->ext` was set to a `tquic_priority_stream_ext` (from priority.c) instead of a `tquic_stream_ext` (from stream.c), the wrong free function is used. The two ext types are different structures stored in the same `stream->ext` pointer -- a type confusion issue.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HTTP3_STREAMS_AUDIT.md"
  },
  {
    "id": "CRIT-04-OTH",
    "title": "Adaptive Scheduler cwnd_avail Underflow",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** A congested path gets an artificially high CWND score, causing the adaptive scheduler to prefer sending traffic to the most congested path. This inverts the scheduling decision.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (path->cc.cwnd == 0)\n    cwnd_score = 0;\nelse {\n    cwnd_avail = path->cc.cwnd - path->cc.bytes_in_flight;  // u32 underflow!\n    cwnd_score = (cwnd_avail * 1000) / path->cc.cwnd;        // garbage\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The CWND availability score is computed as `cwnd_avail = path->cc.cwnd - path->cc.bytes_in_flight`. Both are `u32` fields. If `bytes_in_flight > cwnd` (which can happen during loss recovery when cwnd is reduced but inflight data hasn't been acknowledged), this is an unsigned underflow producing a very large value. The subsequent `cwnd_score = (cwnd_avail * 1000) / path->cc.cwnd` would then overflow.",
    "fix_suggestion": "** Check `if (path->cc.bytes_in_flight >= path->cc.cwnd) cwnd_score = 0;` before the subtraction.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_SCHEDULERS_AUDIT.md"
  },
  {
    "id": "CRIT-05-OTH",
    "title": "Adaptive Feedback Uses Path After list_for_each_entry Exit",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Reading `path_id` from the list head reads from an arbitrary offset in `struct tquic_int_connection`, returning garbage. If the garbage happens to match `fb->path_id`, the function continues with a corrupt pointer, potentially writing to arbitrary memory via the subsequent `tquic_update_rtt()` and `path->cc.*` assignments.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "list_for_each_entry_rcu(path, &conn->paths, list) {\n    if (path->path_id == fb->path_id)\n        break;\n    path_idx++;\n}\n\nif (path->path_id != fb->path_id) {  // path may be &conn->paths (list head)!\n    rcu_read_unlock();\n    return;\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** After `list_for_each_entry_rcu()` exits (either by finding the path or exhausting the list), the code checks `if (path->path_id != fb->path_id)`. However, when the list is exhausted, `path` points to the list head (cast to `struct tquic_path *`), not a valid path. Dereferencing `path->path_id` on the list head is an out-of-bounds read.",
    "fix_suggestion": "** Use a separate flag variable to track whether the path was found, or use `list_for_each_entry_rcu()` with a found flag check.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_SCHEDULERS_AUDIT.md"
  },
  {
    "id": "HIGH-07-OTH",
    "title": "TPROXY Capability Check Logic Inversion",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Unprivileged users can request TPROXY mode and get a working (non-TPROXY) tunnel without any error, potentially bypassing intended access controls. The capability check should happen before the setsockopt attempt.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (is_tproxy) {\n    val = 1;\n    err = tquic_kernel_setsockopt(sock, SOL_IP, IP_TRANSPARENT,\n                                  &val, sizeof(val));\n    if (err < 0) {\n        if (capable(CAP_NET_ADMIN)) {\n            /* Has caps but setsockopt failed -> error */\n            tquic_err(\"IP_TRANSPARENT failed despite CAP_NET_ADMIN: %d\\n\", err);\n            sock_release(sock);\n            return err;\n        }\n        /* No caps -> silent fallback to non-TPROXY */\n        tquic_info(\"IP_TRANSPARENT requires CAP_NET_ADMIN, using normal mode\\n\");\n        tunnel->is_tproxy = false;\n    }\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The TPROXY code path first attempts to set `IP_TRANSPARENT` via `setsockopt`, and only after it fails does it check `capable(CAP_NET_ADMIN)`. The logic is inverted: if the process has `CAP_NET_ADMIN` but `setsockopt` fails for another reason (e.g., kernel config), the socket is released and an error is returned. If the process does NOT have `CAP_NET_ADMIN`, the code silently falls back to non-TPROXY mode. This means an unprivileged process can request TPROXY and get a degraded-but-working tunnel, while a privileged process gets an error.\n\n**Code (tquic_tunnel.c:363-383):**\n```c\nif (is_tproxy) {\n    val = 1;\n    err = tquic_kernel_setsockopt(sock, SOL_IP, IP_TRANSPARENT,\n                                  &val, sizeof(val));\n    if (err < 0) {\n        if (capable(CAP_NET_ADMIN)) {\n            /* Has caps but setsockopt failed -> error */\n            tquic_err(\"IP_TRANSPARENT failed despite CAP_NET_ADMIN: %d\\n\", err);\n            sock_release(sock);\n            return err;\n        }\n        /* No caps -> silent fallback to non-TPROXY */\n        tquic_info(\"IP_TRANSPARENT requires CAP_NET_ADMIN, using normal mode\\n\");\n        tunnel->is_tproxy = false;\n    }\n}\n```",
    "fix_suggestion": "** Check `capable(CAP_NET_ADMIN)` first. If the caller lacks the capability, return `-EPERM` immediately rather than silently degrading.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_MASQUE_TUNNEL_AUDIT.md"
  },
  {
    "id": "HIGH-08-OTH",
    "title": "`tquic_recvmsg()` Same Issue as HIGH-07",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** Same pattern -- `tsk->conn` accessed without lock, used throughout without serialization against close.\n\n---",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_SOCKET_NETLINK_MIGRATION_AUDIT.md"
  },
  {
    "id": "HIGH-09-OTH",
    "title": "`tquic_poll()` Can Report Stale State After Close",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** EPOLL returns wrong result, or kernel crash on freed stream.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** While `READ_ONCE()` is used for `conn` and `stream`, the poll function accesses `stream->recv_buf` and `conn->datagram.recv_queue` without any locking. The `skb_queue_empty()` check races with dequeue operations in recvmsg. More critically, the `default_stream` could be freed between the `READ_ONCE()` and the `skb_queue_empty()` access.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_SOCKET_NETLINK_MIGRATION_AUDIT.md"
  },
  {
    "id": "MED-08-OTH",
    "title": "Stateless Reset Static Key Accessible via `tquic_stateless_reset_get_static_key()` Export",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** A malicious kernel module can forge stateless reset packets to terminate any TQUIC connection.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "const u8 *tquic_stateless_reset_get_static_key(void)\n{\n    if (!global_ctx_initialized)\n        return NULL;\n\n    return global_reset_ctx.static_key;\n}\nEXPORT_SYMBOL_GPL(tquic_stateless_reset_get_static_key);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The static key used for stateless reset token generation is exposed via an exported symbol that returns a direct pointer to the key material. Any other kernel module (loaded with GPL license) can read this key and forge stateless reset tokens for any connection.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_SOCKET_NETLINK_MIGRATION_AUDIT.md"
  },
  {
    "id": "MED-09-OTH",
    "title": "HMAC Transform Allocated Per-Token in `tquic_stateless_reset_generate_token()`",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Performance degradation and functional regression under memory pressure. Not a direct security vulnerability but defense-in-depth concern.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** Every call to `tquic_stateless_reset_generate_token()` allocates a new `crypto_alloc_shash(\"hmac(sha256)\")` and a descriptor, then frees them. This is called from `tquic_cid_issue()` which runs under BH spinlock (the descriptor allocation uses `GFP_ATOMIC`). This is extremely expensive for a hot path and could fail under memory pressure, falling back to `get_random_bytes()` which generates non-deterministic tokens (breaking stateless reset).",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_SOCKET_NETLINK_MIGRATION_AUDIT.md"
  },
  {
    "id": "OBS-01",
    "title": "Three Parallel Scheduler Frameworks",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_SCHEDULERS_AUDIT.md"
  },
  {
    "id": "OBS-02",
    "title": "Inconsistent Congestion State Layouts",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_SCHEDULERS_AUDIT.md"
  },
  {
    "id": "C-1",
    "title": "GSO SKB Allocation Multiplication Overflow",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Heap buffer overflow in kernel. If `max_segs` is attacker-influenced (e.g., via setsockopt or negotiated parameter), this is exploitable for kernel code execution.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "gso->gso_skb = alloc_skb(gso->gso_size * max_segs + MAX_HEADER, GFP_ATOMIC);",
        "size_t alloc_size;\nif (check_mul_overflow((size_t)gso->gso_size, (size_t)max_segs, &alloc_size) ||\n    check_add_overflow(alloc_size, (size_t)MAX_HEADER, &alloc_size))\n    return -EOVERFLOW;\ngso->gso_skb = alloc_skb(alloc_size, GFP_ATOMIC);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `gso->gso_size` is derived from `path->mtu - 48` (u16, max ~65487) and `max_segs` is u16. The multiplication `gso->gso_size * max_segs` is performed in `unsigned int` (32-bit) arithmetic. If `max_segs` is large enough (e.g., 65535), the product `65487 * 65535 = 4,291,493,345` overflows u32 (max 4,294,967,295 -- this particular example barely fits, but values above ~65536 for max_segs would wrap). More critically, adding `MAX_HEADER` could push the result past u32 max, causing a small allocation. Subsequent `skb_put_data` writes would overflow the undersized buffer.",
    "fix_suggestion": "** Use `check_mul_overflow` and `check_add_overflow`:\n```c\nsize_t alloc_size;\nif (check_mul_overflow((size_t)gso->gso_size, (size_t)max_segs, &alloc_size) ||\n    check_add_overflow(alloc_size, (size_t)MAX_HEADER, &alloc_size))\n    return -EOVERFLOW;\ngso->gso_skb = alloc_skb(alloc_size, GFP_ATOMIC);\n```\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_INTEGER_OVERFLOW_AUDIT.md"
  },
  {
    "id": "C-2",
    "title": "Capsule Buffer Size Addition Overflow",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Heap buffer overflow leading to kernel memory corruption. Exploitable if capsule data originates from a peer-controlled MASQUE proxy session.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "buf_len = CAPSULE_MAX_HEADER_SIZE + cap->length;      /* line 850 */\nbuf_len = CAPSULE_MAX_HEADER_SIZE + payload_len;       /* line 894 */",
        "if (cap->length > SIZE_MAX - CAPSULE_MAX_HEADER_SIZE)\n    return -EOVERFLOW;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `cap->length` and `payload_len` are `size_t`. If either is close to `SIZE_MAX`, the addition wraps to a small value. `kmalloc` then allocates a tiny buffer, and subsequent `capsule_encode` writes past the allocation.",
    "fix_suggestion": "** Add overflow check:\n```c\nif (cap->length > SIZE_MAX - CAPSULE_MAX_HEADER_SIZE)\n    return -EOVERFLOW;\n```\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_INTEGER_OVERFLOW_AUDIT.md"
  },
  {
    "id": "C-3",
    "title": "Transcript Buffer Reallocation Doubling Overflow",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Heap buffer overflow during TLS handshake. An attacker sending large handshake messages could trigger this.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "u32 new_alloc = max(new_len * 2, 4096U);",
        "u32 new_alloc;\nif (check_mul_overflow(new_len, 2U, &new_alloc))\n    new_alloc = TQUIC_MAX_TRANSCRIPT_SIZE;\nnew_alloc = max(new_alloc, 4096U);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** While `new_len` is checked for overflow at line 842 (`new_len < hs->transcript_len`), the doubling `new_len * 2` on line 849 can overflow u32. If `new_len` is 2,147,483,648 (2^31) or greater (and `TQUIC_MAX_TRANSCRIPT_SIZE` permits it), `new_len * 2` wraps to a small value. `krealloc` allocates a small buffer, and the subsequent `memcpy` at line 859 writes `len` bytes past the allocation.",
    "fix_suggestion": "** Use `check_mul_overflow` or cap `new_alloc` more conservatively:\n```c\nu32 new_alloc;\nif (check_mul_overflow(new_len, 2U, &new_alloc))\n    new_alloc = TQUIC_MAX_TRANSCRIPT_SIZE;\nnew_alloc = max(new_alloc, 4096U);\n```\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_INTEGER_OVERFLOW_AUDIT.md"
  },
  {
    "id": "C-4",
    "title": "Rate Calculation Integer Overflow (`count * 1000`)",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Rate limiter bypass under DDoS conditions. The system fails to limit connections precisely when it most needs to.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "count = atomic_xchg(&state->rate_window_count, 0);\nrate = (count * 1000) / elapsed_ms;",
        "count = atomic_xchg(&state->rate_window_count, 0);\nrate = (count * 1000) / elapsed_ms;",
        "rate = (u64)count * 1000 / elapsed_ms;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `count` is `int` (from `atomic_xchg`). `count * 1000` overflows `int` when `count > 2,147,483` (~2.1M). Under a flood attack, receiving millions of packets in one rate window is realistic. The overflow produces a negative or small positive value, causing the rate limiter to **underestimate the actual rate** and fail to activate protection.",
    "fix_suggestion": "** Cast to `u64` before multiplication:\n```c\nrate = (u64)count * 1000 / elapsed_ms;\n```",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_INTEGER_OVERFLOW_AUDIT.md"
  },
  {
    "id": "H-1",
    "title": "PTO Duration Exponential Shift Overflow",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Undefined behavior leading to unpredictable timer values. Could cause timers to fire immediately (triggering excessive retransmissions) or never fire (connection hangs).",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "pto_duration *= (1 << rs->pto_count);",
        "u32 shift = min_t(u32, rs->pto_count, 30);\npto_duration *= (1ULL << shift);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `1 << rs->pto_count` is `int` arithmetic. If `pto_count >= 31`, this is **undefined behavior** (shifting a signed 1 by >= 31). If `pto_count >= 32`, UB on all platforms. `pto_count` is typically bounded but the bound must be verified. Even with `pto_count = 30`, the result is `1073741824`, and multiplied by a `pto_duration` of ~1000000 (1s RTT), the product exceeds u64 max at high counts.",
    "fix_suggestion": "**\n```c\nu32 shift = min_t(u32, rs->pto_count, 30);\npto_duration *= (1ULL << shift);\n```\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_INTEGER_OVERFLOW_AUDIT.md"
  },
  {
    "id": "H-2",
    "title": "Prague Congestion Control: `ecn_ce_count * mss` Overflow",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Congestion control bypass. An attacker spoofing ECN counts could manipulate the peer's sending rate.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "ce_bytes = ecn_ce_count * mss;",
        "ecn_ce_count = min_t(u64, ecn_ce_count, U32_MAX);\nce_bytes = ecn_ce_count * mss;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** Both `ecn_ce_count` (u64 from varint) and `mss` (u32) are multiplied. If `ecn_ce_count` is a large varint value (attacker-controlled from ACK-ECN frame), the multiplication overflows u64 when `ecn_ce_count > U64_MAX / mss`. Result: `ce_bytes` wraps to a small value, causing Prague to under-respond to congestion -- the attacker continues sending at high rate despite network congestion.",
    "fix_suggestion": "** Clamp `ecn_ce_count` to a reasonable maximum before multiplication:\n```c\necn_ce_count = min_t(u64, ecn_ce_count, U32_MAX);\nce_bytes = ecn_ce_count * mss;\n```\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_INTEGER_OVERFLOW_AUDIT.md"
  },
  {
    "id": "H-3",
    "title": "BBRv2 Inflight Calculation Truncation",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Performance degradation on high-BDP paths (>4GB BDP). Not a security vulnerability per se, but violates protocol semantics.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "inflight = bbr_bdp(bbr);\ninflight = (inflight * gain) >> BBR_SCALE;\nreturn max((u32)inflight, (u32)(BBR_MIN_CWND * mss));",
        "return (u32)min_t(u64, inflight, U32_MAX);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `inflight * gain` is u64 arithmetic, which is safe from overflow. However, the result is then cast to `u32` on the return. If the BDP is large (e.g., 10 Gbps * 100ms = 125MB = 125,000,000 bytes), and gain is > 1x, the u32 cast truncates to ~4GB max. On high-BDP paths, this limits BBR's congestion window to 4GB regardless of actual BDP, potentially degrading performance.",
    "fix_suggestion": "** Return `u64` or `u32` with saturation:\n```c\nreturn (u32)min_t(u64, inflight, U32_MAX);\n```\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_INTEGER_OVERFLOW_AUDIT.md"
  },
  {
    "id": "H-4",
    "title": "FEC Scheduler Loss Rate Overflow",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** FEC under-protection during high-loss periods, or excessive FEC overhead from wrapped-around values.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "new_rate = (sched->loss_count * 1000) / sched->packet_count;",
        "new_rate = (u32)((u64)sched->loss_count * 1000 / sched->packet_count);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `sched->loss_count` is `u32`. `loss_count * 1000` overflows u32 when `loss_count > 4,294,967` (~4.3M). This would produce an incorrect (wrapped) loss rate, causing the FEC scheduler to compute wrong repair symbol counts.",
    "fix_suggestion": "**\n```c\nnew_rate = (u32)((u64)sched->loss_count * 1000 / sched->packet_count);\n```\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_INTEGER_OVERFLOW_AUDIT.md"
  },
  {
    "id": "H-5",
    "title": "FEC Repair Count Computation: `block_size * target_fec_rate` Truncation",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Incorrect FEC repair count, either too few (data loss) or too many (bandwidth waste).",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "repair_count = ((u32)block_size * sched->target_fec_rate + 99) / 100;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `block_size` is `u8` (max 255), `target_fec_rate` is `u32`. The product `255 * target_fec_rate` overflows u32 if `target_fec_rate > 16,843,009`. While `target_fec_rate` is supposed to be a percentage, there is no validation that it stays within [0, 100]. An improperly configured or corrupted value could trigger overflow.",
    "fix_suggestion": "** Validate `target_fec_rate <= 100` before this calculation.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_INTEGER_OVERFLOW_AUDIT.md"
  },
  {
    "id": "H-6",
    "title": "`quic_offload.c` Version Field Shift Without Cast",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Incorrect version number parsing. A crafted packet with version byte >= 0x80 in the high byte could bypass version checks or cause Version Negotiation to fail.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "version = (data[1] << 24) | (data[2] << 16) | (data[3] << 8) | data[4];",
        "version = ((u32)data[1] << 24) | ((u32)data[2] << 16) |\n          ((u32)data[3] << 8) | data[4];"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `data[1]` is `u8`, promoted to `int` (signed, 32-bit). `data[1] << 24` is fine for values 0-127, but when `data[1] >= 128`, the shift sets the sign bit of the `int`, producing a **negative value**. The OR then sign-extends it, corrupting the version field. This is technically **undefined behavior** in C when shifting into the sign bit of a signed type (pre-C23).",
    "fix_suggestion": "** Cast to `u32` before shift:\n```c\nversion = ((u32)data[1] << 24) | ((u32)data[2] << 16) |\n          ((u32)data[3] << 8) | data[4];\n```",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_INTEGER_OVERFLOW_AUDIT.md"
  },
  {
    "id": "M-1",
    "title": "Potential 32-bit Truncation in Stream Frame `alloc_skb`",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "data_skb = alloc_skb(length, GFP_ATOMIC);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `length` is `u64` (from varint decode). It is checked against 65535 at line 909, which bounds it to fit in `unsigned int` (the `alloc_skb` parameter type). However, the check `if (length > 65535)` at line 909 uses implicit comparison between u64 and int. This is safe, but fragile -- if the limit is ever increased past U32_MAX without updating the type, the truncation would cause undersized allocation.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_INTEGER_OVERFLOW_AUDIT.md"
  },
  {
    "id": "M-2",
    "title": "`tquic_proc.c` Buffer Overflow in Hex CID Formatting",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "for (i = 0; i < scid_len; i++)\n    sprintf(&scid_hex[i * 2], \"%02x\", conn->scid.id[i]);\nscid_hex[scid_len * 2] = '\\0';"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `scid_len` is bounded by `min_t(int, conn->scid.len, TQUIC_MAX_CID_LEN)` at line 414 (max 20). So `scid_len * 2` is max 40. If `scid_hex` is declared as `char scid_hex[42]` or larger, this is safe. However, the `scid_len * 2` multiplication pattern is an `int` multiplication -- if `TQUIC_MAX_CID_LEN` were ever increased significantly, `i * 2` could overflow `int`. The same pattern appears at line 604 and in `tquic_debug.c` lines 207, 216.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_INTEGER_OVERFLOW_AUDIT.md"
  },
  {
    "id": "M-3",
    "title": "`tquic_cong.c` ECN Byte Calculation Overflow",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Incorrect ECN byte estimation, potentially affecting congestion response.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "u64 ecn_bytes = ecn_ce_count * 1200;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `ecn_ce_count` is `u64` from varint decode (attacker-controlled). If `ecn_ce_count > U64_MAX / 1200 = 15,372,286,728,091,293`, the multiplication wraps. This is an extremely large value but is technically reachable via an 8-byte varint.",
    "fix_suggestion": "** Clamp `ecn_ce_count` to a realistic maximum before multiplication.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_INTEGER_OVERFLOW_AUDIT.md"
  },
  {
    "id": "M-4",
    "title": "`quic_packet.c` ACK Range Count Estimation Overflow",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "estimated_min_bytes = (1 + ack_range_count * 2);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `ack_range_count` is bounded to 255 at line 1248, so `ack_range_count * 2 = 510`, and `1 + 510 = 511`. This is safe. The `u64 * int` promotion is also safe. Good existing bound check.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_INTEGER_OVERFLOW_AUDIT.md"
  },
  {
    "id": "M-5",
    "title": "`transport_params.c` Memcpy with `count * sizeof(u32)` Without Overflow Check",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "memcpy(params->version_info->available_versions, available,\n       count * sizeof(u32));"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `count` is `size_t`, bounded by `TQUIC_MAX_AVAILABLE_VERSIONS` at line 2513. If `TQUIC_MAX_AVAILABLE_VERSIONS` is a reasonable constant (e.g., 16), `count * sizeof(u32)` cannot overflow. However, no `check_mul_overflow` is used.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_INTEGER_OVERFLOW_AUDIT.md"
  },
  {
    "id": "M-6",
    "title": "Pacing Rate Division by Potentially Small Value",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "gap_ns = (u64)pkt_size * NSEC_PER_SEC / pacing->pacing_rate;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `pacing_rate` is checked for zero at line 1356. The multiplication `(u64)pkt_size * NSEC_PER_SEC` could overflow u64 if `pkt_size` is very large (>18 exabytes / 10^9 -- impossible for a packet size). Safe in practice.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_INTEGER_OVERFLOW_AUDIT.md"
  },
  {
    "id": "M-7",
    "title": "Signed/Unsigned Mismatch in Scheduler Queue Delay",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "u64 queue_delay = (skb->len * path->stats.rtt_smoothed) /"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `skb->len` is `unsigned int`, `rtt_smoothed` is likely `u64`. The multiplication is promoted to u64. No overflow concern for realistic packet sizes and RTTs.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_INTEGER_OVERFLOW_AUDIT.md"
  },
  {
    "id": "M-8",
    "title": "`bbrv3.c` CE Ratio Potential Division by Zero",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Potential divide-by-zero crash or incorrect ratio from overflow.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "ce_ratio = (ce_count * 100) / (bbr->ecn_ect_count + ce_count);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** If both `ecn_ect_count` and `ce_count` are zero, this divides by zero. However, the code path likely only executes when `ce_count > 0` (from the surrounding logic). The `ce_count * 100` could overflow u32 if `ce_count > 42,949,672`.",
    "fix_suggestion": "** Check denominator and use u64 for multiplication.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_INTEGER_OVERFLOW_AUDIT.md"
  },
  {
    "id": "M-9",
    "title": "`http3_frame.c` Settings Frame Parser: No Bounds on `count`",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "while (p->buf < end && count < max_entries) {\n    ...\n    entries_buf[count].id = id;\n    entries_buf[count].value = value;\n    count++;\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `count` is bounded by `max_entries`, which is the caller's buffer size. If the caller passes an incorrect `max_entries` larger than the actual buffer, this would overflow `entries_buf`. The parser itself is correct; the risk is in the caller contract.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_INTEGER_OVERFLOW_AUDIT.md"
  },
  {
    "id": "L-1",
    "title": "Multiple Varint Implementations (Code Duplication Risk)",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** There are at least **10 separate implementations** of QUIC varint encode/decode. Each is a potential source of inconsistency. If a bug is found in one, it may not be fixed in all copies. All implementations reviewed appear correct, but this level of duplication is a maintenance hazard.",
    "fix_suggestion": "** Consolidate to the single canonical implementation in `core/varint.c` and export symbols for all callers.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_INTEGER_OVERFLOW_AUDIT.md"
  },
  {
    "id": "L-2",
    "title": "`tquic_debug.c` CID Hex Loop Bound",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "for (i = conn->scid.len * 2; i < 34; i++)"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `conn->scid.len` is u8 (max 255). `255 * 2 = 510`, far exceeding 34, so the loop body never executes. However, if `scid.len > 17`, the hex output prior to this loop would overflow the fixed-size buffer being padded. Verify that the destination buffer is at least `TQUIC_MAX_CID_LEN * 2 + 1 = 41` bytes.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_INTEGER_OVERFLOW_AUDIT.md"
  },
  {
    "id": "L-3",
    "title": "Stream ID Right-Shift Comparison",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if ((next_id >> 2) < max_streams)"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `next_id` is u64. Right-shifting by 2 is safe and produces a value in range [0, 2^60). This is the correct QUIC stream ID to stream count conversion. No issue.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_INTEGER_OVERFLOW_AUDIT.md"
  },
  {
    "id": "L-4",
    "title": "`bench_common.c` Variance Calculation (Userspace Code)",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "double variance = (s->sum_sq - s->count * mean * mean) / (s->count - 1);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** This is benchmark/test code, not kernel code. Floating point issues (NaN from division by zero when `count == 1`, negative variance from floating-point imprecision) are possible but not security-relevant.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_INTEGER_OVERFLOW_AUDIT.md"
  },
  {
    "id": "L-5",
    "title": "`bench_latency.c` Allocation Without Overflow Check (Userspace Code)",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "** Medium. Incorrect flag interpretation could enable/disable optional features incorrectly.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "double *rtt_us = malloc(state->sample_count * sizeof(double));",
        "ret = tquic_decode_varint(ctx->data + ctx->offset,\n                          ctx->len - ctx->offset, &value);",
        "data->flags = (u8)val;      /* line 260 - val is u64 from varint */\ndata->loss_rate = (u32)val;  /* line 276 - val is u64 from varint */",
        "if (val > U8_MAX)\n    return -EINVAL;\ndata->flags = (u8)val;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `sample_count * sizeof(double)` can overflow `size_t` on 32-bit systems for very large sample counts. However, this is userspace benchmark code.",
    "fix_suggestion": "** Validate before truncation:\n```c\nif (val > U8_MAX)\n    return -EINVAL;\ndata->flags = (u8)val;\n```",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_INTEGER_OVERFLOW_AUDIT.md"
  },
  {
    "id": "C1",
    "title": "QPACK Dynamic Table Duplicate: Use-After-Free via Lock Drop",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** An attacker who can trigger concurrent QPACK encoder instruction processing (e.g., via multiple streams referencing the same dynamic table) can cause kernel memory corruption, leading to privilege escalation or denial of service.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `qpack_dynamic_table_duplicate()` looks up a source entry pointer under the table spinlock, then drops the lock to perform a `kmalloc(GFP_KERNEL)` allocation, then re-acquires the lock and uses the original source pointer. Between the lock drop and re-acquisition, another thread can evict the source entry from the dynamic table, freeing it. The subsequent `memcpy` from the stale pointer is a use-after-free.",
    "fix_suggestion": "** Either (a) increment the entry's refcount before dropping the lock, or (b) copy the name/value data into a local buffer before dropping the lock, or (c) use `GFP_ATOMIC` allocation under the lock (acceptable for small allocations).",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_HTTP3_MISC.md"
  },
  {
    "id": "C2",
    "title": "HTTP/3 Stream Lookup: Use-After-Free (No Refcount)",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Remote attacker can trigger this by rapidly opening and closing streams while sending frames that reference those streams. Results in use-after-free, potential code execution.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `h3_stream_lookup()` returns a raw pointer to an `h3_stream` without incrementing its reference count. Callers use this pointer outside the lock that protected the lookup. If another thread closes/destroys the stream concurrently, the caller dereferences freed memory.",
    "fix_suggestion": "** Add `refcount_inc(&stream->refcount)` in `h3_stream_lookup()` and require all callers to call a corresponding `h3_stream_put()` when done.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_HTTP3_MISC.md"
  },
  {
    "id": "C3",
    "title": "Connection Destroy Calls Sleeping Function Under Spinlock",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Kernel panic (BUG) during connection teardown, causing denial of service. Easily triggered by any connection close.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `h3_connection_destroy()` iterates over streams under a spinlock and calls `tquic_stream_close()` for each. `tquic_stream_close()` may invoke allocation paths with `GFP_KERNEL` (sleeping allocation) or other sleeping operations. Calling a potentially-sleeping function under a spinlock causes a BUG on kernels with `CONFIG_DEBUG_ATOMIC_SLEEP`.",
    "fix_suggestion": "** Collect stream pointers into a local list under the spinlock, release the spinlock, then close each stream outside the lock.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_HTTP3_MISC.md"
  },
  {
    "id": "C4",
    "title": "Path Metrics Netlink: Unbounded Allocation from Attacker-Influenced Value",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Local denial of service via repeated large kernel allocations. If `num_paths` validation is ever bypassed, attacker-controlled allocation size.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The function allocates `nlmsg_new(NLMSG_DEFAULT_SIZE * conn->num_paths, GFP_KERNEL)`. `conn->num_paths` is influenced by the number of paths on a connection (up to `TQUIC_MAX_PATHS` = 16, but the multiplication with `NLMSG_DEFAULT_SIZE` (typically 8192) can be up to 128KB). While `TQUIC_MAX_PATHS=16` provides some bound, if `num_paths` is ever corrupted or the limit is raised, this becomes an unbounded allocation. More importantly, any unprivileged user can trigger this allocation (see H1).",
    "fix_suggestion": "** Cap the allocation at a fixed reasonable maximum (e.g., `min(conn->num_paths, TQUIC_MAX_PATHS) * NLMSG_DEFAULT_SIZE`), and add the CAP_NET_ADMIN check from H1.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_HTTP3_MISC.md"
  },
  {
    "id": "H1",
    "title": "Path Metrics Netlink: Missing CAP_NET_ADMIN Permission Check",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Information disclosure of network connection metadata (RTT, bandwidth, loss rates, connection IDs, peer addresses) to unprivileged users. Subscription flooding can also cause kernel memory exhaustion.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The genetlink operations for path metrics export (`tquic_nl_get_path_metrics`, `tquic_nl_get_all_paths`, `tquic_nl_subscribe_events`) do not require `CAP_NET_ADMIN`. Any unprivileged local user can query connection metrics, subscribe to events, and enumerate all TQUIC connections.",
    "fix_suggestion": "** Add `.policy` with `GENL_ADMIN_PERM` flag or explicit `CAP_NET_ADMIN` check in each handler.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_HTTP3_MISC.md"
  },
  {
    "id": "H2",
    "title": "QPACK Decoder: Unbounded Blocked Stream Memory Exhaustion",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Remote attacker can exhaust kernel memory by sending many large header blocks that all reference high insert counts. With `max_blocked_streams=100` and headers up to the frame size limit, this could consume hundreds of megabytes.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** When a header block references a dynamic table entry that has not yet been received (insert count > known received count), the decoder stores the entire header block data via `kmemdup(data, len, GFP_ATOMIC)`. While there is a `max_blocked_streams` limit on the count of blocked streams, there is no limit on the total memory consumed by blocked stream data. An attacker can send large header blocks (up to the maximum allowed) on each blocked stream.",
    "fix_suggestion": "** Track total blocked stream memory and enforce a per-connection limit (e.g., 1MB total blocked stream data).",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_HTTP3_MISC.md"
  },
  {
    "id": "H3",
    "title": "WebTransport Context Destroy: Lock Drop During Iteration",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Kernel memory corruption during WebTransport session teardown, triggerable by a remote peer closing sessions concurrently.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** During WebTransport context destruction, the function iterates over sessions and drops/re-acquires the lock for cleanup operations. This creates a window where the session list can be modified by concurrent operations, potentially causing list corruption or use-after-free of the iteration cursor.",
    "fix_suggestion": "** Use a safe iteration pattern: move items to a local list under the lock, release the lock, then process the local list.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_HTTP3_MISC.md"
  },
  {
    "id": "H4",
    "title": "WebTransport: Unbounded Capsule Buffer Growth",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Remote denial of service via kernel memory exhaustion.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The capsule parsing code accumulates incoming capsule data into `capsule_buf` without enforcing a maximum total size. A remote peer can send an arbitrarily large capsule (or many partial capsules) to exhaust kernel memory.",
    "fix_suggestion": "** Enforce a maximum capsule buffer size (e.g., 64KB or configurable via socket option) and reject connections that exceed it with `H3_EXCESSIVE_LOAD`.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_HTTP3_MISC.md"
  },
  {
    "id": "H5",
    "title": "HTTP/3 Settings Frame Length Truncation",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Protocol confusion: the truncated length causes the peer to misparse the stream, potentially leading to security-relevant misinterpretation of subsequent frames. While 255 bytes is sufficient for typical settings, extensions or future settings could exceed this.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The settings frame length is cast to `u8`: `*len_pos = (u8)settings_len;`. If the total settings payload exceeds 255 bytes, the length field is silently truncated. The peer will parse an incomplete settings frame, potentially interpreting subsequent data as a new frame.",
    "fix_suggestion": "** Use proper QUIC variable-length integer encoding for the frame length, or validate that `settings_len <= 255` before the cast and return an error if exceeded.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_HTTP3_MISC.md"
  },
  {
    "id": "H6",
    "title": "QPACK Encoder: Insert Count Increment Overflow",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** The encoder may reference non-existent dynamic table entries, causing the decoder to fail or reference wrong entries. This could lead to header injection if the wrong entry is referenced.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The Insert Count Increment instruction handler adds the received value to `known_received_count` without overflow checking: `known_received_count += value;`. An attacker can send a crafted increment value that wraps the counter, causing the encoder to believe the decoder has received entries that do not exist.",
    "fix_suggestion": "** Validate that `known_received_count + value <= insert_count` (the total entries ever inserted) and that the addition does not overflow.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_HTTP3_MISC.md"
  },
  {
    "id": "H7",
    "title": "HTTP/3 Request: TOCTOU Between State Check and Send",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Protocol violation, potential data corruption or crash if send operates on a closed/reset stream.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The function checks the stream state under a lock, releases the lock, then performs the actual send operation without the lock. Between the check and the send, another thread can change the stream state (e.g., close the stream), causing the send to operate on a stream in an invalid state.",
    "fix_suggestion": "** Either hold the lock during the entire send operation, or re-validate state after acquiring any needed resources.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_HTTP3_MISC.md"
  },
  {
    "id": "M1",
    "title": "HTTP/3 Frame Parsing: 16MB Maximum Frame Payload",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** A remote attacker can trigger large kernel allocations by sending frames with large payload lengths.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `H3_MAX_FRAME_PAYLOAD_SIZE` is set to 16MB. While this is a valid limit, it means a single frame can cause a 16MB kernel allocation. Under memory pressure, this is significant.",
    "fix_suggestion": "** Consider reducing the default limit to 1MB or making it configurable. Most HTTP/3 frames (HEADERS, SETTINGS, GOAWAY) should be much smaller.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_HTTP3_MISC.md"
  },
  {
    "id": "M2",
    "title": "QPACK Huffman Decoder: O(n*256) Complexity",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** CPU exhaustion: an attacker can send Huffman-encoded headers that maximize decoding time. With large headers, this becomes a practical slowloris-style attack.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The Huffman decoder uses a brute-force O(n * 256) algorithm that iterates over all 256 possible symbols for each input byte. This is significantly slower than a proper lookup-table or tree-based decoder.",
    "fix_suggestion": "** Replace with a 256-entry lookup table or state-machine-based decoder (standard approach for HPACK/QPACK Huffman).",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_HTTP3_MISC.md"
  },
  {
    "id": "M3",
    "title": "QPACK Integer Decode: Shift Overflow",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Undefined behavior (implementation-defined on most architectures) that could produce incorrect values, leading to buffer overflows or other memory safety issues.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The QPACK integer decode loop accumulates `value |= (byte & 0x7f) << shift` and increments `shift` by 7 each iteration. If the input contains many continuation bytes, `shift` can exceed 63, causing undefined behavior for the left shift on a `u64`.",
    "fix_suggestion": "** Add a check: `if (shift > 62) return -H3_ERR_QPACK_DECOMPRESSION_FAILED;`",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_HTTP3_MISC.md"
  },
  {
    "id": "M4",
    "title": "QPACK Encoder/Decoder: Excessive Stack Usage",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Stack overflow if these functions are called from a deep call chain (e.g., interrupt context -> softirq -> QUIC receive -> QPACK decode). Results in kernel panic.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** Multiple functions allocate large buffers on the stack:\n  - `qpack_decoder`: `name_buf[256]` + `value_buf[8192]` = 8448 bytes\n  - `qpack_encoder_insert_name_ref()`: `buf[QPACK_MAX_HEADER_VALUE_LEN + 32]` = 8224 bytes\n  - `qpack_encoder_insert_literal()`: `buf[8512]` = 8512 bytes\n\n  Kernel stack is typically 8KB-16KB. These allocations consume most of the available stack, leaving very little for called functions.",
    "fix_suggestion": "** Allocate these buffers dynamically with `kmalloc(GFP_ATOMIC)` or use a pre-allocated per-connection buffer.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_HTTP3_MISC.md"
  },
  {
    "id": "M5",
    "title": "HTTP/3 Settings Parser: TOCTOU on Settings Count",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** If the buffer is shared, settings could be double-processed or skipped, potentially leading to protocol confusion.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The settings parser checks the count/length of settings, then processes them in a separate pass. If the underlying data can change between the check and the processing (e.g., if the buffer is shared), this is a TOCTOU vulnerability. In practice, this depends on whether the input buffer is guaranteed to be stable.",
    "fix_suggestion": "** Ensure the input buffer is exclusively owned during parsing, or perform length validation inline during the single-pass parse.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_HTTP3_MISC.md"
  },
  {
    "id": "M6",
    "title": "HTTP/3 Connection: O(n) Push Entry Counting",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** CPU exhaustion for servers processing many push promises from a malicious client (or vice versa).",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The connection counts push entries by iterating the entire push list on each operation, resulting in O(n) complexity. An attacker can create many push promises to make subsequent operations slow.",
    "fix_suggestion": "** Maintain a running counter of push entries instead of counting on demand.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_HTTP3_MISC.md"
  },
  {
    "id": "M7",
    "title": "WebTransport: TOCTOU in Datagram Queue Push",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Queue size limit bypass, potentially leading to memory exhaustion if the limit is the only defense against unbounded growth.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The datagram queue checks its current size, then pushes a new element. If two threads push concurrently, both may see the queue as under-limit and both push, exceeding the intended limit.",
    "fix_suggestion": "** Perform the size check and push atomically under a lock, or use an atomic counter with compare-and-swap.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_HTTP3_MISC.md"
  },
  {
    "id": "M8",
    "title": "Qlog Ring Buffer: Not Truly Lock-Free",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Performance degradation under high qlog event rates. Not a security vulnerability per se, but the misleading documentation could lead to incorrect assumptions about safety in interrupt context.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The qlog ring buffer is documented as lock-free but actually uses a spinlock for write operations. Under high event rates, this creates contention on the hot path.",
    "fix_suggestion": "** Either implement a true lock-free ring buffer (using `smp_store_release`/`smp_load_acquire` pairs) or document the locking requirement clearly.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_HTTP3_MISC.md"
  },
  {
    "id": "M9",
    "title": "Qlog: JSON Strings Not Escaped",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Malformed JSON output that could cause parsing failures in qlog consumers. If a qlog consumer naively processes the JSON (e.g., injecting into a web dashboard), this could be an XSS vector.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** When emitting JSON-formatted qlog events, string values (such as reason phrases from CONNECTION_CLOSE frames) are included without JSON escaping. If a reason phrase contains characters like `\"`, `\\`, or control characters, the resulting JSON is malformed.",
    "fix_suggestion": "** Implement JSON string escaping for all string values emitted in qlog JSON output.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_HTTP3_MISC.md"
  },
  {
    "id": "M10",
    "title": "Path Metrics Subscription: Timer/Connection Lifetime Race",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Use-after-free when the timer fires on a freed connection, causing kernel memory corruption.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** A metrics subscription timer can fire after the associated connection has been freed, if `tquic_metrics_unsubscribe_conn()` races with the timer callback. The timer callback accesses the connection pointer without verifying it is still valid.",
    "fix_suggestion": "** Use `del_timer_sync()` in `tquic_metrics_unsubscribe_conn()` to ensure the timer callback has completed before freeing the connection, or hold a connection reference in the subscription.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_HTTP3_MISC.md"
  },
  {
    "id": "L1",
    "title": "Duplicate Static Functions: h3_varint_encode/decode",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "** Maintenance risk; potential for divergent behavior if one copy is patched but not the other.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** Both files contain independent static implementations of varint encode/decode functions. If one is fixed for a bug and the other is not, inconsistent behavior results.",
    "fix_suggestion": "** Move to a shared helper (e.g., in `http3_frame.c` or a common header as inline functions).",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_HTTP3_MISC.md"
  },
  {
    "id": "L2",
    "title": "HTTP/3 Priority: push_buckets Not Initialized",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "** If the allocation path changes to use `kmalloc` instead of `kzalloc`, the array would contain garbage, leading to incorrect scheduling or null pointer dereferences.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The `push_buckets[]` array used for server push scheduling is not explicitly initialized in the priority scheduler initialization path. It relies on the structure being zeroed by `kzalloc`, which is correct but fragile.",
    "fix_suggestion": "** Explicitly initialize `push_buckets[]` in the priority init function for defensive coding.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_HTTP3_MISC.md"
  },
  {
    "id": "L3",
    "title": "Qlog: Lock Drop Around copy_to_user",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "** Userspace may receive a partially old/partially new event if the ring buffer wraps during the copy. This is a data integrity issue, not a security vulnerability.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The qlog read path drops the ring buffer lock before calling `copy_to_user()` (which may sleep). This is correct behavior (you cannot hold a spinlock across `copy_to_user`), but the entry being copied could be overwritten by a new event between the lock drop and the copy completion.",
    "fix_suggestion": "** Copy the entry to a local kernel buffer under the lock, then `copy_to_user` from the local buffer.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_HTTP3_MISC.md"
  },
  {
    "id": "L4",
    "title": "Benchmark Code: Userspace, Not Kernel",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "** No kernel security impact. The code is a test harness only.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The benchmark code in `net/tquic/bench/` is userspace code using libc functions (`printf`, `malloc`, `FILE *`, `math.h`). It does not run in kernel context and is not compiled as part of the kernel module.",
    "fix_suggestion": "** Consider moving benchmark code to a `tools/` or `tests/` directory to avoid confusion about its execution context.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_HTTP3_MISC.md"
  },
  {
    "id": "CRITICAL-1",
    "title": "List Iterator Invalidation in BPM Netdev Notifier (Drop-Relock Pattern)",
    "category": "concurrency",
    "severity": "S0",
    "confidence": "high",
    "impact": "After dropping `pm->lock` and calling `tquic_bpm_path_set_state()`, another thread could remove or free `path` from the list. When the lock is reacquired, the `list_for_each_entry` macro continues using `path->list.next` which may point to freed memory. This is a **use-after-free** that can be triggered by concurrent netdev events.\n\nThe same pattern repeats for `NETDEV_CHANGE` at lines 1876-1898 with TWO separate unlock/relock windows inside the inner loop.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "rcu_read_lock();\nlist_for_each_entry_rcu(pm, &tquic_bpm_list, path_list) {\n    spin_lock_bh(&pm->lock);\n    list_for_each_entry(path, &pm->path_list, list) {\n        if (path->ifindex == dev->ifindex &&\n            path->state != TQUIC_BPM_PATH_FAILED) {\n            spin_unlock_bh(&pm->lock);           // DROPPED\n            tquic_bpm_path_set_state(path, ...);  // path may be freed here\n            spin_lock_bh(&pm->lock);              // REACQUIRED\n            pm->paths_failed++;                    // list iteration continues!\n        }\n    }\n    spin_unlock_bh(&pm->lock);\n}\nrcu_read_unlock();"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "Use `list_for_each_entry_safe()` is NOT sufficient here since the iteration continues after relock. Instead, collect paths to process into a separate list under the lock, then process them after releasing the lock.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_LOCKING_AUDIT.md"
  },
  {
    "id": "CRITICAL-2",
    "title": "TOCTOU Race in Failover Hysteresis (Atomic Read-Modify-Write)",
    "category": "concurrency",
    "severity": "S0",
    "confidence": "high",
    "impact": "`READ_ONCE + 1 + WRITE_ONCE` is NOT atomic. Two concurrent timeout callbacks (from different timer expirations) could both read the same value and write the same incremented value, losing an increment. While individual increments being lost is not catastrophic, the combined pattern at lines 198-229 uses the result to make failover decisions:\n\n```c\nswitch (READ_ONCE(pt->hyst_state)) {        // Line 207\ncase TQUIC_PATH_HYST_DEGRADED:\n    if (READ_ONCE(pt->consec_failures) >= TQUIC_HYST_FAIL_THRESHOLD)\n        goto do_failover;                     // Line 230\n```\n\nBetween the READ_ONCE of `hyst_state` and the READ_ONCE of `consec_failures`, another thread could change both values. This can cause missed failovers or spurious failovers.\n\nSimilarly at line 688:\n```c\nWRITE_ONCE(pt->consec_successes, READ_ONCE(pt->consec_successes) + 1);\n```",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "WRITE_ONCE(pt->consec_failures, READ_ONCE(pt->consec_failures) + 1);\nWRITE_ONCE(pt->consec_successes, 0);",
        "switch (READ_ONCE(pt->hyst_state)) {        // Line 207\ncase TQUIC_PATH_HYST_DEGRADED:\n    if (READ_ONCE(pt->consec_failures) >= TQUIC_HYST_FAIL_THRESHOLD)\n        goto do_failover;                     // Line 230",
        "WRITE_ONCE(pt->consec_successes, READ_ONCE(pt->consec_successes) + 1);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "Either protect these operations with a per-path spinlock, or use `atomic_inc_return()` / `atomic_set()` with `atomic_t` fields instead of plain integers + READ_ONCE/WRITE_ONCE.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_LOCKING_AUDIT.md"
  },
  {
    "id": "CRITICAL-3",
    "title": "Path Pointer Use After Lock Release",
    "category": "concurrency",
    "severity": "S0",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "static struct tquic_path *tquic_find_path_by_addr(struct tquic_connection *conn,\n                                                   struct sockaddr_storage *addr)\n{\n    struct tquic_path *found = NULL;\n\n    spin_lock_bh(&conn->paths_lock);\n    list_for_each_entry(path, &conn->paths, list) {\n        if (memcmp(&path->remote_addr, addr, sizeof(*addr)) == 0) {\n            found = path;\n            break;\n        }\n    }\n    spin_unlock_bh(&conn->paths_lock);\n\n    return found;  // Path can be freed after unlock!\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "Take a reference on the path before releasing the lock: `tquic_path_get(found)` and require callers to call `tquic_path_put()`.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_LOCKING_AUDIT.md"
  },
  {
    "id": "CRITICAL-4",
    "title": "Nested Lock Hierarchy Violation in Timer Code",
    "category": "concurrency",
    "severity": "S0",
    "confidence": "high",
    "impact": "The lock ordering is `ts->lock -> pns->lock -> rs->lock` in `tquic_timer_update_pto`, but `pns->lock -> rs->lock` (without ts->lock) in `tquic_timer_detect_lost`. This is not a direct ordering violation, but the triple nesting combined with the fact that `tquic_timer_pto_expired` runs from timer softirq means that if any of these locks are also taken from process context with `_bh` disabled, a softirq deadlock can occur.\n\nAdditionally, at line 1628-1677:\n```c\nspin_lock_bh(&pns->lock);\n    list_for_each_entry_safe(pkt, tmp, &pns->sent_list, list) {\n        spin_lock(&rs->lock);        // Nested under pns->lock\n        spin_unlock(&rs->lock);\n    }\nspin_unlock_bh(&pns->lock);\n```\n\nThe same `rs->lock` is also taken as `spin_lock_bh(&rs->lock)` at lines 1782, 1811, and also as `spin_lock(&rs->lock)` at lines 842, 941, 1001, 1090. This mixed `_bh` / non-`_bh` usage of the SAME lock is dangerous -- if the lock is held without `_bh` in process context and a softirq tries to acquire it with `spin_lock_bh`, there is no deadlock. However, if `spin_lock_bh(&rs->lock)` is called at line 1589 from process context while `spin_lock(&rs->lock)` is being held at line 842 from softirq (which cannot happen since 842 is under pns->lock _bh), the overall correctness depends on consistently calling from the right context.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "// tquic_timer_pto_expired (timer callback, softirq context)\nspin_lock_bh(&ts->lock);           // Lock #1: ts->lock\n    spin_lock(&rs->lock);           // Lock #2: rs->lock (nested)\n    rs->pto_count++;\n    spin_unlock(&rs->lock);\nspin_unlock_bh(&ts->lock);",
        "spin_lock_bh(&ts->lock);           // Lock #1: ts->lock\n    for (i = 0; i < TQUIC_PN_SPACE_COUNT; i++) {\n        spin_lock(&pns->lock);      // Lock #2: pns->lock (nested)\n            spin_lock(&rs->lock);    // Lock #3: rs->lock (TRIPLE nested!)\n            spin_unlock(&rs->lock);\n        spin_unlock(&pns->lock);\n    }\nspin_unlock_bh(&ts->lock);",
        "spin_lock_bh(&pns->lock);           // Lock pns FIRST\n    spin_lock(&rs->lock);            // Then rs\n    spin_unlock(&rs->lock);\nspin_unlock_bh(&pns->lock);",
        "spin_lock_bh(&pns->lock);\n    list_for_each_entry_safe(pkt, tmp, &pns->sent_list, list) {\n        spin_lock(&rs->lock);        // Nested under pns->lock\n        spin_unlock(&rs->lock);\n    }\nspin_unlock_bh(&pns->lock);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "Standardize ALL uses of `rs->lock` and `pns->lock` to use `spin_lock_bh` / `spin_unlock_bh` consistently, since they are accessed from both timer/softirq context and process context.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_LOCKING_AUDIT.md"
  },
  {
    "id": "HIGH-1",
    "title": "Bonding State Machine Drop-Relock Without Re-validation",
    "category": "concurrency",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "spin_lock_bh(&bc->state_lock);\n    // ... state transition logic ...\n    if (new_state == TQUIC_BOND_SINGLE_PATH && bc->reorder) {\n        spin_unlock_bh(&bc->state_lock);     // DROP LOCK\n        tquic_bonding_free_reorder(bc);       // Calls synchronize_rcu()!\n        spin_lock_bh(&bc->state_lock);        // REACQUIRE\n\n        // Re-evaluate after relock (good!)\n        total_usable = bc->active_path_count;\n        // ... re-checks state ...\n    }\nspin_unlock_bh(&bc->state_lock);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "Add a \"destroying\" flag to `bc` checked after relock, or use refcounting on `bc`.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_LOCKING_AUDIT.md"
  },
  {
    "id": "HIGH-2",
    "title": "GRO Flush Unlock-Relock Loop Without Re-validation",
    "category": "concurrency",
    "severity": "S1",
    "confidence": "high",
    "impact": "Between `spin_unlock` (line 2306) and `spin_lock` (line 2309), `tquic_gro_receive_internal()` could add new packets and increment `gro->held_count`. After the loop finishes, `gro->held_count = 0` blindly resets the count, losing track of any packets added during the unlock window. Those packets will sit in the queue without being properly tracked.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "spin_lock(&gro->lock);\nwhile ((skb = __skb_dequeue(&gro->hold_queue)) != NULL) {\n    spin_unlock(&gro->lock);\n    deliver(skb);               // Arbitrary callback!\n    flushed++;\n    spin_lock(&gro->lock);     // New packets may have been added\n}\ngro->held_count = 0;           // Resets to 0, but new packets arrived!\nspin_unlock(&gro->lock);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "After the loop, set `gro->held_count = skb_queue_len(&gro->hold_queue)` instead of hard-coding 0.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_LOCKING_AUDIT.md"
  },
  {
    "id": "HIGH-3",
    "title": "accept() Uses spin_lock_bh on sk_lock.slock While lock_sock() Is Held",
    "category": "concurrency",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "lock_sock(sk);\n// ...\nfor (;;) {\n    spin_lock_bh(&sk->sk_lock.slock);    // Takes the backing spinlock!\n    if (!list_empty(&tsk->accept_queue)) {\n        // ...\n        spin_unlock_bh(&sk->sk_lock.slock);\n        goto out_unlock;\n    }\n    spin_unlock_bh(&sk->sk_lock.slock);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "Remove the inner `spin_lock_bh(&sk->sk_lock.slock)` calls in `tquic_accept()`. The `lock_sock()` already provides sufficient serialization. If the accept queue needs to be accessed from softirq context, use a dedicated spinlock instead of the socket's backing slock.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_LOCKING_AUDIT.md"
  },
  {
    "id": "HIGH-4",
    "title": "smartnic.c Uses spin_lock Without _bh",
    "category": "concurrency",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "Audit all call sites. If any are reachable from softirq context, change to `spin_lock_bh`.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_LOCKING_AUDIT.md"
  },
  {
    "id": "HIGH-5",
    "title": "http3_stream.c Uses spin_lock Without _bh",
    "category": "concurrency",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "Use `spin_lock_bh` consistently.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_LOCKING_AUDIT.md"
  },
  {
    "id": "HIGH-6",
    "title": "Security Hardening Pre-HS Atomic TOCTOU",
    "category": "concurrency",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "new_total = atomic64_add_return(size, &pre_hs_state.total_memory);\nif (new_total > pre_hs_state.memory_limit) {\n    atomic64_sub(size, &pre_hs_state.total_memory);\n    return -ENOMEM;\n}\n\nentry = find_or_create_ip_entry(addr, true);\nif (entry) {\n    new_per_ip = atomic64_add_return(size, &entry->memory_used);\n    if (new_per_ip > pre_hs_state.per_ip_budget) {\n        atomic64_sub(size, &entry->memory_used);\n        atomic64_sub(size, &pre_hs_state.total_memory);\n        return -ENOMEM;\n    }\n\n    if (atomic_read(&entry->conn_count) >= TQUIC_PRE_HS_MAX_CONNS_PER_IP) {\n        // ... rollback ...\n        return -ENOMEM;\n    }\n\n    atomic_inc(&entry->conn_count);  // TOCTOU with the check above!\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "Use `atomic_inc_return()` and check the result instead of separate read + increment.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_LOCKING_AUDIT.md"
  },
  {
    "id": "MEDIUM-1",
    "title": "Error Ring Uses Atomics Under Spinlock Unnecessarily",
    "category": "concurrency",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "spin_lock(&ring->lock);\nidx = atomic_read(&ring->head) & (TQUIC_ERROR_RING_SIZE - 1);\natomic_inc(&ring->head);\n\nif (atomic_read(&ring->count) < TQUIC_ERROR_RING_SIZE)\n    atomic_set(&ring->count, ...);\n// ...\nspin_unlock(&ring->lock);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_LOCKING_AUDIT.md"
  },
  {
    "id": "MEDIUM-2",
    "title": "FEC Encoder Triple-Nested Locking",
    "category": "concurrency",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "spin_lock_bh(&enc->lock);           // Outer lock\n    spin_lock(&block->lock);         // Inner lock (nested)\n    // ... operations ...\n    spin_unlock(&block->lock);\nspin_unlock_bh(&enc->lock);",
        "spin_lock(&block->lock);   // Line 576 -- no enc->lock held!"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_LOCKING_AUDIT.md"
  },
  {
    "id": "MEDIUM-3",
    "title": "poll() Accesses Connection/Stream Without Any Lock",
    "category": "concurrency",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (sk->sk_state == TCP_LISTEN) {\n    if (tsk->accept_queue_len > 0)      // No lock!\n        mask |= EPOLLIN | EPOLLRDNORM;\n} else if (sk->sk_state == TCP_ESTABLISHED) {\n    conn = READ_ONCE(tsk->conn);\n    stream = READ_ONCE(tsk->default_stream);\n\n    if (conn && stream) {\n        if (!skb_queue_empty(&stream->recv_buf))  // No lock on stream!\n            mask |= EPOLLIN | EPOLLRDNORM;\n    }\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "Use `READ_ONCE(tsk->accept_queue_len)`.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_LOCKING_AUDIT.md"
  },
  {
    "id": "MEDIUM-4",
    "title": "Coupled Congestion Control Division by Zero",
    "category": "concurrency",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "spin_lock_bh(&ctx->lock);\n// ... ctx->total_cwnd checked != 0 at line 897 ...\nincrease = div64_u64(ctx->alpha * acked_bytes * mss,\n                     ctx->total_cwnd * COUPLED_ALPHA_SCALE);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_LOCKING_AUDIT.md"
  },
  {
    "id": "MEDIUM-5",
    "title": "rcu_dereference Outside Explicit RCU Section",
    "category": "concurrency",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "static struct sk_buff *tquic_udp_gro_receive(struct sock *sk, ...)\n{\n    us = rcu_dereference_sk_user_data(sk);",
        "us = rcu_dereference_sk_user_data(sk);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_LOCKING_AUDIT.md"
  },
  {
    "id": "LOW-1",
    "title": "Inconsistent Lock Variant for conn->lock in tquic_input.c",
    "category": "concurrency",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "Add a comment explaining why `_bh` is not needed in the receive path.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_LOCKING_AUDIT.md"
  },
  {
    "id": "LOW-2",
    "title": "Scheduler Lock Uses spin_lock Without _bh",
    "category": "concurrency",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_LOCKING_AUDIT.md"
  },
  {
    "id": "LOW-3",
    "title": "Redundant Lock in tquic_bonding_get_state",
    "category": "concurrency",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "return READ_ONCE(bc->state);   // Line 526 -- lockless read\n// ...\nif (READ_ONCE(bc->state) == TQUIC_BOND_SINGLE_PATH)   // Line 899"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_LOCKING_AUDIT.md"
  },
  {
    "id": "LOW-4",
    "title": "Missing lockdep Annotations",
    "category": "concurrency",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "Global Locks\n                          ============\ntquic_nf_lock (bh)\ntquic_udp_hash_lock (bh)\ntquic_listener_lock (bh)\nport_alloc.lock (bh)\ntquic_nic_lock (plain)\ntquic_sched_lock (plain)\ntquic_bpm_list_lock (bh)\n\n                          Mutex Locks (sleepable)\n                          =======================\ntquic_client_mutex\ntquic_token_mutex\nintegrity_aead_lock\ntquic_retry_mutex\nstate->pool_locks[slot]\nkeyring_mutex\npm_ops_lock\ntquic_cid_table_lock\n\n                          Per-Connection Hierarchy\n                          ========================\nsk->sk_lock (lock_sock)\n  |\n  +-- conn->lock (spin_lock_bh)\n  |     |\n  |     +-- conn->paths_lock (spin_lock_bh or spin_lock in softirq)\n  |     |\n  |     +-- conn->streams_lock (spin_lock_bh)\n  |     |\n  |     +-- conn->datagram.lock (spin_lock)\n  |\n  +-- ts->lock (timer state, spin_lock_bh)\n        |\n        +-- pns->lock (per PN-space, spin_lock_bh or spin_lock)\n        |     |\n        |     +-- rs->lock (recovery state, spin_lock_bh or spin_lock)\n        |\n        +-- rs->lock (can also be direct under ts->lock)\n\n                          Per-Path Hierarchy\n                          ==================\npath->state_lock (spin_lock_bh)\n  |\n  +-- path->cc_lock (spin_lock_bh)\n\n                          Bonding Hierarchy\n                          =================\nbc->state_lock (spin_lock_bh)\n\npm->lock (spin_lock_bh)\n  |\n  +-- path->state_lock (via drop-relock pattern -- UNSAFE)\n\nfc->sent_packets_lock (spin_lock_bh)\n  |\n  +-- fc->retx_queue.lock (spin_lock_bh) -- taken separately, same level\n\n                          FEC Hierarchy\n                          =============\nenc->lock (spin_lock_bh)\n  |\n  +-- block->lock (spin_lock)\n\n                          Other Per-Object Locks\n                          ======================\nh3conn->lock (spin_lock)\nh3s->lock (spin_lock_init only, never used?)\nrb->buffer_lock (reorder, spin_lock_bh)\nstate->lock (deadline sched, spin_lock_bh)\nctx->lock (coupled CC, spin_lock_bh)\npool->lock (CID pool, spin_lock_bh)\nbucket->lock (rate limit, spin_lock_irqsave)\nring->lock (error ring, spin_lock)\ngro->lock (spin_lock)\ncfg->lock (LB config, spin_lock)\nzc->lock (zerocopy, spin_lock_bh)"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "Add `lockdep_assert_held(&conn->lock)` at the beginning of functions that require `conn->lock` to be held.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_LOCKING_AUDIT.md"
  },
  {
    "id": "CRITICAL-01",
    "title": "Tunnel Socket Creation Uses init_net (Container Escape)",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** When a containerized process creates a TQUIC tunnel, the underlying TCP socket is created in the host network namespace. This allows the container to:",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "err = sock_create_kern(&init_net, family, SOCK_STREAM, IPPROTO_TCP,\n                       &sock);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Must use `sock_net(conn->sk)` or propagate the caller's namespace. The tunnel struct should store a `struct net *` reference obtained from the originating socket.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_NAMESPACE_PRIVILEGE_AUDIT.md"
  },
  {
    "id": "CRITICAL-02",
    "title": "MASQUE CONNECT-UDP Proxy Creates Sockets in init_net (Container Escape)",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** A MASQUE proxy running inside a container creates its forwarding UDP sockets in the host namespace. An attacker who can trigger CONNECT-UDP proxy functionality from within a container can send UDP packets from the host's network stack to arbitrary destinations, completely bypassing container isolation.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "ret = sock_create_kern(&init_net, family, SOCK_DGRAM, IPPROTO_UDP, &sock);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** The tunnel must inherit the network namespace from the QUIC connection's socket: `sock_net(tunnel->conn->sk)`.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_NAMESPACE_PRIVILEGE_AUDIT.md"
  },
  {
    "id": "CRITICAL-03",
    "title": "QUIC-over-TCP Client and Server Sockets Use init_net (Container Escape)",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Both QUIC-over-TCP client connections and server listeners operate entirely in the host namespace, regardless of the caller's namespace. A container can listen on TCP ports and accept connections in the host namespace.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "// Client socket (line 1225):\nret = sock_create_kern(&init_net, addr->sa_family, SOCK_STREAM,\n                       IPPROTO_TCP, &conn->tcp_sk);\n\n// Server listener (line 1446):\nret = sock_create_kern(&init_net, AF_INET6, SOCK_STREAM,\n                       IPPROTO_TCP, &listener->tcp_sk);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Propagate `sock_net(quic_conn->sk)` to the TCP socket creation.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_NAMESPACE_PRIVILEGE_AUDIT.md"
  },
  {
    "id": "CRITICAL-04",
    "title": "AF_XDP Socket and Device Lookup Use init_net (Container Escape)",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "// Socket creation (line 367):\nerr = sock_create_kern(&init_net, AF_XDP, SOCK_RAW, 0, &xsk->sock);\n\n// Device lookup (line 1096 and 1117):\ndev = dev_get_by_name(&init_net, ifname);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Replace `&init_net` with `current->nsproxy->net_ns` consistently, and use `ns_capable()` instead of `capable()` to check capabilities relative to the correct namespace.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_NAMESPACE_PRIVILEGE_AUDIT.md"
  },
  {
    "id": "CRITICAL-05",
    "title": "Netfilter Hooks Registered Only in init_net",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** TQUIC connection tracking only works in the init namespace. TQUIC connections within containers will not be tracked by the netfilter integration. This is a functional bug that also means:\n- Container traffic may bypass TQUIC-specific firewall rules",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "ret = nf_register_net_hooks(&init_net, tquic_nf_hooks,\n                            ARRAY_SIZE(tquic_nf_hooks));\n\ntquic_nf_proc_entry = proc_create(\"tquic_conntrack\", 0444,\n                                   init_net.proc_net, &tquic_nf_proc_ops);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Register hooks via `pernet_operations` so each namespace gets its own hooks, or verify this is intentionally init_net-only and document the limitation.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_NAMESPACE_PRIVILEGE_AUDIT.md"
  },
  {
    "id": "CRITICAL-06",
    "title": "IPv4/IPv6 Address Discovery Enumerates Host Interfaces (Container Escape / Info Leak)",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** When TQUIC discovers available network addresses for multipath, it enumerates **all devices in the host namespace**, regardless of the caller's container. This leaks host network topology information (interface names, IP addresses) to containerized processes. In multipath bonding mode, it could also cause the container to establish paths via host-only interfaces.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "for_each_netdev(&init_net, dev) {",
        "for_each_netdev_rcu(&init_net, dev) {"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Use `sock_net(conn->sk)` to enumerate only devices visible in the connection's namespace.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_NAMESPACE_PRIVILEGE_AUDIT.md"
  },
  {
    "id": "HIGH-10-OTH",
    "title": "Missing Validation of `TQUIC_MIGRATE` sockopt Address",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Heap corruption or information disclosure when creating paths with invalid address families.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "case TQUIC_MIGRATE: {\n        struct tquic_migrate_args args;\n\n        if (optlen < sizeof(args))\n            return -EINVAL;\n\n        if (copy_from_sockptr(&args, optval, sizeof(args)))\n            return -EFAULT;\n\n        if (args.reserved != 0)\n            return -EINVAL;\n\n        if (tsk->conn)\n            return tquic_migrate_explicit(tsk->conn,\n                                          &args.local_addr,\n                                          args.flags);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `args.local_addr` is a `sockaddr_storage` from userspace. Its `ss_family` field is never validated. It is passed directly to `tquic_migrate_explicit()` which passes it to `tquic_path_find_by_addr()` and `tquic_path_create()`. As noted in HIGH-01, `tquic_path_create()` treats any non-AF_INET family as AF_INET6 for copy size, which could copy garbage data.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_SOCKET_NETLINK_MIGRATION_AUDIT.md"
  },
  {
    "id": "MEDIUM-11",
    "title": "Security Hardening MIB Stats Always Go to init_net",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Security event counters are always attributed to the host namespace, not the namespace where the attack occurred. This pollutes host statistics and prevents per-namespace security monitoring. A containerized attacker generating flood traffic will show up in the host's MIB counters but not in their own namespace's counters.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "TQUIC_INC_STATS(&init_net, TQUIC_MIB_SEC_PRE_HS_LIMIT);\nTQUIC_INC_STATS(&init_net, TQUIC_MIB_SEC_RETIRE_CID_FLOOD);\nTQUIC_INC_STATS(&init_net, TQUIC_MIB_SEC_NEW_CID_RATE_LIMIT);\nTQUIC_INC_STATS(&init_net, TQUIC_MIB_SEC_OPTIMISTIC_ACK);\nTQUIC_INC_STATS(&init_net, TQUIC_MIB_SEC_INVALID_ACK);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Pass the connection's `sock_net(conn->sk)` to the security event reporting function.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_NAMESPACE_PRIVILEGE_AUDIT.md"
  },
  {
    "id": "MEDIUM-12",
    "title": "Sysctl and Proc Entries Registered in init_net Only",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Multiple sysctl tables and proc entries are registered only in the init_net namespace. While `tquic_proto.c` does have per-netns sysctl registration via `pernet_operations` (correctly skipping init_net at line 843), several subsystems bypass this and register globally. Containers cannot see or configure their own TQUIC sysctls for these subsystems.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "tquic_sysctl_header = register_net_sysctl_sz(&init_net, \"net/tquic\", ...);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_NAMESPACE_PRIVILEGE_AUDIT.md"
  },
  {
    "id": "MEDIUM-13",
    "title": "Proc Entries Hardcoded to init_net.proc_net",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Diagnostic and certificate proc entries are only visible in the host namespace. Lower severity but indicates incomplete namespace awareness.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "pde = proc_create(\"tquic_napi\", 0444, init_net.proc_net, ...);",
        "tquic_cert_proc_dir = proc_mkdir(\"tquic_cert\", init_net.proc_net);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_NAMESPACE_PRIVILEGE_AUDIT.md"
  },
  {
    "id": "MEDIUM-14",
    "title": "Diag/Tracepoints Initialize in init_net",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Path metrics tracing is only initialized for the host namespace.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "ret = tquic_path_metrics_init(&init_net);\n// ...\ntquic_path_metrics_exit(&init_net);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_NAMESPACE_PRIVILEGE_AUDIT.md"
  },
  {
    "id": "CRITICAL-15",
    "title": "No Privilege Check for TQUIC Socket Creation",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Consider requiring `CAP_NET_ADMIN` for bonding/multipath features, or at minimum for creating tunnels and MASQUE proxies.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_NAMESPACE_PRIVILEGE_AUDIT.md"
  },
  {
    "id": "CRITICAL-16",
    "title": "No Privilege Checks for Security-Sensitive Socket Options",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Add `ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN)` checks for privileged options.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_NAMESPACE_PRIVILEGE_AUDIT.md"
  },
  {
    "id": "HIGH-17",
    "title": "MASQUE Proxy Has No Access Control",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Require `CAP_NET_ADMIN` to enable MASQUE proxy functionality.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_NAMESPACE_PRIVILEGE_AUDIT.md"
  },
  {
    "id": "HIGH-18",
    "title": "Load Balancer Has No Privilege Checks",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** All LB configuration interfaces should require `CAP_NET_ADMIN`.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_NAMESPACE_PRIVILEGE_AUDIT.md"
  },
  {
    "id": "HIGH-19",
    "title": "Tunnel Creation Has Insufficient Privilege Checks",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (capable(CAP_NET_ADMIN)) {\n    tquic_err(\"IP_TRANSPARENT failed despite CAP_NET_ADMIN: %d\\n\", err);\n} else {\n    tquic_info(\"IP_TRANSPARENT requires CAP_NET_ADMIN, using normal mode\\n\");\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Require `CAP_NET_ADMIN` to create tunnels. Use `ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN)`.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_NAMESPACE_PRIVILEGE_AUDIT.md"
  },
  {
    "id": "HIGH-20",
    "title": "Packet Forwarding Has No Privilege Checks",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Require `CAP_NET_ADMIN` to enable packet forwarding.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_NAMESPACE_PRIVILEGE_AUDIT.md"
  },
  {
    "id": "MEDIUM-21",
    "title": "Sysctl Permissions Are Overly Permissive",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_NAMESPACE_PRIVILEGE_AUDIT.md"
  },
  {
    "id": "MEDIUM-22",
    "title": "XDP Uses capable() Instead of ns_capable()",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (!capable(CAP_NET_ADMIN))\n    return -EPERM;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_NAMESPACE_PRIVILEGE_AUDIT.md"
  },
  {
    "id": "LOW-23",
    "title": "Netlink Operations All Require GENL_ADMIN_PERM",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "{ .cmd = TQUIC_NL_CMD_PATH_ADD,    .flags = GENL_ADMIN_PERM },\n{ .cmd = TQUIC_NL_CMD_PATH_REMOVE, .flags = GENL_ADMIN_PERM },\n{ .cmd = TQUIC_NL_CMD_PATH_SET,    .flags = GENL_ADMIN_PERM },\n{ .cmd = TQUIC_NL_CMD_PATH_GET,    .flags = GENL_ADMIN_PERM },\n{ .cmd = TQUIC_NL_CMD_PATH_LIST,   .flags = GENL_ADMIN_PERM },\n{ .cmd = TQUIC_NL_CMD_SCHED_SET,   .flags = GENL_ADMIN_PERM },\n{ .cmd = TQUIC_NL_CMD_SCHED_GET,   .flags = GENL_ADMIN_PERM },\n{ .cmd = TQUIC_NL_CMD_STATS_GET,   .flags = GENL_ADMIN_PERM },\n{ .cmd = TQUIC_NL_CMD_CONN_GET,    .flags = GENL_ADMIN_PERM },"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_NAMESPACE_PRIVILEGE_AUDIT.md"
  },
  {
    "id": "LOW-24",
    "title": "Netlink Correctly Uses sock_net for Namespace Scoping",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "struct net *net = sock_net(skb->sk);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_NAMESPACE_PRIVILEGE_AUDIT.md"
  },
  {
    "id": "CRITICAL-25",
    "title": "No security_socket_* Hook Invocations",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** SELinux, AppArmor, Smack, and other Linux Security Modules cannot control TQUIC connections. This means:\n\n1. SELinux policies cannot restrict which processes use QUIC\n2. AppArmor profiles cannot deny QUIC network access\n3. Audit subsystem will not log TQUIC socket operations\n4. seccomp-bpf can only block the initial `socket()` call, not TQUIC-specific operations\n\nFor context, the standard kernel TCP/UDP code paths invoke:\n- `security_socket_create()` -- during socket creation\n- `security_socket_bind()` -- during bind\n- `security_socket_connect()` -- during connect\n- `security_socket_sendmsg()` / `security_socket_recvmsg()` -- during data transfer\n\nTQUIC appears to rely on the underlying UDP socket's security hooks, which may provide partial coverage for the data path. However, TQUIC-specific operations (tunnel creation, MASQUE proxy, multipath bonding) are completely invisible to LSMs.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Invoke appropriate `security_socket_*` hooks in TQUIC socket operations. At minimum:\n- `security_socket_create()` in `tquic_sock_create()`\n- `security_socket_connect()` in `tquic_connect_socket()`\n- `security_socket_bind()` in `tquic_sock_bind()`",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_NAMESPACE_PRIVILEGE_AUDIT.md"
  },
  {
    "id": "C-1-OTH",
    "title": "Use-After-Free in Path Lookup (tquic_input.c, lines 245-261)",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "Kernel heap use-after-free leading to arbitrary code execution (privilege escalation), kernel crash (DoS).",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "static struct tquic_path *tquic_find_path_by_addr(struct tquic_connection *conn,\n                                                  struct sockaddr_storage *addr)\n{\n    struct tquic_path *path;\n    struct tquic_path *found = NULL;\n\n    spin_lock_bh(&conn->paths_lock);\n    list_for_each_entry(path, &conn->paths, list) {\n        if (memcmp(&path->remote_addr, addr, sizeof(*addr)) == 0) {\n            found = path;\n            break;\n        }\n    }\n    spin_unlock_bh(&conn->paths_lock);\n\n    return found;  /* <-- returned WITHOUT refcount increment */\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "Implement reference counting on `tquic_path` objects. The lookup function should atomically increment the refcount under `paths_lock` before returning. Callers must call `tquic_path_put()` when done.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "C-2-OTH",
    "title": "Stale skb->len Read After ip_local_out (tquic_output.c, lines 1730-1736)",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "Reading freed memory. In the best case, corrupted statistics. In the worst case, the freed memory is reallocated and attacker-controlled data is read as `skb->len`, potentially corrupting `tx_bytes` (u64 stat counter).",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "/* Send via IP */\n    ret = ip_local_out(&init_net, NULL, skb);\n\n    /* Update path statistics */\n    if (ret >= 0) {\n        path->stats.tx_packets++;\n        path->stats.tx_bytes += skb->len;   /* <-- skb may be freed */\n        path->last_activity = ktime_get();",
        "u32 pkt_len = skb->len;\nret = ip_local_out(&init_net, NULL, skb);\nif (ret >= 0) {\n    path->stats.tx_bytes += pkt_len;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "Save `skb->len` in a local variable before calling `ip_local_out()`:\n```c\nu32 pkt_len = skb->len;\nret = ip_local_out(&init_net, NULL, skb);\nif (ret >= 0) {\n    path->stats.tx_bytes += pkt_len;\n```\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "C-3-OTH",
    "title": "Wrong Network Namespace in ip_local_out (tquic_output.c, line 1730)",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "Network namespace escape. Containers can send traffic through the host network. This violates a fundamental Linux security boundary. Firewall rules in the container's namespace are bypassed.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "ret = ip_local_out(&init_net, NULL, skb);",
        "ret = ip_local_out(net, conn->sk, skb);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "Use `sock_net(conn->sk)` instead of `&init_net`. The correct network namespace was already computed at line 1681 in the `rt` lookup:\n```c\nret = ip_local_out(net, conn->sk, skb);\n```\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "H-1-OTH",
    "title": "GRO Coalesce Uses Hardcoded 8-byte CID Comparison (tquic_input.c, lines 2249-2253)",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "Out-of-bounds read (heap info leak / crash). Incorrect coalescing could mix packets from different connections, causing frame processing confusion.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "/* For short headers, compare DCID */\n    if (!(h1[0] & TQUIC_HEADER_FORM_LONG)) {\n        /* Assume 8-byte CID for now */\n        return memcmp(h1 + 1, h2 + 1, 8) == 0;\n    }",
        "if (skb1->len < 1 + cid_len || skb2->len < 1 + cid_len)\n    return false;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "The GRO coalesce function needs to know the actual CID length. Pass it via skb metadata or look it up from connection state. Also add length checks:\n```c\nif (skb1->len < 1 + cid_len || skb2->len < 1 + cid_len)\n    return false;\n```\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "H-2-OTH",
    "title": "tquic_process_stream_frame Allocates skb Based on Attacker-Controlled length (tquic_input.c, line 944)",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "Memory exhaustion (kernel OOM) by flooding STREAM frames from multiple connections.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (length > 65535)\n        return -EINVAL;\n    ...\n    /* Copy data to stream receive buffer */\n    data_skb = alloc_skb(length, GFP_ATOMIC);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "Move the `sk_rmem_alloc` check BEFORE the `alloc_skb()` call to avoid the allocation entirely when the buffer is full. Also consider a global receive buffer cap.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "H-3-OTH",
    "title": "ECN Counter Values Passed Directly to TQUIC_ADD_STATS Without Overflow Check (tquic_input.c, lines 702-707)",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "Congestion control manipulation. An attacker spoofing ACK_ECN frames can cause the sender to dramatically reduce its congestion window, effectively performing a denial of service by throttling legitimate traffic.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (ecn_ect0 > 0)\n        TQUIC_ADD_STATS(net, TQUIC_MIB_ECNECT0RX, ecn_ect0);\n    if (ecn_ect1 > 0)\n        TQUIC_ADD_STATS(net, TQUIC_MIB_ECNECT1RX, ecn_ect1);\n    if (ecn_ce > 0)\n        TQUIC_ADD_STATS(net, TQUIC_MIB_ECNCEMARKSRX, ecn_ce);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "Validate that ECN counts are monotonically increasing from previous values. Store previous ECN counts per-path and only react to the *increase*, not the absolute value (as RFC 9002 Section 7.1 requires). The comment at line 759-763 acknowledges this is missing.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "H-4-OTH",
    "title": "(Revised): tquic_pacing_work Accesses skb->len After tquic_output_packet (tquic_output.c, lines 1413-1418)",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "Reading freed memory for pacing calculation. Could result in incorrect pacing timing or kernel crash if slab is reallocated.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "skb = __skb_dequeue(&pacing->queue);\n        spin_unlock_bh(&pacing->lock);\n\n        /* Actually send the packet */\n        tquic_output_packet(NULL, pacing->path, skb);\n\n        spin_lock_bh(&pacing->lock);\n\n        /* Update next send time */\n        gap = tquic_pacing_calc_gap(pacing, skb->len);  /* <-- UAF */"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "Save `skb->len` before calling `tquic_output_packet()`.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "H-5-OTH",
    "title": "Multipath Frame Processing Lacks Encryption Level Validation (tquic_input.c, lines 2027-2038)",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "State manipulation via forged multipath frames in weakly-authenticated Initial/Handshake packets. Could cause path confusion, CID manipulation, or denial of service.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "#ifdef CONFIG_TQUIC_MULTIPATH\n        } else if (frame_type == 0x40) {\n            /* MP_NEW_CONNECTION_ID (RFC 9369) */\n            ret = tquic_process_mp_new_connection_id_frame(&ctx);\n        } else if (frame_type == 0x41) {\n            /* MP_RETIRE_CONNECTION_ID (RFC 9369) */\n            ret = tquic_process_mp_retire_connection_id_frame(&ctx);\n        } else if (frame_type == 0x42 || frame_type == 0x43) {\n            /* MP_ACK or MP_ACK_ECN (RFC 9369) */\n            ret = tquic_process_mp_ack_frame(&ctx);\n        } else if (tquic_is_mp_extended_frame(&ctx)) {\n            /* Extended multipath frames (PATH_ABANDON, PATH_STATUS) */\n            ret = tquic_process_mp_extended_frame(&ctx);\n#endif",
        "} else if (frame_type == 0x40) {\n    if (is_initial || is_handshake) {\n        conn->error_code = EQUIC_FRAME_ENCODING;\n        return -EPROTO;\n    }\n    ret = tquic_process_mp_new_connection_id_frame(&ctx);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "Add encryption level checks for all multipath frame types. They should only be accepted in 1-RTT packets (and possibly 0-RTT):\n```c\n} else if (frame_type == 0x40) {\n    if (is_initial || is_handshake) {\n        conn->error_code = EQUIC_FRAME_ENCODING;\n        return -EPROTO;\n    }\n    ret = tquic_process_mp_new_connection_id_frame(&ctx);\n```\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "H-6-OTH",
    "title": "ACK Frame bytes_acked Calculation Can Overflow (tquic_input.c, lines 736-738)",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "Congestion control manipulation. The sender may suddenly increase its sending rate based on bogus ACK data, potentially contributing to network congestion or enabling amplification.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "{\n        u64 bytes_acked = (first_ack_range + 1) * 1200;\n\n        /* Dispatch ACK event to congestion control */\n        tquic_cong_on_ack(ctx->path, bytes_acked, rtt_us);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "Cap `first_ack_range` to a reasonable value (e.g., the maximum number of packets in flight) before the multiplication. Alternatively, cap `bytes_acked` to the actual bytes in flight.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "H-7",
    "title": "CID Lookup Returns Connection Without Reference Count",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Returns a raw pointer to a connection without incrementing any reference count. If the connection is concurrently destroyed (e.g., timeout, reset) after the lookup but before the caller uses the pointer, this is a use-after-free. This is the packet demux hot path -- every incoming packet calls this function.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "struct tquic_connection *tquic_cid_lookup(const struct tquic_cid *cid)\n{\n    entry = rhashtable_lookup_fast(&tquic_cid_table, cid, cid_rht_params);\n    if (entry && entry->state == CID_STATE_ACTIVE)\n        return entry->conn;\n    return NULL;\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** The caller should be in an RCU read-side section, and connections should be freed via `kfree_rcu()`. Alternatively, take a refcount on the connection before returning.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_MULTIPATH_BONDING.md"
  },
  {
    "id": "H-8",
    "title": "Weighted Scheduler Index Assumption Breaks After Path Removal",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** The weighted scheduler uses a positional index into `path_data[]` array that is implicitly coupled to the order of paths in the linked list. When a path is removed from the middle of the list, subsequent paths shift position but the array data does not. This means path_data entries become misaligned: path N gets the deficit/weight state of path N-1. This corrupts scheduling fairness and may cause starvation of some paths.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "list_for_each_entry_rcu(path, &conn->paths, list) {\n    if (idx == path_idx) {\n        pd = &wd->path_data[path_idx];\n        pd->deficit += ...;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Index `path_data[]` by `path->path_id` (which is stable) rather than by list position. Add bounds checking for `path_id < TQUIC_MAX_PATHS`.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_MULTIPATH_BONDING.md"
  },
  {
    "id": "M-1-OTH",
    "title": "ktime_get_ts64 Written to skb->cb May Exceed cb Size (tquic_input.c, line 1471)",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "Logic confusion if skbs are mishandled between datagram and stream paths. Low exploitability but a correctness issue.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "/* Store receive timestamp in SKB cb */\n    ktime_get_ts64((struct timespec64 *)dgram_skb->cb);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "`skb->cb` is 48 bytes. `struct timespec64` is 16 bytes (on 64-bit kernels). This fits. However, the DATAGRAM receive path also stores the recv timestamp here, while the STREAM frame path stores a `u64 offset` in `skb->cb` (line 951: `*(u64 *)data_skb->cb = offset`). There is no type safety -- if code later processes a datagram skb expecting a `u64` offset, or a stream skb expecting a `timespec64`, data corruption occurs.",
    "fix_suggestion": "Use a typed union or dedicated struct for `skb->cb` usage, documented per frame type.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "M-2-OTH",
    "title": "tquic_recv_datagram Can Loop Forever Under Signal Pressure (tquic_output.c, lines 2706-2743)",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "A blocking `tquic_recv_datagram` call without SO_RCVTIMEO can be held in a tight retry loop if a racing consumer steals datagrams, consuming CPU.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "retry:\n    spin_lock_irqsave(&conn->datagram.lock, irqflags);\n    skb = skb_peek(&conn->datagram.recv_queue);\n    if (!skb) {\n        spin_unlock_irqrestore(&conn->datagram.lock, irqflags);\n        if (flags & MSG_DONTWAIT)\n            return -EAGAIN;\n        if (timeo == 0)\n            return -EAGAIN;\n        if (signal_pending(current))\n            return sock_intr_errno(timeo);\n        ret = tquic_datagram_wait_data(conn, &timeo);\n        if (ret < 0) { ... return ... }\n        if (conn->state != TQUIC_CONN_CONNECTED ...) return -ENOTCONN;\n        goto retry;\n    }",
        "int retries = 0;\n...\nretry:\n    if (++retries > 3) return -EAGAIN;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "Add a retry counter to prevent excessive looping:\n```c\nint retries = 0;\n...",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "M-3-OTH",
    "title": "Version Negotiation Versions Logged Without Rate Limiting (tquic_input.c, lines 473-477)",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "Log flooding (minor DoS of logging infrastructure).",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "for (i = 0; i + 4 <= versions_len; i += 4) {\n        u32 version = ...;\n        tquic_dbg(\"  version 0x%08x\\n\", version);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "Either remove the per-version debug line or cap the number of logged versions.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "M-4-OTH",
    "title": "tquic_gro_flush Drops and Re-acquires Lock Per Packet (tquic_input.c, lines 2303-2310)",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "Incorrect `held_count` could cause GRO to hold more packets than intended, or to prematurely stop holding, affecting performance but not security directly.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "while ((skb = __skb_dequeue(&gro->hold_queue)) != NULL) {\n        spin_unlock(&gro->lock);\n        deliver(skb);\n        flushed++;\n        spin_lock(&gro->lock);\n    }\n\n    gro->held_count = 0;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "After the loop, set `held_count = skb_queue_len(&gro->hold_queue)`.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "M-5-OTH",
    "title": "Coalesced Packet Processing Silently Truncates on Overflow (tquic_input.c, lines 3172-3173)",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "Could cause frame parsing errors or incomplete CRYPTO frame data being fed to the TLS state machine, potentially triggering TLS parsing bugs.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (offset + pkt_len > total_len)\n            pkt_len = total_len - offset;",
        "if (offset + pkt_len > total_len)\n    break;  /* Malformed coalesced packet -- stop */"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "Instead of silently truncating, reject the coalesced packet entirely when the claimed length exceeds remaining data:\n```c\nif (offset + pkt_len > total_len)\n    break;  /* Malformed coalesced packet -- stop */\n```",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "M-6-OTH",
    "title": "Scheduler Change Race Between State Check and Modification",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** The connection state is checked before acquiring `conn->lock`. A concurrent connection establishment could change the state between the check and the lock acquisition, allowing the scheduler to be changed mid-connection. While unlikely, this violates the stated invariant (\"Scheduler locked at connection establishment\").",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (conn->state != TQUIC_CONN_IDLE)\n    return -EISCONN;\n// ... RCU lookup, module_get ...\nspin_lock_bh(&conn->lock);\nold_sched = conn->sched;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Move the state check inside the spinlock-protected region.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_MULTIPATH_BONDING.md"
  },
  {
    "id": "M-7-OTH",
    "title": "Missing Bounds Check on tquic_hyst_state_names Array Access",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** If `old_state` or `new_state` is out of bounds (e.g., due to memory corruption or a bug), this will cause an out-of-bounds read from the array, potentially leaking kernel memory through log messages.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "pr_info(\"path %u hysteresis: %s -> %s ...\\n\",\n    pt->path_id,\n    tquic_hyst_state_names[old_state],\n    tquic_hyst_state_names[new_state], ...);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Use `ARRAY_SIZE(tquic_hyst_state_names)` bounds check before indexing.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_MULTIPATH_BONDING.md"
  },
  {
    "id": "M-8-OTH",
    "title": "Netlink PM Commands Missing CAP_NET_ADMIN Checks",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** The `tquic_pm_nl_add_path()` and `tquic_pm_nl_del_path()` netlink command handlers do not appear to require `CAP_NET_ADMIN`. While the genl_ops definition may set `.flags = GENL_ADMIN_PERM`, this was not verified in the visible code. Without privilege checks, any user process could add or remove paths from QUIC connections, enabling path hijacking or denial-of-service.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Ensure all PM netlink ops have `.flags = GENL_ADMIN_PERM` in the `genl_ops` array, or add explicit `capable(CAP_NET_ADMIN)` checks in each handler.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_MULTIPATH_BONDING.md"
  },
  {
    "id": "M-9-OTH",
    "title": "Path Score Computation Can Overflow in Migration Target Selection",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** The score starts at 1000000 and is multiplied by 1000, bandwidth, (100-loss), (256-priority), and weight without overflow checks. For a path with high bandwidth (e.g., 10Gbps = 1250000000) and low RTT, the intermediate value `1000000 * 1000 / rtt * bandwidth` can overflow u64 (bandwidth * 1000000000 > 2^64).",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "u64 score = 1000000;\nscore = score * 1000 / stats->rtt_smoothed;\nscore = (score * stats->bandwidth) >> 20;\nscore = score * (100 - min(loss_pct, 90ULL)) / 100;\nscore = score * (256 - path->priority) / 256;\nscore = score * path->weight;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Reorder operations to divide before multiplying, or cap intermediate values.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_MULTIPATH_BONDING.md"
  },
  {
    "id": "M-10",
    "title": "Path Manager netdev_event Shadows Variable 'i'",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** The inner variable `i` shadows the outer `i` declared at function scope. While C allows this, it suggests a potential bug if the outer `i` was intended to be used later. This is a code quality issue that could mask real bugs.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "int num_addrs, i;    // outer 'i'\n// ...\nfor (i = 0; i < num_addrs; i++) {  // shadows outer 'i'"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Rename the inner loop variable.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_MULTIPATH_BONDING.md"
  },
  {
    "id": "M-11",
    "title": "BPM Path Manager Uses Workqueue Without Connection Lifetime Guard",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** The path manager schedules work items that reference the connection. If the connection is freed before the work runs, the work callback will dereference a freed `pm->conn` pointer. While `cancel_delayed_work_sync()` should be called during teardown, if any work items are missed (e.g., discover_work, failover_work), this is a use-after-free.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "struct work_struct discover_work;\nstruct work_struct failover_work;\nstruct delayed_work probe_work;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Add a `struct tquic_connection *conn` reference with proper refcounting, and verify all work items are cancelled during teardown.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_MULTIPATH_BONDING.md"
  },
  {
    "id": "M-12",
    "title": "NAT Keepalive Config Pointer Not Protected Against Concurrent Free",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** `state->config` is read without holding `state->lock`. If the config is freed or replaced concurrently (e.g., via sysctl or sockopt), the pointer dereference at `state->config->enabled` would be a use-after-free.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (!state || !state->initialized || state->suspended)\n    return false;\nif (!state->config || !state->config->enabled)\n    return false;\n// ...\nconfig = state->config;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Access `state->config` under `state->lock`, or use `rcu_dereference()`/`rcu_assign_pointer()` for RCU-protected access.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_MULTIPATH_BONDING.md"
  },
  {
    "id": "L-1-OTH",
    "title": "tquic_encode_varint Does Not Validate val Range (tquic_output.c, lines 164-198)",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "If any code path passes a value >= 2^62, the encoded varint would decode to a different (smaller) value. This is a correctness issue that could cause protocol violations.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "The function calls `tquic_varint_len(val)` which should return -EINVAL or similar for values >= 2^62 (the QUIC varint maximum). If `tquic_varint_len` returns 8 for values in [2^62, 2^64-1], the encoding would produce incorrect output (the high 2 bits would be overwritten by the length prefix `0xc0`, silently truncating the value).",
    "fix_suggestion": "Add validation: `if (val >= (1ULL << 62)) return -EINVAL;`\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "L-2-OTH",
    "title": "tquic_build_short_header_internal Writes pkt_num to buf+64 Scratch Space (tquic_output.c, line 818)",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "Stack buffer overflow. The 4 bytes at `header[64..67]` overwrite whatever is next on the stack. Depending on stack layout, this could corrupt the return address or other local variables. However, the overwritten data is then never used (it's just scratch for determining `pkt_num_len`), so the written values don't matter as long as the stack frame can absorb 4 extra bytes.\n\nIn practice, the compiler's stack frame is likely larger than 64 bytes due to other local variables. But this is undefined behavior in C and could cause intermittent corruption depending on optimization level and stack layout.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "pkt_num_len = tquic_encode_pkt_num(buf + 64, pkt_num, largest_acked);",
        "u8 pn_scratch[4];\npkt_num_len = tquic_encode_pkt_num(pn_scratch, pkt_num, largest_acked);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "This writes the packet number encoding into `buf + 64` as scratch space. The function is called with `buf` pointing to stack buffers of size 64 (e.g., line 1915: `u8 header[64]`). Writing at `buf + 64` is a stack buffer overflow of up to 4 bytes past the 64-byte buffer.\n\nIn the `tquic_assemble_packet` path, `buf` is `header_buf[128]` (line 961), so `buf + 64` is within bounds. But in `tquic_send_ack` (line 1915) and `tquic_send_connection_close` (line 1982), `buf` is `u8 header[64]`, making `buf + 64` a 4-byte stack overflow.",
    "fix_suggestion": "Allocate a separate scratch buffer or use a function-local buffer:\n```c\nu8 pn_scratch[4];\npkt_num_len = tquic_encode_pkt_num(pn_scratch, pkt_num, largest_acked);\n```\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "L-3-OTH",
    "title": "tquic_gso_init Integer Overflow in Allocation Size (tquic_output.c, line 1489)",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "Allocation of undersized buffer if overflow occurs, leading to heap buffer overflow when GSO segments are added.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "gso->gso_skb = alloc_skb(gso->gso_size * max_segs + MAX_HEADER, GFP_ATOMIC);",
        "size_t alloc_size;\nif (check_mul_overflow((size_t)gso->gso_size, (size_t)max_segs, &alloc_size))\n    return -EINVAL;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "`gso->gso_size` is `path->mtu - 48` (u16), `max_segs` is u16. The multiplication `gso_size * max_segs` is performed in 32-bit (u16 * u16 promotes to int). Maximum value: 65535 * 65535 = 4,294,836,225 which overflows u32. However, `max_segs` is typically small (TQUIC_GSO_MAX_SEGS = 64), making the practical maximum 65535 * 64 = 4,194,240, which fits. But if `max_segs` is user-controllable or comes from an untrusted source, this could overflow.",
    "fix_suggestion": "Use `size_t` arithmetic with overflow checking:\n```c\nsize_t alloc_size;\nif (check_mul_overflow((size_t)gso->gso_size, (size_t)max_segs, &alloc_size))\n    return -EINVAL;\n```\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "L-4-OTH",
    "title": "tquic_process_ack_frame Does Not Validate largest_ack vs first_ack_range (tquic_input.c, lines 601-660)",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "Protocol confusion in the congestion control / loss detection subsystem. An attacker could cause the CC to mark incorrect packets as acknowledged.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "Per RFC 9000 Section 19.3.1: \"The largest packet number in the first ACK Range is determined by subtracting the First ACK Range value from the Largest Acknowledged field.\" If `first_ack_range > largest_ack`, this subtraction underflows. The code does not validate this relationship.\n\nSimilarly, within the ACK ranges loop, each gap and range should be validated against the running smallest acknowledged value to ensure monotonically decreasing packet numbers.",
    "fix_suggestion": "Add: `if (first_ack_range > largest_ack) return -EINVAL;`\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "L-5-OTH",
    "title": "tquic_process_coalesced Missing Infinite Loop Guard (tquic_input.c, lines 3079-3182)",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "Bounded CPU consumption (at most ~214 iterations for a 1500-byte datagram).",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "The coalesced packet loop increments `offset` by `pkt_len` each iteration. For short header packets (line 3169), `pkt_len = total_len - offset`, which always terminates the loop. For long header packets, `pkt_len` is computed from the Length field. If `pkt_len` computes to 0 (e.g., `hdr_len + 0 = hdr_len`, but then `check_add_overflow(hdr_len, 0, &pkt_len)` gives `pkt_len = hdr_len`), the loop processes the same bytes repeatedly. However, `pkt_len` must be at least `hdr_len >= 7`, so `offset` always advances at least 7 bytes. This bounds the loop to `total_len / 7` iterations.\n\nActually, the pkt_len could be very small (just the header) but still positive, so the loop always terminates. Still, adding a `packets` counter limit would be a defense-in-depth improvement.",
    "fix_suggestion": "Add `if (packets > 16) break;` to cap coalesced packets.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "L-6",
    "title": "Path Validation Response Queue Uses Two Tracking Mechanisms",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "** The response queue uses both `skb_queue_*` (which has its own count via `skb_queue_len()`) and a separate `atomic_t count`. These could diverge if a dequeue path forgets to decrement the atomic. Dual tracking is error-prone.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (atomic_read(&path->response.count) >= TQUIC_MAX_PENDING_RESPONSES) {\n// ...\nskb_queue_tail(&path->response.queue, skb);\natomic_inc(&path->response.count);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Use only one mechanism. `skb_queue_len()` is already atomic and thread-safe.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_MULTIPATH_BONDING.md"
  },
  {
    "id": "L-7",
    "title": "Coupled CC Alpha Smoothing May Suppress Rapid Changes",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "** `COUPLED_ALPHA_SMOOTHING = 8` means alpha changes by only 1/8 per update. When a path is suddenly added or removed, it takes many RTTs for alpha to converge, causing unfair bandwidth distribution during transitions. This is a design tradeoff, not a bug, but it could be improved.",
    "evidence": {
      "file_paths": [
        "** Proper reorder buffer with RTT-spread-based timeout calculation handles out-of-order delivery across paths with different latencies."
      ],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Consider faster convergence when path count changes.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_MULTIPATH_BONDING.md"
  },
  {
    "id": "C-4-OTH",
    "title": "conn->sk Accessed Without Lock After Stateless Reset (tquic_input.c, lines 397-407)",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "Use-after-free on the socket structure, leading to privilege escalation or kernel crash.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "static void tquic_handle_stateless_reset(struct tquic_connection *conn)\n{\n    struct sock *sk;\n\n    spin_lock_bh(&conn->lock);\n    conn->state = TQUIC_CONN_CLOSED;\n    conn->error_code = EQUIC_NO_ERROR;\n\n    /* Read sk under lock to prevent use-after-free */\n    sk = READ_ONCE(conn->sk);\n    spin_unlock_bh(&conn->lock);\n\n    /* Notify upper layer */\n    if (sk)\n        sk->sk_state_change(sk);  /* <-- sk could be freed here */\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "Hold a reference to the socket (`sock_hold(sk)`) under the lock, then call `sk_state_change`, then release the reference (`sock_put(sk)`).\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "C-5",
    "title": "PADDING Frame Infinite Skip Without Bound on Encrypted Payload (tquic_input.c, lines 565-571)",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "static int tquic_process_padding_frame(struct tquic_rx_ctx *ctx)\n{\n    /* Just skip padding bytes */\n    while (ctx->offset < ctx->len && ctx->data[ctx->offset] == 0)\n        ctx->offset++;\n\n    return 0;\n}",
        "if (ctx.offset == prev_offset)\n    return -EPROTO;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "This function is called from the frame processing loop after decryption. The frame type byte (0x00 = PADDING) is NOT consumed before entering the `while` loop -- the caller does not increment `ctx->offset` for the PADDING case (line 1901 calls `tquic_process_padding_frame` which enters the while loop seeing `data[offset] == 0` which is the frame type itself).\n\nHowever, note the anti-infinite-loop guard at line 2058:\n```c\nif (ctx.offset == prev_offset)\n    return -EPROTO;\n```\n\nIf `ctx->data[ctx->offset]` is NOT zero (i.e., padding byte is actually non-zero due to decryption producing a 0x00 frame type followed by non-zero), the function returns without advancing `ctx->offset` at all if `ctx->data[ctx->offset]` happens to be non-zero on the first check. Actually wait -- the caller enters at `frame_type == TQUIC_FRAME_PADDING` (line 1900), so `data[offset]` IS 0, so the while loop will advance at least one byte. This is actually OK -- the stuck-parsing guard will catch any zero-progress case.\n\n**Re-assessment**: After closer analysis, this is actually handled correctly. The while loop always makes at least one iteration of progress since `data[offset] == 0` was already verified by the caller. **Downgrading to Informational -- not a real issue.**\n\n**REPLACING C-5**:",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "C-5-OTH",
    "title": "(Revised): tquic_process_packet Does Not Validate pkt_num_len Against Remaining Data (tquic_input.c, lines 2528-2529, 2572-2574)",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "Out-of-bounds read of 1-4 bytes past the packet buffer. On a SLUB-allocated buffer, this reads from adjacent slab objects, potentially leaking sensitive data (heap information disclosure). If the packet data is in an skb's linear data area, this could read past `skb->tail`.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "/* Packet number length from first byte */\n    pkt_num_len = (data[0] & 0x03) + 1;   /* line 2529 or 2545 */\n    ...\n    /* Decode packet number */\n    pkt_num = tquic_decode_pkt_num(data + ctx.offset, pkt_num_len, 0); /* line 2573 */\n    ctx.offset += pkt_num_len;  /* line 2574 */",
        "if (ctx.offset + pkt_num_len > len)\n    return -EINVAL;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "Add a bounds check before decoding the packet number:\n```c\nif (ctx.offset + pkt_num_len > len)\n    return -EINVAL;\n```\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "C-6",
    "title": "Packet Number Length Extracted Before Header Unprotection (tquic_input.c, lines 2529, 2545 vs 2565)",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "Protocol confusion leading to frame processing of attacker-controlled data at wrong offsets. Combined with C-5 (no bounds check), this is a high-impact logic error.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "// Long header path (line 2529):\n    pkt_num_len = (data[0] & 0x03) + 1;\n\n    // Short header path (line 2545):\n    pkt_num_len = (data[0] & 0x03) + 1;\n\n    // Header protection removal (line 2565):\n    ret = tquic_remove_header_protection(conn, data, ctx.offset, ...);",
        "ret = tquic_remove_header_protection(conn, data, ctx.offset, ...);\nif (ret < 0) return ret;\npkt_num_len = (data[0] & 0x03) + 1;  // Now reads unprotected bits\nif (ctx.offset + pkt_num_len > len) return -EINVAL;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "Move the `pkt_num_len` extraction to AFTER `tquic_remove_header_protection()`:\n```c\nret = tquic_remove_header_protection(conn, data, ctx.offset, ...);\nif (ret < 0) return ret;\npkt_num_len = (data[0] & 0x03) + 1;  // Now reads unprotected bits\nif (ctx.offset + pkt_num_len > len) return -EINVAL;\n```",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "H-7-OTH",
    "title": "tquic_udp_recv Processes Stateless Reset Before Authenticating Packet (tquic_input.c, lines 2916-2932)",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "CPU exhaustion via stateless reset token scanning on every incoming short-header packet. In a multipath scenario with many CIDs, this becomes expensive.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "/* Check for stateless reset (received from peer) */\n    if (len < TQUIC_STATELESS_RESET_MIN_LEN)\n        goto not_reset;\n\n    if (data[0] & TQUIC_HEADER_FORM_LONG)\n        goto not_reset;\n\n    /* Try to find connection for reset check */\n    if (len > 1) {\n        u8 dcid_len = min_t(size_t, len - 1, TQUIC_MAX_CID_LEN);\n        conn = tquic_lookup_by_dcid(data + 1, dcid_len);\n    }\n\n    if (conn && tquic_is_stateless_reset_internal(conn, data, len)) {\n        tquic_handle_stateless_reset(conn);\n        kfree_skb(skb);\n        return 0;\n    }"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "Only check for stateless reset AFTER regular decryption fails (RFC 9000 Section 10.3.1 recommends this order). The check should be a last resort, not a first check.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "H-8-OTH",
    "title": "tquic_output_packet Passes NULL conn to ip_local_out (tquic_output.c, line 1413)",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "Statistics and security state (key update tracking) are silently skipped for pacing-deferred packets. The namespace escape (C-3) is always triggered.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "/* Actually send the packet */\n    tquic_output_packet(NULL, pacing->path, skb);",
        "ret = ip_local_out(&init_net, NULL, skb);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "Store a reference to `conn` in `tquic_pacing_state` and pass it through.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "L-6-OTH",
    "title": "spin_lock (Not spin_lock_bh) Used in tquic_process_max_data_frame (tquic_input.c, lines 1015-1017)",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "Potential deadlock if `conn->lock` is acquired from both softirq and process context on the same CPU.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "spin_lock(&ctx->conn->lock);\n    ctx->conn->max_data_remote = max(ctx->conn->max_data_remote, max_data);\n    spin_unlock(&ctx->conn->lock);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "The input path runs in softirq context (UDP receive callback). Using `spin_lock` instead of `spin_lock_bh` means softirqs are NOT disabled. If another softirq on the same CPU also takes `conn->lock` (e.g., timer processing), deadlock occurs.\n\nOther lock acquisitions in the same file correctly use `spin_lock_bh` (e.g., lines 251, 917).",
    "fix_suggestion": "Change to `spin_lock_bh(&ctx->conn->lock)`.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "L-7-OTH",
    "title": "tquic_output_flush Holds conn->lock While Calling GFP_ATOMIC Allocation (tquic_output.c, lines 2071-2117)",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "Potential latency spike from holding `conn->lock` through multiple iterations of the stream loop with GFP_ATOMIC allocations.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "The function acquires `conn->lock` at line 2071 and calls `kzalloc(sizeof(*frame), GFP_ATOMIC)` at line 2117, `kmalloc(chunk_size, GFP_ATOMIC)` at line 2132. GFP_ATOMIC is correct for atomic context, but holding a spinlock while allocating memory is a performance concern. The lock is released before `tquic_assemble_packet` (line 2148), which is good.\n\nThe real concern is that `spin_lock_bh` disables softirqs, and if `kzalloc(GFP_ATOMIC)` fails, the error handling at lines 2118-2121 and 2133-2136 correctly breaks out but the lock is still held. The cleanup after the loop at line 2216 releases the lock. This is correct but could hold the lock for a long time if many streams have data.",
    "fix_suggestion": "Consider pre-allocating frame structures outside the lock, or batching frame preparation.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "I-1",
    "title": "ACK Frequency Frame Type Inconsistency",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "Verify the frame type dispatch logic handles multi-byte frame types correctly.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "I-2",
    "title": "IMMEDIATE_ACK Frame Type Similar Issue",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "I-3",
    "title": "tquic_encap_recv Double UDP Header Strip",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "I-4",
    "title": "send_skb Variable Used After Potential NULL",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [
        "|   |-- tquic_parse_long_header_internal [2354]",
        "|   |-- tquic_parse_short_header_internal [2539]"
      ],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "UDP Datagram from Network\n    |\n    v\ntquic_encap_recv() [line 3027]\n    |-- __skb_pull(skb, sizeof(struct udphdr))\n    v\ntquic_udp_recv(sk, skb) [line 2718]  <-- MAIN ENTRY POINT\n    |\n    |-- Rate limiting check [2785-2913]\n    |   |-- tquic_decode_varint (token parsing) [2841]\n    |   |-- tquic_ratelimit_check_initial [2862]\n    |   |-- tquic_retry_send [2896]    <-- amplification vector\n    |\n    |-- Stateless reset check [2916-2932]  <-- H-7: expensive\n    |   |-- tquic_lookup_by_dcid [2925]\n    |   |-- tquic_is_stateless_reset_internal [2928]\n    |\n    |-- Version negotiation [2936-2961]\n    |   |-- tquic_process_version_negotiation [2954]\n    |\n    v\ntquic_process_packet() [line 2329]  <-- CORE PROCESSING\n    |\n    |-- Long header path:\n    |   |-- tquic_parse_long_header_internal [2354]\n    |   |-- Version negotiation [2361]\n    |   |-- Retry processing [2380]\n    |   |-- 0-RTT processing [2438]\n    |   |-- Token parsing for Initial [2501]\n    |   |-- Length field parsing [2519]\n    |   |-- pkt_num_len extraction [2529]  <-- C-6: before HP\n    |\n    |-- Short header path:\n    |   |-- tquic_parse_short_header_internal [2539]\n    |   |-- pkt_num_len extraction [2545]  <-- C-6: before HP\n    |\n    |-- tquic_remove_header_protection [2565]\n    |-- tquic_decode_pkt_num [2573]  <-- C-5: no bounds check\n    |\n    |-- Decryption:\n    |   |-- kmem_cache_alloc / kmalloc [2586-2590]\n    |   |-- tquic_zero_rtt_decrypt [2601] or tquic_decrypt_payload [2618]\n    |\n    |-- Key update detection [2656-2670]\n    |\n    v\ntquic_process_frames() [line 1839]  <-- FRAME DEMUX\n    |\n    |-- PADDING [1900]\n    |-- PING [1902]\n    |-- ACK/ACK_ECN [1904]  <-- H-3, H-6, L-4\n    |-- CRYPTO [1915]\n    |-- NEW_TOKEN [1925]\n    |-- STREAM [1935]  <-- H-2\n    |-- MAX_DATA [1945]  <-- L-6\n    |-- PATH_CHALLENGE/RESPONSE [1963,1972]\n    |-- NEW_CONNECTION_ID [1981]\n    |-- CONNECTION_CLOSE [1999]\n    |-- HANDSHAKE_DONE [2003]\n    |-- DATAGRAM [2013]\n    |-- ACK_FREQUENCY [2022]  <-- I-1\n    |-- MP frames [2027-2038]  <-- H-5\n    |-- Unknown frame -> FRAME_ENCODING_ERROR [2040]\n    |\n    |-- Infinite loop guard [2058]"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_INPUT_OUTPUT_AUDIT.md"
  },
  {
    "id": "CRITICAL-01-OTH",
    "title": "Complete SSRF in CONNECT-UDP -- No Address Validation",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Full SSRF -- remote attacker can reach any IP the kernel can reach, including cloud metadata endpoints, internal services, and loopback interfaces. This is a network-level compromise vector.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "static int resolve_target(struct tquic_connect_udp_tunnel *tunnel)\n{\n    struct tquic_connect_udp_target *target = &tunnel->target;\n    struct sockaddr_in *sin;\n    struct sockaddr_in6 *sin6;\n    int ret;\n\n    if (target->resolved)\n        return 0;\n\n    /* Try IPv4 first */\n    sin = (struct sockaddr_in *)&target->addr;\n    ret = in4_pton(target->host, strlen(target->host),\n                   (u8 *)&sin->sin_addr.s_addr, -1, NULL);\n    if (ret == 1) {\n        sin->sin_family = AF_INET;\n        sin->sin_port = htons(target->port);\n        target->resolved = true;\n        return 0;   /* <-- NO VALIDATION WHATSOEVER */\n    }\n    /* ... IPv6 path similarly unvalidated ... */\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The `resolve_target()` function parses the client-supplied target address but performs absolutely zero validation on the resolved IP address. A remote attacker connected via QUIC can use the CONNECT-UDP proxy to send UDP packets to any IP address reachable from the kernel, including loopback (127.0.0.1), link-local (169.254.x.x including AWS/GCP/Azure metadata at 169.254.169.254), all RFC1918 private ranges, and multicast addresses.",
    "fix_suggestion": "** Add address validation after `in4_pton`/`in6_pton` succeeds. Block at minimum: `ipv4_is_loopback()`, `ipv4_is_multicast()`, `ipv4_is_lbcast()`, `ipv4_is_zeronet()`, `ipv4_is_private_10()`, `ipv4_is_private_172()`, `ipv4_is_private_192()`, link-local (169.254.0.0/16), and the IPv6 equivalents. Provide a configurable allowlist/denylist for deployment flexibility.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_MASQUE_TUNNEL_AUDIT.md"
  },
  {
    "id": "CRITICAL-02-OTH",
    "title": "Hardcoded init_net Namespace Bypass in Socket Creation",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Complete network namespace isolation bypass. Containers can escape their network restrictions and access the host network. This is a container escape vulnerability.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "ret = sock_create_kern(&init_net, family, SOCK_DGRAM, IPPROTO_UDP, &sock);",
        "err = sock_create_kern(&init_net, family, SOCK_STREAM, IPPROTO_TCP, &sock);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** Both the CONNECT-UDP proxy and the TCP-over-QUIC tunnel create kernel sockets using the hardcoded `&init_net` network namespace instead of the namespace of the requesting process or connection. This completely defeats container network isolation.\n\n**Code (connect_udp.c:459):**\n```c\nret = sock_create_kern(&init_net, family, SOCK_DGRAM, IPPROTO_UDP, &sock);\n```\n\n**Code (tquic_tunnel.c:332):**\n```c\nerr = sock_create_kern(&init_net, family, SOCK_STREAM, IPPROTO_TCP, &sock);\n```",
    "fix_suggestion": "** Store a reference to the correct network namespace (`struct net *`) at connection establishment time (via `sock_net(sk)` from the original QUIC socket) and use that namespace for all subsequent socket creation.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_MASQUE_TUNNEL_AUDIT.md"
  },
  {
    "id": "CRITICAL-03-OTH",
    "title": "Unbounded Memory Allocation from Attacker-Controlled Capsule Length",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Remote denial-of-service via kernel memory exhaustion. Attacker can trigger OOM killer, killing arbitrary processes on the system.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "/* Header complete, allocate capsule */\nparser->cur_capsule = capsule_alloc(\n    parser->header.type,\n    parser->header.length,  /* <-- attacker-controlled u64 */\n    GFP_ATOMIC);",
        "struct capsule *capsule_alloc(u64 type, size_t payload_len, gfp_t gfp)\n{\n    struct capsule *cap;\n    /* ... allocate cap ... */\n    cap->type = type;\n    cap->length = payload_len;\n\n    if (payload_len > 0) {\n        cap->value = kmalloc(payload_len, gfp);  /* <-- NO UPPER BOUND CHECK */\n        if (!cap->value) {"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The capsule parser allocates memory based on the `header.length` field which is a varint decoded directly from network data. This is a `u64` value that can be up to 2^62. The `CAPSULE_MAX_PAYLOAD_SIZE` constant (65535) is defined but never checked in the allocation path. An attacker can send a capsule header with a multi-gigabyte length value, causing the kernel to attempt a massive allocation.\n\n**Code (capsule.c:427-430, in capsule_parser_feed):**\n```c\n/* Header complete, allocate capsule */\nparser->cur_capsule = capsule_alloc(\n    parser->header.type,\n    parser->header.length,  /* <-- attacker-controlled u64 */\n    GFP_ATOMIC);\n```\n\n**Code (capsule.c:241-257, capsule_alloc):**\n```c\nstruct capsule *capsule_alloc(u64 type, size_t payload_len, gfp_t gfp)\n{\n    struct capsule *cap;\n    /* ... allocate cap ... */\n    cap->type = type;\n    cap->length = payload_len;\n\n    if (payload_len > 0) {\n        cap->value = kmalloc(payload_len, gfp);  /* <-- NO UPPER BOUND CHECK */\n        if (!cap->value) {\n```",
    "fix_suggestion": "** Validate `parser->header.length <= CAPSULE_MAX_PAYLOAD_SIZE` immediately after header decode succeeds, before calling `capsule_alloc()`. Additionally, add the same check inside `capsule_alloc()` as defense-in-depth.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_MASQUE_TUNNEL_AUDIT.md"
  },
  {
    "id": "CRITICAL-04-OTH",
    "title": "No Address Validation in CONNECT-IP Packet Injection",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Remote attacker gains the ability to inject arbitrary IP packets into the kernel network stack. This enables SSRF to any local service, IP spoofing for reflection/amplification attacks, and netfilter bypass.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "int tquic_connect_ip_inject_packet(struct tquic_connect_ip_tunnel *tunnel,\n                                   struct sk_buff *skb)\n{\n    unsigned char *data;\n    u8 ip_version;\n\n    /* ... basic NULL/length checks ... */\n\n    data = skb->data;\n    ip_version = (data[0] >> 4) & 0x0f;\n\n    skb->dev = NULL;  /* No device association */\n    skb_reset_mac_header(skb);\n    skb_reset_network_header(skb);\n\n    if (ip_version == 4) {\n        skb->protocol = htons(ETH_P_IP);\n        ret = netif_rx(skb);  /* <-- Inject arbitrary packet into kernel */\n    }\n    /* ... IPv6 path similar ... */\n}",
        "static int connect_ip_validate_ip_header(struct sk_buff *skb, u8 *version)\n{\n    /* Only checks: version, IHL >= 5, length consistency */\n    /* NO check on source address, destination address */\n    /* NO check on protocol field */\n    /* NO check for RFC1918, loopback, multicast, link-local */\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The CONNECT-IP tunnel validates IP header structure (version, IHL, length) but never checks the destination or source addresses of forwarded packets. The `tquic_connect_ip_inject_packet()` function calls `netif_rx()` to inject arbitrary IP packets directly into the kernel network stack. An attacker can forge packets with any source/destination address, effectively gaining raw IP socket capability through the proxy.\n\n**Code (connect_ip.c:2047-2084):**\n```c\nint tquic_connect_ip_inject_packet(struct tquic_connect_ip_tunnel *tunnel,\n                                   struct sk_buff *skb)\n{\n    unsigned char *data;\n    u8 ip_version;\n\n    /* ... basic NULL/length checks ... */\n\n    data = skb->data;\n    ip_version = (data[0] >> 4) & 0x0f;\n\n    skb->dev = NULL;  /* No device association */\n    skb_reset_mac_header(skb);\n    skb_reset_network_header(skb);\n\n    if (ip_version == 4) {\n        skb->protocol = htons(ETH_P_IP);\n        ret = netif_rx(skb);  /* <-- Inject arbitrary packet into kernel */\n    }\n    /* ... IPv6 path similar ... */\n}\n```\n\n**Code (connect_ip.c:1029-1071, connect_ip_validate_ip_header):**\n```c\nstatic int connect_ip_validate_ip_header(struct sk_buff *skb, u8 *version)\n{\n    /* Only checks: version, IHL >= 5, length consistency */\n    /* NO check on source address, destination address */\n    /* NO check on protocol field */\n    /* NO check for RFC1918, loopback, multicast, link-local */\n}\n```",
    "fix_suggestion": "** Add source and destination address validation in `connect_ip_validate_ip_header()` or a new function called before `netif_rx()`. Block loopback, multicast, broadcast, link-local, RFC1918, and IPv4-mapped-IPv6 addresses. Set `skb->dev` to the tunnel's virtual network device so netfilter rules apply correctly.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_MASQUE_TUNNEL_AUDIT.md"
  },
  {
    "id": "CRITICAL-05-OTH",
    "title": "Authentication Bypass in QUIC-Aware Proxy",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Unauthenticated proxy access allows any network client to relay traffic through the server. This enables use as an open proxy for attacks, circumventing IP-based access controls.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "proxy->config.require_auth = false;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The QUIC-Aware Proxy initialization sets `require_auth = false` by default, and no authentication check is performed in the connection registration path. Any client that can establish a QUIC connection can register proxied connections and use CID cooperation to route traffic through the proxy.\n\n**Code (quic_proxy.c:524):**\n```c\nproxy->config.require_auth = false;\n```",
    "fix_suggestion": "** Set `require_auth = true` by default. Implement mandatory authentication (PSK, certificate, or token-based) in `tquic_quic_proxy_register_conn()` before processing any registration.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_MASQUE_TUNNEL_AUDIT.md"
  },
  {
    "id": "CRITICAL-06-OTH",
    "title": "Anti-Amplification Bypass via Atomic Counter Race",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** RFC 9000 anti-amplification limit bypass. A remote attacker can use the server as an amplification oracle during migration, amplifying data volume beyond the 3x limit. This violates the core anti-amplification guarantee of QUIC.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "bool tquic_path_anti_amplification_check(struct tquic_path *path, u64 bytes)\n{\n    u64 limit;\n    u64 sent, received;\n\n    if (!path->anti_amplification.active)\n        return true;\n\n    received = atomic64_read(&path->anti_amplification.bytes_received);\n    sent = atomic64_read(&path->anti_amplification.bytes_sent);\n    limit = received * TQUIC_ANTI_AMPLIFICATION_LIMIT;\n\n    if (sent + bytes > limit) {\n        /* ... blocked ... */\n        return false;\n    }\n    return true;\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The check and subsequent `tquic_path_anti_amplification_sent()` are not atomic. Two concurrent callers (e.g., output path and retransmission) can both pass the check simultaneously, each sending `bytes`, causing the total sent to exceed `3x received`. This is a classic TOCTOU (time-of-check-time-of-use) race.\n\nFurthermore, `received * TQUIC_ANTI_AMPLIFICATION_LIMIT` can overflow if `received` exceeds `U64_MAX / 3`. An attacker sending just above 6.1 exabytes would cause the limit to wrap to a small value, but this is practically unreachable.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_SOCKET_NETLINK_MIGRATION_AUDIT.md"
  },
  {
    "id": "CRITICAL-07",
    "title": "`tquic_shutdown()` Missing `lock_sock()` -- Race on Connection State",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Use-after-free or double-free of connection state.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "int tquic_sock_shutdown(struct socket *sock, int how)\n{\n    struct sock *sk = sock->sk;\n    struct tquic_sock *tsk = tquic_sk(sk);\n    int ret = 0;\n\n    if (tsk->conn && tsk->conn->state == TQUIC_CONN_CONNECTED) {\n        ret = tquic_conn_shutdown(tsk->conn);\n    }\n    // NO lock_sock() -- concurrent sendmsg/recvmsg can race"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `tquic_sock_shutdown()` reads and acts on `tsk->conn` and `tsk->conn->state` without acquiring `lock_sock()`. A concurrent `close()` or `sendmsg()` call can modify or free the connection while shutdown is in progress.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_SOCKET_NETLINK_MIGRATION_AUDIT.md"
  },
  {
    "id": "CRITICAL-08",
    "title": "`tquic_close()` Does Not Hold `lock_sock()` During Connection Teardown",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Double-free, use-after-free, kernel crash.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "void tquic_close(struct sock *sk, long timeout)\n{\n    struct tquic_sock *tsk = tquic_sk(sk);\n\n    if (tsk->conn) {\n        tquic_pm_conn_release(tsk->conn);\n        if (tsk->conn->state == TQUIC_CONN_CONNECTED ||\n            tsk->conn->state == TQUIC_CONN_CONNECTING) {\n            tquic_conn_close_with_error(tsk->conn, 0x00, NULL);\n        }\n    }\n    inet_sk_set_state(sk, TCP_CLOSE);\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `tquic_close()` does not call `lock_sock(sk)`. It accesses `tsk->conn` and calls `tquic_pm_conn_release()` and `tquic_conn_close_with_error()` without serialization. Multiple threads calling `close()` concurrently (or close + sendmsg) can cause double-free of path manager state and connection resources.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_SOCKET_NETLINK_MIGRATION_AUDIT.md"
  },
  {
    "id": "HIGH-11-OTH",
    "title": "`tquic_cid_pool_destroy()` Removes from rhashtable Under BH spinlock",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Use-after-free in CID lookup during connection teardown. A remote attacker sending packets during connection close can trigger UAF via the rhashtable lookup path.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "spin_lock_bh(&pool->lock);\n    list_for_each_entry_safe(entry, tmp, &pool->local_cids, list) {\n        if (cid_table_initialized && entry->state == CID_STATE_ACTIVE)\n            rhashtable_remove_fast(&tquic_cid_table, &entry->node,\n                                   cid_rht_params);\n        list_del(&entry->list);\n        kfree(entry);    // <--- immediate kfree, not kfree_rcu\n    }\n    spin_unlock_bh(&pool->lock);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `rhashtable_remove_fast()` is called, then `kfree(entry)` is called immediately. If there are concurrent `rhashtable_lookup_fast()` calls (which run under RCU), they may still be accessing the entry after `kfree()`. The correct pattern is to use `kfree_rcu()` or call `synchronize_rcu()` before freeing.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_SOCKET_NETLINK_MIGRATION_AUDIT.md"
  },
  {
    "id": "C-1",
    "title": "GSO Segment Accumulation Can Overflow SKB Tailroom",
    "category": "memory",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Kernel panic (BUG_ON in skb_put) or heap corruption if\nskb_over_panic is not enabled. Attacker can trigger by sending data that\ncauses many segments to be coalesced.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "static int __maybe_unused tquic_gso_add_segment(struct tquic_gso_ctx *gso,\n                                                const u8 *data, size_t len)\n{\n    if (gso->gso_segs >= TQUIC_GSO_MAX_SEGS)\n        return -ENOSPC;\n\n    if (len > gso->gso_size)\n        return -EINVAL;\n\n    /* Add data to GSO SKB */\n    skb_put_data(gso->gso_skb, data, len);\n\n    /* Pad to segment size if not the last */\n    if (len < gso->gso_size) {\n        memset(skb_put(gso->gso_skb, gso->gso_size - len), 0,\n               gso->gso_size - len);\n    }"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Validate cumulative bytes written against SKB tailroom\nbefore each `skb_put_data`/`skb_put` call, or check\n`skb_tailroom(gso->gso_skb) >= len` before the write.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "C-2",
    "title": "Slab Cache Decryption Buffer May Be Too Small for Payload",
    "category": "memory",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Slab corruption, potential code execution. Network-reachable by\na remote attacker sending crafted encrypted packets.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (likely(payload_len <= TQUIC_RX_BUF_SIZE)) {\n    decrypted = kmem_cache_alloc(tquic_rx_buf_cache, GFP_ATOMIC);\n    decrypted_from_slab = true;\n} else {\n    decrypted = kmalloc(payload_len, GFP_ATOMIC);\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Pass the output buffer size to `tquic_decrypt_payload`",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "C-3",
    "title": "Stream Data Delivery Uses u64 Length with u32 alloc_skb",
    "category": "memory",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Memory exhaustion DoS. An attacker can send many stream frames\nwith large length fields to exhaust kernel memory.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "static void quic_packet_deliver_stream_data(struct tquic_stream *stream, u64 offset,\n                                            const u8 *data, u64 len, bool fin)\n{\n    if (!stream || !data || len == 0)\n        return;\n\n    if (len > U32_MAX)\n        return;\n\n    skb = alloc_skb((unsigned int)len, GFP_ATOMIC);\n    if (!skb)\n        return;\n\n    skb_put_data(skb, data, len);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Cap `len` to a reasonable maximum (e.g., 16384 or the\nconnection's max_stream_data) before allocation.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "C-4",
    "title": "Missing SKB Tailroom Check in Coalesced Packet Output",
    "category": "memory",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Stack buffer overflow and SKB overflow if header exceeds 64 bytes.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (header_len > 0)\n    skb_put_data(skb, header, header_len);\n\nskb_put_data(skb, buf_stack, ctx.offset);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Add `BUILD_BUG_ON(TQUIC_MAX_HEADER_SIZE > 64)` or use\n`min(header_len, 64)` as a defense.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "C-5",
    "title": "quic_packet.c Stream Frame - Uncapped Stream Creation",
    "category": "memory",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Kernel OOM from remote attacker. Critical DoS vulnerability.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "stream = tquic_stream_lookup_internal(conn, stream_id);\nif (!stream) {\n    stream = tquic_stream_create_internal(conn, stream_id);\n    if (!stream)\n        return -ENOMEM;\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Replace `tquic_stream_create_internal` with\n`tquic_stream_open_incoming` which validates peer's MAX_STREAMS limit.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "C-6",
    "title": "Recursive Coalesced Packet Processing - Stack Exhaustion",
    "category": "memory",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Kernel stack overflow leading to panic. Network-triggerable.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "/* Process any remaining coalesced packets */\nif (next_skb)\n    return tquic_packet_process(conn, next_skb);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Convert recursion to iteration using a loop, or limit\ncoalesced packet depth to a small constant (e.g., 4, since RFC only expects\nInitial + Handshake + 1-RTT).",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "H-1",
    "title": "qlog TOCTOU Race Between Length Check and copy_to_user",
    "category": "memory",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Low practical risk due to json_len cap at 1024, but the pattern\nis fragile. Information disclosure if ring entry is reused.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "while (tail != head && total < count) {\n    ...\n    json_len = tquic_qlog_emit_json(qlog, entry, json_buf, 1024);\n    ...\n    if (total + json_len > count)\n        break;\n\n    spin_unlock_irqrestore(&qlog->lock, flags);\n\n    if (copy_to_user(buf + total, json_buf, json_len)) {"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "H-2",
    "title": "copy_from_user with User-Controlled Size in Socket Options",
    "category": "memory",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "case TQUIC_SCHEDULER: {\n    char name[TQUIC_SCHED_NAME_MAX];\n    ...\n    if (optlen < 1 || optlen >= TQUIC_SCHED_NAME_MAX)\n        return -EINVAL;\n\n    if (copy_from_sockptr(name, optval, optlen))\n        return -EFAULT;\n    name[optlen] = '\\0';"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "H-3",
    "title": "getsockopt PSK Identity - Missing Length Validation",
    "category": "memory",
    "severity": "S1",
    "confidence": "high",
    "impact": "** User-space buffer overflow. Not a kernel vulnerability per se,\nbut violates API contract and can cause user-space crashes.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (copy_to_user(optval, tsk->psk_identity, identity_len)) {\n    ...\n}\nif (put_user(identity_len, optlen))"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Add `if (identity_len > len) return -EINVAL;` before\nthe copy_to_user call.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "H-4",
    "title": "getsockopt Hostname - Same Missing Length Check",
    "category": "memory",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Same as H-3.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (copy_to_user(optval, hostname, hostname_len)) {\n    ...\n}\nif (put_user(hostname_len, optlen))"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "H-5",
    "title": "ALPN Name getsockopt - Same Pattern",
    "category": "memory",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "H-6",
    "title": "Netfilter Short Header DCID Parsing Uses Arbitrary Length",
    "category": "memory",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "info->dcid.len = 8;\nif (len < info->dcid.len)\n    info->dcid.len = len;\nmemcpy(info->dcid.id, p, info->dcid.len);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "H-7",
    "title": "tquic_output.c Payload Buffer Size Calculation",
    "category": "memory",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Low, since MTU is typically <= 9000. But if path->mtu is\ncorrupted (e.g., by a race or bug), `max_payload + 16` could wrap.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "payload_buf = skb_put(skb, max_payload + 16);\n\nctx.buf_len = max_payload - 128 - 16;  /* room for header + tag */"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Add `if (max_payload > 65535) max_payload = 1500;`\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "H-8",
    "title": "Zero-RTT Session Ticket Deserialization Trusts Length Fields",
    "category": "memory",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Potential heap corruption from malicious session ticket data.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "memcpy(out->psk, p, out->psk_len);\n...\nmemcpy(out->alpn, p, out->alpn_len);\n...\nmemcpy(out->transport_params, p, out->transport_params_len);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "M-1",
    "title": "snprintf Return Value Not Checked in qlog.c",
    "category": "memory",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Information truncation (not a security issue). But in some\ncompilers, `buflen - len` when len > buflen (both size_t) wraps to a huge\nvalue, causing snprintf to try to format a huge string. This is benign\nin practice.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "len = snprintf(buf, buflen, ...);     // Returns 1500 if buflen is 1024\nlen += snprintf(buf + len, buflen - len, ...);  // buflen - len underflows!"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Use `scnprintf` consistently (returns actual bytes\nwritten, not hypothetical) or check `if (len >= buflen) return;` after\neach snprintf.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "M-2",
    "title": "connect_ip.c Datagram Buffer Allocation from Attacker Data",
    "category": "memory",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Potential large allocation, bounded by transport parameter.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "datagram_len = context_id_size + skb->len;\n\nif (datagram_len > conn->datagram.max_send_size)\n    return -EMSGSIZE;\n\ndatagram_buf = kmalloc(datagram_len, GFP_ATOMIC);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "M-3",
    "title": "cert_verify.c - kmalloc(count + 1) Integer Overflow",
    "category": "memory",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Depends on TQUIC_MAX_CERT_SIZE value.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (count > TQUIC_MAX_CERT_SIZE)\n    return -EINVAL;\n\nkbuf = kmalloc(count + 1, GFP_KERNEL);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "M-4",
    "title": "Benchmark write() Handler - Stack Buffer for User Input",
    "category": "memory",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "char cmd[64];\n...\nif (count >= sizeof(cmd))\n    return -EINVAL;\n\nif (copy_from_user(cmd, buf, count))\n    return -EFAULT;\n\ncmd[count] = '\\0';"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "M-5",
    "title": "Interop Framework - Same Pattern",
    "category": "memory",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "M-6",
    "title": "tquic_proc.c - snprintf for SCID Hex Without Bounds Check",
    "category": "memory",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "snprintf(scid_hex + i * 2, 3, \"%02x\", entry->scid[i]);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "M-7",
    "title": "smartnic.c - kmalloc_array with Attacker-Influenced Count",
    "category": "memory",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Handled by existing validation. VERIFIED SAFE.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "pns = kmalloc_array(count, sizeof(u64), GFP_ATOMIC);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "M-8",
    "title": "tquic_output.c - CRYPTO Frame Output Without Tailroom Check",
    "category": "memory",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "skb_put_data(send_skb, frame_hdr, hdr_len);\nskb_put_data(send_skb, crypto_skb->data, data_len);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "M-9",
    "title": "http3_priority.c snprintf Priority Field Truncation",
    "category": "memory",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "written = snprintf(buf, buf_len, \"u=%u\", priority->urgency);\n...\nint added = snprintf(buf + written, buf_len - written, \", i\");"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "M-10",
    "title": "connect_udp.c URL Encoding Can Exceed Buffer",
    "category": "memory",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "snprintf(p, remaining, \"%%%02X\", (u8)*src);\n...\nwritten = snprintf(p, remaining, \"/%u/\", port);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "M-11",
    "title": "Multiple getsockopt Handlers Copy Fixed Structs Without Size Check",
    "category": "memory",
    "severity": "S2",
    "confidence": "high",
    "impact": "** User-space buffer overflow. Can corrupt user-space memory.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (copy_to_user(optval, &info, sizeof(info)))\n    return -EFAULT;\nif (put_user(sizeof(info), optlen))\n    return -EFAULT;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "L-1",
    "title": "memzero_explicit Used Correctly for Key Material",
    "category": "memory",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "L-2",
    "title": "Constant-Time Comparison Used for Integrity Tags",
    "category": "memory",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "return crypto_memneq(computed_tag, received_tag,\n                     TQUIC_RETRY_INTEGRITY_TAG_LEN) == 0;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "L-3",
    "title": "tquic_retry_rate_limit Potential Token Bucket Underflow",
    "category": "memory",
    "severity": "S3",
    "confidence": "high",
    "impact": "** Rate limiter could temporarily allow more tokens than intended\nafter long idle periods. Low severity.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "refill = (elapsed_ms / TQUIC_RETRY_RATE_LIMIT_REFILL_MS) *\n         TQUIC_RETRY_RATE_LIMIT_REFILL_AMOUNT;\ntquic_retry_rate_tokens = min_t(u32,\n                                tquic_retry_rate_tokens + refill,\n                                TQUIC_RETRY_RATE_LIMIT_TOKENS);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "L-4",
    "title": "nla_put Operations in Netlink Properly Handle Failure",
    "category": "memory",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "L-5",
    "title": "copy_from_sockptr in setsockopt Always Uses sizeof(type)",
    "category": "memory",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "L-6",
    "title": "Version Negotiation Response - dcid/scid_len Not Capped",
    "category": "memory",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "pkt_len = 7 + dcid_len + scid_len + sizeof(supported_versions);\n...\nmemcpy(p, scid, scid_len);\n...\nmemcpy(p, dcid, dcid_len);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "L-7",
    "title": "quic_exfil.c Decoy Packet Size Controlled by MTU",
    "category": "memory",
    "severity": "S3",
    "confidence": "high",
    "impact": "** OOM attempt if MTU is corrupted. Low likelihood.\n\n---",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "decoy_size = 64 + (rand_val % (shaper->mtu - 64 + 1));\n...\nmemset(skb_put(skb, decoy_size), 0x00, decoy_size);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "L-8",
    "title": "io_uring.c getsockopt Same len Validation Pattern",
    "category": "memory",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "L-9",
    "title": "tquic_ipv6.c MTU Info getsockopt",
    "category": "memory",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (copy_to_user(optval, &mtuinfo, sizeof(mtuinfo)))\n    return -EFAULT;\nif (put_user(sizeof(mtuinfo), optlen))\n    return -EFAULT;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: ULTRA_MEMORY_BOUNDS_AUDIT.md"
  },
  {
    "id": "CRIT-01",
    "title": "Server Accept CID Parsing Missing Bounds Checks -- Buffer Over-Read",
    "category": "correctness",
    "severity": "S0",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "/* tquic_conn_server_accept */\noffset = 5;\ndcid_len = data[offset++];     // Line 2450: No check that offset < len\nmemcpy(dcid.id, data + offset, dcid_len);  // No check dcid_len <= TQUIC_MAX_CID_LEN\ndcid.len = dcid_len;\noffset += dcid_len;\n\nscid_len = data[offset++];     // Line 2509: No check that offset < len\nif (offset + scid_len > len)\n    goto err_free;",
        "if (offset >= len) goto err_free;\ndcid_len = data[offset++];\nif (dcid_len > TQUIC_MAX_CID_LEN) goto err_free;\nif (offset + dcid_len > len) goto err_free;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Add bounds validation:\n```c\nif (offset >= len) goto err_free;\ndcid_len = data[offset++];\nif (dcid_len > TQUIC_MAX_CID_LEN) goto err_free;\nif (offset + dcid_len > len) goto err_free;\n```\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CORE_PROTOCOL_AUDIT.md"
  },
  {
    "id": "CRIT-02",
    "title": "Version Negotiation Packet Overflow -- Unsanitized CID Lengths in tquic_send_version_negotiation",
    "category": "correctness",
    "severity": "S0",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "int tquic_send_version_negotiation(struct tquic_connection *conn,\n                                   const struct tquic_cid *dcid,\n                                   const struct tquic_cid *scid)\n{\n    u8 packet[256];\n    u8 *p = packet;\n\n    *p++ = 0x80;\n    *p++ = 0x00; *p++ = 0x00; *p++ = 0x00; *p++ = 0x00;\n\n    *p++ = scid->len;\n    memcpy(p, scid->id, scid->len);   // Line 961\n    p += scid->len;\n\n    *p++ = dcid->len;\n    memcpy(p, dcid->id, dcid->len);   // Line 965\n    p += dcid->len;\n\n    for (i = 0; tquic_supported_versions[i] != 0; i++) {\n        u32 ver = cpu_to_be32(tquic_supported_versions[i]);\n        memcpy(p, &ver, 4);           // Line 971\n        p += 4;\n    }"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Calculate required size upfront and validate against `sizeof(packet)`.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CORE_PROTOCOL_AUDIT.md"
  },
  {
    "id": "CRIT-03",
    "title": "Handshake Packet Parsing with Unvalidated Offsets",
    "category": "correctness",
    "severity": "S0",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (len > 20) {\n    size_t hdr_offset;\n    u8 dcid_len, scid_len;\n    ...\n    hdr_offset = 5;\n    dcid_len = data[hdr_offset++];       // Line 1932\n    hdr_offset += dcid_len;              // No bounds check\n    scid_len = data[hdr_offset++];       // Line 1934: May be past buffer end\n    hdr_offset += scid_len;              // No bounds check\n\n    token_len = data[hdr_offset];        // Line 1938: May be past buffer end\n    ...\n    hdr_offset += token_len_size + token_len;  // Line 1947\n\n    pkt_length = data[hdr_offset];       // Line 1950: May be past buffer end\n    ...\n    hdr_offset += length_size;\n    hdr_offset += 4;                     // Line 1961\n\n    payload_offset = hdr_offset;\n\n    if (payload_offset < len &&\n        data[payload_offset] == 0x06) {  // Line 1967"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Replace the ad-hoc parsing with calls to the existing safe header parser `tquic_parse_long_header()`, or add proper bounds checks before every `data[hdr_offset]` access.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CORE_PROTOCOL_AUDIT.md"
  },
  {
    "id": "CRIT-04",
    "title": "Retry Token Validation -- Plaintext Buffer Overread",
    "category": "correctness",
    "severity": "S0",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "/* Copy ciphertext to plaintext buffer for in-place decryption */\nmemcpy(plaintext, token + TQUIC_RETRY_TOKEN_IV_LEN, ciphertext_len);",
        "u8 plaintext[128];\nciphertext_len = token_len - TQUIC_RETRY_TOKEN_IV_LEN;",
        "token_len >= TQUIC_RETRY_TOKEN_IV_LEN + sizeof(ktime_t) + 1 + sizeof(u32) + TQUIC_RETRY_TOKEN_TAG_LEN"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Add `if (ciphertext_len > sizeof(plaintext)) return -EINVAL;` before the memcpy.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CORE_PROTOCOL_AUDIT.md"
  },
  {
    "id": "HIGH-01",
    "title": "Retry Packet Stack Buffer Overflow",
    "category": "correctness",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "int tquic_send_retry(...)\n{\n    u8 packet[512];\n    u8 *p = packet;\n    u8 token[TQUIC_RETRY_TOKEN_MAX_LEN];  // 256 bytes\n    ...\n    u8 pseudo_packet[512];\n    u8 *pp = pseudo_packet;\n    ...\n    *pp++ = original_dcid->len;\n    memcpy(pp, original_dcid->id, original_dcid->len);\n    pp += original_dcid->len;\n\n    pkt_len = p - packet;\n    memcpy(pp, packet, pkt_len);     // Line 1379\n    pp += pkt_len;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Allocate `packet`, `token`, and `pseudo_packet` on the heap using `kmalloc`.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CORE_PROTOCOL_AUDIT.md"
  },
  {
    "id": "HIGH-02",
    "title": "Retry Token AEAD Key Set Under Non-IRQ-Safe Spinlock",
    "category": "correctness",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "spin_lock(&tquic_retry_aead_lock);\nret = crypto_aead_setkey(tquic_retry_aead, tquic_retry_token_key, ...);\n...\nret = crypto_aead_encrypt(req);\nspin_unlock(&tquic_retry_aead_lock);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Use a mutex instead of a spinlock, or use `spin_lock_bh`. Better yet, allocate a per-connection AEAD instance to avoid global locking entirely.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CORE_PROTOCOL_AUDIT.md"
  },
  {
    "id": "HIGH-03",
    "title": "Return Pointer to Stack/Lock-Protected Data in tquic_conn_get_active_cid",
    "category": "correctness",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "struct tquic_cid *tquic_conn_get_active_cid(struct tquic_connection *conn)\n{\n    ...\n    spin_lock_bh(&conn->lock);\n    list_for_each_entry(entry, &cs->remote_cids, list) {\n        if (!entry->retired) {\n            result = &entry->cid;\n            break;\n        }\n    }\n    spin_unlock_bh(&conn->lock);\n\n    return result;\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Copy the CID data into a caller-provided buffer while holding the lock, rather than returning a pointer to shared data.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CORE_PROTOCOL_AUDIT.md"
  },
  {
    "id": "HIGH-04",
    "title": "Anti-Amplification Integer Overflow",
    "category": "correctness",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (cs->is_server) {\n    u64 limit = cs->bytes_received_unvalidated * cs->amplification_limit;\n    if (cs->bytes_sent_unvalidated + bytes > limit) {"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Use `check_add_overflow` and `check_mul_overflow` for safe arithmetic.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CORE_PROTOCOL_AUDIT.md"
  },
  {
    "id": "HIGH-05",
    "title": "Coalesced Packet Splitting Assumes v1 Packet Type Encoding",
    "category": "correctness",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "/* Check for Initial packet (has token) */\nif ((data[offset] & QUIC_LONG_HEADER_TYPE_MASK) ==\n    (QUIC_PACKET_TYPE_INITIAL << QUIC_LONG_HEADER_TYPE_SHIFT)) {",
        "if ((data[offset] & QUIC_LONG_HEADER_TYPE_MASK) ==\n    (QUIC_PACKET_TYPE_RETRY << QUIC_LONG_HEADER_TYPE_SHIFT)) {"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Read the version field (bytes 1-4) and use `tquic_decode_packet_type()` for version-aware type detection.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CORE_PROTOCOL_AUDIT.md"
  },
  {
    "id": "HIGH-06",
    "title": "payload_len Subtraction Underflow in Long Header Parsing",
    "category": "correctness",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "hdr->header_len = offset;\n/* Adjust payload_len to not include packet number */\nhdr->payload_len -= hdr->pn_len;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Add `if (hdr->payload_len < hdr->pn_len) return -EPROTO;` before the subtraction.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CORE_PROTOCOL_AUDIT.md"
  },
  {
    "id": "MED-01",
    "title": "Retry Token Address Validation Uses Weak Hash",
    "category": "correctness",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "u32 hash = jhash(&sin->sin_addr, sizeof(sin->sin_addr), sin->sin_port);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Use `siphash` instead of `jhash` for address validation hashing.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CORE_PROTOCOL_AUDIT.md"
  },
  {
    "id": "MED-02",
    "title": "Token Hash Comparison Not Constant-Time",
    "category": "correctness",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (token_hash != expected_hash) {"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Use `crypto_memneq` for the comparison.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CORE_PROTOCOL_AUDIT.md"
  },
  {
    "id": "MED-03",
    "title": "CID Sequence Number Rollback on rhashtable Insert Failure",
    "category": "correctness",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "cs->next_local_cid_seq--;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Perform the sequence number increment inside the spinlock, or use atomic operations.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CORE_PROTOCOL_AUDIT.md"
  },
  {
    "id": "MED-04",
    "title": "Version Negotiation Packet Not Authenticated",
    "category": "correctness",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "int tquic_handle_version_negotiation(...)\n{\n    ...\n    if (cs->version_negotiation_done) {\n        tquic_conn_warn(conn, \"duplicate version negotiation\\n\");\n        return -EPROTO;\n    }\n    new_version = tquic_version_select(versions, num_versions);\n    ...\n    conn->version = new_version;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Check that the VN version list does NOT contain the version the client originally tried.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CORE_PROTOCOL_AUDIT.md"
  },
  {
    "id": "MED-05",
    "title": "Unbounded Pending Path Challenges",
    "category": "correctness",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "int tquic_send_path_challenge(struct tquic_connection *conn, struct tquic_path *path)\n{\n    ...\n    challenge = kzalloc(sizeof(*challenge), GFP_ATOMIC);\n    ...\n    list_add_tail(&challenge->list, &cs->pending_challenges);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Limit pending challenges to a reasonable maximum (e.g., 10).\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CORE_PROTOCOL_AUDIT.md"
  },
  {
    "id": "MED-06",
    "title": "ACK Frame Range Count Uses u64 Loop Variable Against size_t max_ranges",
    "category": "correctness",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (frame->ack.ack_range_count > max_ranges)\n    return -EOVERFLOW;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CORE_PROTOCOL_AUDIT.md"
  },
  {
    "id": "MED-07",
    "title": "Packet Number Decode Returns 0 on Invalid Input",
    "category": "correctness",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (len < 1 || len > 4)\n    return 0;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Return a sentinel value or use an error pointer pattern (pass pn by reference, return error code).\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CORE_PROTOCOL_AUDIT.md"
  },
  {
    "id": "MED-08",
    "title": "Connection State Not Checked in tquic_conn_handle_close",
    "category": "correctness",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "int tquic_conn_handle_close(struct tquic_connection *conn,\n                            u64 error_code, u64 frame_type,\n                            const char *reason, bool is_app)\n{\n    ...\n    /* Enter draining state */\n    tquic_conn_enter_draining(conn);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Check `conn->state` and early-return for DRAINING/CLOSED states.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CORE_PROTOCOL_AUDIT.md"
  },
  {
    "id": "LOW-01",
    "title": "Retry Integrity Tag Computed with Potentially-Failing AEAD",
    "category": "correctness",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "aead = crypto_alloc_aead(\"gcm(aes)\", 0, 0);\nif (!IS_ERR(aead)) {\n    ...\n    ret = crypto_aead_encrypt(req);\n    if (ret == 0) {\n        memcpy(p, tag, 16);\n        p += 16;\n    }\n    ...\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Return an error if the integrity tag cannot be computed rather than sending a tagless packet.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CORE_PROTOCOL_AUDIT.md"
  },
  {
    "id": "LOW-02",
    "title": "close_work Repurposes drain_work for Retransmit Scheduling",
    "category": "correctness",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "static void tquic_close_work_handler(struct work_struct *work)\n{\n    ...\n    if (cs->close_retries < 3) {\n        tquic_send_close_frame(conn);\n        schedule_delayed_work(&cs->drain_work,\n                              msecs_to_jiffies(1000));\n    }"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Use a separate delayed_work for close retransmission.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CORE_PROTOCOL_AUDIT.md"
  },
  {
    "id": "LOW-03",
    "title": "HMAC Output Not Zeroized on Fallback Path",
    "category": "correctness",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "fallback:\n    kfree(desc);\n    crypto_free_shash(tfm);\n    tquic_stateless_reset_generate_token(cid, static_key, token);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Add `memzero_explicit(hmac_out, sizeof(hmac_out));` before `goto fallback`.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CORE_PROTOCOL_AUDIT.md"
  },
  {
    "id": "LOW-04",
    "title": "Version Negotiation First Byte Missing Fixed Bit Randomization",
    "category": "correctness",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "*p++ = 0x80;  /* Long header */"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CORE_PROTOCOL_AUDIT.md"
  },
  {
    "id": "LOW-05",
    "title": "Duplicate CID Not Checked in tquic_conn_add_remote_cid",
    "category": "correctness",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "int tquic_conn_add_remote_cid(struct tquic_connection *conn,\n                              const struct tquic_cid *cid, u64 seq, ...)\n{\n    ...\n    entry = tquic_cid_entry_create(cid, seq);\n    ...\n    list_add_tail(&entry->list, &cs->remote_cids);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Check for existing seq before adding.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CORE_PROTOCOL_AUDIT.md"
  },
  {
    "id": "C-1",
    "title": "Retry Token Address Validation Uses Non-Constant-Time Comparison",
    "category": "correctness",
    "severity": "S0",
    "confidence": "high",
    "impact": "** LOW practical impact since AEAD already protects the token, but fails defense-in-depth best practice.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "memcpy(&token_hash, p, sizeof(token_hash));\nif (token_hash != expected_hash) {\n    tquic_conn_dbg(conn, \"retry token address mismatch\\n\");\n    return -EINVAL;\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The retry token validation compares the address hash using a direct `!=` comparison. While the address hash itself is not a secret, the comparison of the overall token uses AEAD decryption (which is constant-time), but the subsequent hash comparison reveals whether the decryption produced a valid address. An attacker could use timing differences to distinguish between \"bad decryption\" (fast failure) and \"decryption succeeded but address doesn't match\" (slightly slower).",
    "fix_suggestion": "** Use `crypto_memneq()` for the hash comparison, or accept the current design as adequate given AEAD authentication.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "C-2",
    "title": "Connection State Transition Not Fully Atomic",
    "category": "correctness",
    "severity": "S0",
    "confidence": "high",
    "impact": "** A race condition could cause the connection to skip required cleanup steps (e.g., skipping DRAINING when going directly to CLOSED), potentially leaking resources or causing use-after-free if work items execute on freed state.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "static int tquic_conn_set_state(struct tquic_connection *conn,\n                                enum tquic_conn_state new_state,\n                                enum tquic_state_reason reason)\n{\n    // ... state validation ...\n    conn->state = new_state;\n    // ... entry actions (scheduling work, waking waiters) ...\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `tquic_conn_set_state()` performs the state transition and entry actions without holding a lock. The caller is expected to hold `conn->lock`, but this is not enforced by the function itself. Multiple callers from different contexts (timer callbacks, packet reception, socket operations) could race to transition state. Specifically:\n- `tquic_handle_stateless_reset()` at `/Users/justinadams/Downloads/tquic-kernel/net/tquic/tquic_input.c:398` directly sets `conn->state = TQUIC_CONN_CLOSED` under `conn->lock`, bypassing the state machine validation entirely.",
    "fix_suggestion": "** All state transitions MUST go through `tquic_conn_set_state()`, and the function should assert/acquire `conn->lock` internally. Fix `tquic_handle_stateless_reset()` to use the state machine.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "C-3",
    "title": "ECN CE Count Processing Does Not Track Deltas",
    "category": "correctness",
    "severity": "S0",
    "confidence": "high",
    "impact": "** A malicious peer can cause severe, spurious congestion responses by repeatedly reporting the same CE count, effectively throttling a legitimate connection to near-zero throughput.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (has_ecn && ecn_ce > 0) {\n    /*\n     * Track previous ECN-CE count to detect increase.\n     * For now, treat any reported CE count as new marks.\n     */\n    tquic_cong_on_ecn(ctx->path, ecn_ce);\n    ...\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** RFC 9002 Section 7.1 requires that congestion control respond only to **increases** in the ECN-CE counter: \"Each increase in the ECN-CE counter is a signal of congestion.\" The current implementation treats the raw CE count as the delta, which means if a peer reports CE=5 in every ACK, the congestion controller will react 5 times per ACK rather than only when the count increases. This directly violates RFC 9002.",
    "fix_suggestion": "** Store the previous ECN counts per path (in `struct tquic_ecn_tracking`) and only call `tquic_cong_on_ecn()` with the delta when `ecn_ce > path->ecn.ce_count`. Update the stored count after processing.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "C-4",
    "title": "RTT Estimation Uses Approximation Instead of Per-Packet Tracking",
    "category": "correctness",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Incorrect RTT estimates directly affect PTO calculation (RFC 9002), loss detection thresholds, and congestion control behavior. This could cause premature retransmissions, failed loss detection, or incorrect persistent congestion detection.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "rtt_us = ktime_us_delta(now, ctx->path->last_activity);\nif (rtt_us > ack_delay_us)\n    rtt_us -= ack_delay_us;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The RTT sample is computed using `path->last_activity` as an approximation of the sent time. RFC 9002 Section 5.1 requires: \"An RTT sample MUST NOT be generated on receiving an ACK frame that does not newly acknowledge at least one ack-eliciting packet.\" The approximation can produce wildly inaccurate RTT samples, especially on paths with multiple in-flight packets.",
    "fix_suggestion": "** Implement per-packet sent-time tracking in the `tquic_sent_packet` structure and look up the actual send time of the largest newly-acknowledged packet when processing ACKs.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "C-5",
    "title": "`ack_delay` Exponent Hardcoded to Default",
    "category": "correctness",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Incorrect ACK delay scaling leads to incorrect RTT estimation per RFC 9002 Section 5.3, which cascades into incorrect PTO, loss detection, and congestion control.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "u64 ack_delay_us = ack_delay * 8;  /* Default exponent = 3 */"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The ACK delay exponent is hardcoded to 3 (multiplier 8). RFC 9000 Section 18.2 specifies that this value is negotiated via the `ack_delay_exponent` transport parameter. If the peer negotiates a different exponent, all ACK delay values will be misinterpreted.",
    "fix_suggestion": "** Use the negotiated `ack_delay_exponent` from the peer's transport parameters: `ack_delay_us = ack_delay << conn->remote_params.ack_delay_exponent`.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "C-6",
    "title": "`tquic_varint_len()` Returns 0 for Invalid Values Without Error Propagation",
    "category": "correctness",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Attacker-controlled values (e.g., stream IDs, offsets) that exceed the varint maximum could be silently encoded as 0 bytes, corrupting packet contents and potentially causing protocol violations.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "static inline int tquic_varint_len(u64 val)\n{\n    // ... (declared elsewhere but used here)\n}\n\nstatic inline int tquic_encode_varint(u8 *buf, size_t buf_len, u64 val)\n{\n    int len = tquic_varint_len(val);\n    if (len > buf_len)\n        return -ENOSPC;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** If `tquic_varint_len()` returns 0 (value too large), the check `len > buf_len` evaluates to `0 > buf_len` which is always false for `size_t`. The function would then enter the switch statement with `len=0`, falling through to no case and returning 0 (success with 0 bytes written). This silently truncates varint values that exceed 2^62-1.",
    "fix_suggestion": "** Add explicit check: `if (len == 0) return -EOVERFLOW;`",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "C-7",
    "title": "Stream Frame Without Length Allows Reading Past Decrypted Buffer",
    "category": "correctness",
    "severity": "S0",
    "confidence": "high",
    "impact": "** LOW - the design is correct as long as the frame dispatcher respects the protocol requirement that a frame without a length field must be the last frame. However, the code lacks an explicit assertion or comment in the dispatcher to enforce this invariant.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "} else {\n    /* Length extends to end of packet */\n    length = ctx->len - ctx->offset;\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** When a STREAM frame does not have the LENGTH bit set, the code assumes the data extends to the end of the buffer. However, `ctx->len` represents the total payload length, which may include subsequent frames in the same packet. Per RFC 9000 Section 19.8, a STREAM frame without the LENGTH bit \"extends to the end of the packet.\" Since this is the last frame in a packet, this is correct in theory, but the frame dispatcher (the caller of this function) should not call any further frame processing after a length-less STREAM frame. If the dispatcher continues processing, it would find `ctx->offset == ctx->len` and cleanly exit, so this is safe.",
    "fix_suggestion": "** Add a flag to `tquic_rx_ctx` that records when a length-less STREAM frame is processed, and assert in the dispatcher that no further frames follow.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "H-1",
    "title": "`bytes_acked` Estimate Based on First ACK Range is Grossly Inaccurate",
    "category": "correctness",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Congestion controller can be manipulated by a malicious peer to increase sending rate far beyond what the network can handle (ACK amplification/optimistic ACK attack).",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "u64 bytes_acked = (first_ack_range + 1) * 1200;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The bytes acknowledged calculation multiplies the ACK range count by a fixed 1200-byte MTU estimate. This is incorrect for several reasons: (1) packets vary in size, (2) only the first ACK range is used ignoring additional ranges, (3) the value 1200 is the minimum QUIC packet size, not typical size. A malicious peer could send ACK frames claiming to acknowledge many packets, causing the congestion controller to inflate CWND inappropriately.",
    "fix_suggestion": "** Track actual sent bytes per packet in `tquic_sent_packet.sent_bytes` and sum the bytes of newly acknowledged packets.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "H-2",
    "title": "Missing `retire_prior_to > seq_num` Validation in NEW_CONNECTION_ID Processing",
    "category": "correctness",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Could force retirement of all CIDs, potentially causing connection failure or forcing use of a specific CID controlled by the attacker.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** When processing NEW_CONNECTION_ID frames, the code does not validate that `retire_prior_to <= seq_num` as required by RFC 9000 Section 19.15: \"The value in the Retire Prior To field MUST be less than or equal to the value in the Sequence Number field.\" A malicious peer sending `retire_prior_to > seq_num` could cause retirement of CIDs that should remain active.",
    "fix_suggestion": "** Add validation: `if (retire_prior_to > seq_num) return -EPROTO;`",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "H-3",
    "title": "Stateless Reset Handling Bypasses Connection State Machine",
    "category": "correctness",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Pending work items may fire after the connection is freed, causing use-after-free.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "static void tquic_handle_stateless_reset(struct tquic_connection *conn)\n{\n    spin_lock_bh(&conn->lock);\n    conn->state = TQUIC_CONN_CLOSED;\n    // ...\n    spin_unlock_bh(&conn->lock);\n    if (sk)\n        sk->sk_state_change(sk);\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** This directly sets the connection state to CLOSED, bypassing `tquic_conn_set_state()` and all its cleanup logic (canceling work items, flushing drain timer, etc.). This means pending work items (close_work, migration_work, drain_work, validation_work) are not canceled.",
    "fix_suggestion": "** Use the state machine: call `tquic_conn_set_state(conn, TQUIC_CONN_CLOSED, TQUIC_REASON_PEER_CLOSE)` instead.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "H-4",
    "title": "`tquic_output.c` Encode Varint Does Not Check for 0 Return from `tquic_varint_len`",
    "category": "correctness",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Protocol messages could be constructed with missing fields, causing the peer to misparse them.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The `tquic_encode_varint()` inline function calls `tquic_varint_len()` which can return 0 for values exceeding `TQUIC_VARINT_MAX`. If `len` is 0, the check `if (len > buf_len)` passes (0 is never > any size_t), and the switch falls through with no case matched, returning 0. This means the caller thinks 0 bytes were written (success with no data), silently dropping the varint.",
    "fix_suggestion": "** Add `if (len == 0) return -EOVERFLOW;` after the `tquic_varint_len()` call.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "H-5",
    "title": "STREAM Frame `length` Validation Allows Up to 65535 Bytes Per Frame",
    "category": "correctness",
    "severity": "S1",
    "confidence": "high",
    "impact": "** MEDIUM - could cause interoperability issues with peers sending large STREAM frames. The limit should be the remaining packet length, which is already checked on line 912.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (length > 65535)\n    return -EINVAL;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** This limit is arbitrary and not from the RFC. RFC 9000 does not impose a per-frame length limit beyond the packet size. While the intent is resource protection, the limit means legitimate peers sending frames up to the maximum UDP payload size minus overhead (~65,200 bytes) could be rejected if they happen to exceed 65535.",
    "fix_suggestion": "** Remove the 65535 limit since line 912 already validates against the actual packet bounds.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "H-6",
    "title": "`tquic_conn_retire_cid()` Does Not Remove CID from Lookup Hash Table",
    "category": "correctness",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Per RFC 9000 Section 5.1.2: \"An endpoint SHOULD stop accepting packets sent to a retired connection ID.\" Continuing to accept packets on retired CIDs defeats the privacy benefits of CID rotation and could enable tracking.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** When retiring a CID, the code marks `entry->retired = true` but does not remove the entry from `cid_lookup_table` (the rhashtable). This means the global lookup table still maps the retired CID to this connection. A peer could continue using a retired CID and the connection would still be found via hash lookup.",
    "fix_suggestion": "** Call `rhashtable_remove_fast()` when retiring a local CID.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "H-7",
    "title": "Missing Validation of `first_ack_range` Against `largest_ack`",
    "category": "correctness",
    "severity": "S1",
    "confidence": "high",
    "impact": "** A malicious peer sending `first_ack_range > largest_ack` could cause integer underflow in ACK range calculations, potentially marking packet numbers that were never sent as acknowledged.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** RFC 9000 Section 19.3.1 states: \"The First ACK Range value is the value of the Largest Acknowledged field minus the smallest packet number acknowledged in this range.\" Therefore `first_ack_range` MUST be <= `largest_ack`. Neither the frame parser nor the input processor validates this constraint.",
    "fix_suggestion": "** Add validation: `if (first_ack_range > largest_ack) return -EPROTO;`",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "H-8",
    "title": "Stream State Machine Allows Unexpected Transitions from OPEN",
    "category": "correctness",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Bidirectional streams cannot properly half-close, which would break applications that shut down one direction while keeping the other open.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "case TQUIC_STREAM_OPEN:\n    /* Can go to SIZE_KNOWN, DATA_SENT, RESET_SENT, RESET_RECVD */\n    if (new_state != TQUIC_STREAM_SIZE_KNOWN &&\n        new_state != TQUIC_STREAM_DATA_SENT &&\n        new_state != TQUIC_STREAM_RESET_SENT &&\n        new_state != TQUIC_STREAM_RESET_RECVD)\n        return -EINVAL;\n    break;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** Per RFC 9000 Figure 3 (bidirectional stream states), OPEN can transition to SEND (half-close receiving) or RECV (half-close sending), SIZE_KNOWN (recv side), DATA_SENT (send side), RESET_SENT (send side), or RESET_RECVD (recv side). The current implementation is missing SEND and RECV transitions from OPEN.",
    "fix_suggestion": "** Add TQUIC_STREAM_SEND and TQUIC_STREAM_RECV as valid transitions from OPEN.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "H-9",
    "title": "`ext->final_size = -1` Uses Signed Overflow",
    "category": "correctness",
    "severity": "S1",
    "confidence": "high",
    "impact": "** LOW - functionally correct but poor code clarity. Any comparison against 2^62-1 limits would pass incorrectly if the sentinel is not properly handled.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "ext->final_size = -1;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `final_size` is likely a `u64` field. Assigning `-1` produces `U64_MAX` (0xFFFFFFFFFFFFFFFF). While this is a common sentinel pattern, RFC 9000 limits stream data offsets to 2^62-1. Using U64_MAX as \"unknown\" is correct but should use a named constant like `TQUIC_STREAM_SIZE_UNKNOWN` to avoid confusion.",
    "fix_suggestion": "** Define `#define TQUIC_STREAM_SIZE_UNKNOWN U64_MAX` and use it consistently.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "H-10",
    "title": "Retry Packet Version Encoding Is Hardcoded for v1",
    "category": "correctness",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Retry packets are malformed on v2 connections and on little-endian architectures, causing connection establishment failures.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "*p++ = 0xf0;  /* Long header, Retry type */\nmemcpy(p, &conn->version, 4);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The first byte `0xf0` encodes Retry type as `0b11` (bits 4-5) which is the QUIC v1 encoding. For QUIC v2 (RFC 9369), Retry type is `0b00`. If the connection negotiated v2, this produces an invalid packet type.\n\nAdditionally, `conn->version` is copied in host byte order, not network byte order. This would produce corrupted version fields on little-endian systems.",
    "fix_suggestion": "** Use `tquic_encode_packet_type()` for the header byte and `cpu_to_be32(conn->version)` for the version field.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "H-11",
    "title": "Retry Integrity Tag Uses Wrong Key/Nonce for QUIC v2",
    "category": "correctness",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Retry integrity verification fails for QUIC v2 connections, preventing address validation.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The retry integrity key and nonce are hardcoded for QUIC v1. RFC 9369 Section 3.4.2 specifies different keys for QUIC v2:",
    "fix_suggestion": "** Select retry integrity key/nonce based on `conn->version`.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "H-12",
    "title": "Version Negotiation Packet Missing Randomized First Byte",
    "category": "correctness",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Middlebox ossification - fixed patterns allow NATs/firewalls to fingerprint QUIC version negotiation packets.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "*p++ = 0x80;  /* Long header */"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** RFC 9000 Section 17.2.1 states for Version Negotiation: \"The value of the unused fields is selected randomly.\" The first byte should have random bits in the type-specific fields (bits 0-5). The current implementation uses a fixed `0x80`, making VN packets distinguishable by middleboxes (ossification risk).",
    "fix_suggestion": "** Use `get_random_bytes(&first_byte, 1); first_byte |= 0x80;` similar to the function in `tquic_input.c:523`.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "M-1",
    "title": "`tquic_fc_conn_data_sent()` Race Between Check and Update",
    "category": "correctness",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** Although the function holds `fc->conn.lock`, the caller may have checked `tquic_fc_conn_can_send()` and then called `tquic_fc_conn_data_sent()` without atomicity between the two calls. Another thread could have consumed the credit between check and update.",
    "fix_suggestion": "** Provide a combined `tquic_fc_conn_try_send()` that atomically checks and commits.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "M-2",
    "title": "`kmem_cache_create()` Per Stream Manager Risks Name Collision",
    "category": "correctness",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** Each stream manager creates slab caches with fixed names like `\"tquic_stream_ext\"`. `kmem_cache_create()` requires globally unique names; creating multiple stream managers (multiple connections) with the same cache name could fail or cause confusing sysfs entries.",
    "fix_suggestion": "** Use a global slab cache shared across all stream managers, or include a unique identifier in the cache name.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "M-3",
    "title": "`additional_addr_add()` Has TOCTOU Between Duplicate Check and Insert",
    "category": "correctness",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The function releases `addrs->lock` after the duplicate check (line 188) and before the `kzalloc()` and re-acquisition (line 191 is outside the lock). Another thread could add the same address in between.",
    "fix_suggestion": "** Keep the lock held across the check-and-insert operation, or use a two-phase approach with lock re-check after allocation.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "M-4",
    "title": "`ring_index()` Uses Unbounded While Loop",
    "category": "correctness",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "static inline u32 ring_index(u32 head, s32 offset, u32 size)\n{\n    s32 idx = (s32)head + offset;\n    while (idx < 0)\n        idx += size;\n    return (u32)(idx % size);\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** If `size` is 0, this is an infinite loop. If `offset` is very negative (e.g., INT_MIN) and `size` is small, the loop could iterate billions of times.",
    "fix_suggestion": "** Add a guard: `if (size == 0) return 0;` and use modular arithmetic: `return ((idx % (s32)size) + size) % size;`",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "M-5",
    "title": "Anti-Replay Hash Table Cleanup Iterates All Buckets Under spinlock",
    "category": "correctness",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The anti-replay check iterates over all 4096 hash buckets under `anti_replay_state.lock` to clean expired entries. This is O(buckets) per check, executed for every 0-RTT packet.",
    "fix_suggestion": "** Use a separate periodic cleanup timer rather than inline cleanup, or maintain a time-ordered list for efficient expiration.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "M-6",
    "title": "`tquic_process_stream_frame()` Does Not Check Final Size Consistency",
    "category": "correctness",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (fin)\n    stream->fin_received = true;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** RFC 9000 Section 4.5 requires: \"Once a final size for a stream is known, it cannot change.\" The code does not check whether a previously received FIN specified a different final size than the current `offset + length`. Receiving data beyond a previously-indicated final size is a FINAL_SIZE_ERROR.",
    "fix_suggestion": "** When FIN is received, record `stream->final_size = offset + length`. On subsequent data, verify `offset + length <= stream->final_size` and that any new FIN matches the recorded value.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "M-7",
    "title": "Connection Close Does Not Validate Reason Phrase Encoding",
    "category": "correctness",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** RFC 9000 Section 19.19 states the reason phrase \"SHOULD be a UTF-8 encoded string.\" While not mandatory to validate, the reason_len is used to advance the offset without any sanity check against reasonable lengths. A 2^62-1 byte reason phrase would pass the check on line 1248 only if the packet was that large.",
    "fix_suggestion": "** The existing check is adequate for safety. Consider adding a reasonable maximum for logging purposes.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "M-8",
    "title": "`tquic_accept()` Holding `sk_lock.slock` Improperly",
    "category": "correctness",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The accept function acquires `sk->sk_lock.slock` (the BH spinlock) while already holding `sk_lock` (from `lock_sock()`). This nesting is technically valid (socket lock ordering allows this), but the inner spinlock is unnecessary because `lock_sock()` already provides exclusive access. The extra spinlock adds latency.",
    "fix_suggestion": "** Access the accept queue under `lock_sock()` alone without the additional spinlock.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "M-9",
    "title": "`tquic_poll()` Checks Stream Data Without Lock",
    "category": "correctness",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (conn && stream) {\n    if (!skb_queue_empty(&stream->recv_buf))\n        mask |= EPOLLIN | EPOLLRDNORM;\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `stream->recv_buf` is checked without holding any lock. While `skb_queue_empty()` reads `skb_queue_len()` which is updated atomically, there is a potential for the stream pointer itself to become invalid between the `READ_ONCE()` and the queue check.",
    "fix_suggestion": "** This is acceptable for poll() semantics (spurious wakeups are allowed), but document the intentional lockless access.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "L-1",
    "title": "Multiple Redundant Varint Implementations",
    "category": "correctness",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** There are at least 6 separate varint encode/decode implementations across the codebase. This increases maintenance burden and the chance of inconsistent behavior or bugs in one copy.",
    "fix_suggestion": "** Consolidate to a single implementation in `varint.c`/`varint.h` and use it everywhere.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "L-2",
    "title": "`established_time` Set Twice in Connection State Machine",
    "category": "correctness",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `conn->stats.established_time = ktime_get()` is set in both CONNECTING and CONNECTED entry actions. The CONNECTING value is immediately overwritten when transitioning to CONNECTED.",
    "fix_suggestion": "** Only set it in CONNECTED, or rename the CONNECTING one to `handshake_start_time`.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "L-3",
    "title": "`tquic_cid_compare()` Marked `__maybe_unused`",
    "category": "correctness",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The function is marked as possibly unused, suggesting dead code. Either it should be used or removed.",
    "fix_suggestion": "** Remove if truly unused, or remove the `__maybe_unused` annotation.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "L-4",
    "title": "Version Negotiation Packet Size Not Validated Against 256-Byte Buffer",
    "category": "correctness",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The VN packet is built in a 256-byte stack buffer. With two CIDs at maximum 20 bytes each and version list, the maximum size is `5 + 1 + 20 + 1 + 20 + 8 = 55` bytes, well within the 256-byte buffer. However, there is no explicit bounds check during packet construction.",
    "fix_suggestion": "** Add a bounds check or use the `p - packet < sizeof(packet)` idiom.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "L-5",
    "title": "`tquic_sysctl_prefer_v2()` Function Not Declared in Visible Header",
    "category": "correctness",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `tquic_sysctl_prefer_v2()` is called but not visible in any included header, relying on implicit declaration.",
    "fix_suggestion": "** Add a proper declaration in a shared header file.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "L-6",
    "title": "`sk->sk_err = -ret` Stores Negative Error Code",
    "category": "correctness",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "sk->sk_err = -ret;  /* Store error for getsockopt */"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `sk_err` is conventionally a positive errno value. The code negates `ret` (which is already negative), producing a positive value, so this is correct. However, the pattern is confusing.",
    "fix_suggestion": "** Add a comment: `/* ret is negative errno, sk_err needs positive */`",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "L-7",
    "title": "`tquic_store_session_ticket()` Does Not Store ALPN or Transport Parameters",
    "category": "correctness",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "plaintext.alpn_len = 0;\nplaintext.transport_params_len = 0;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The session ticket does not save the ALPN or transport parameters. RFC 9001 Section 4.6.1 requires that 0-RTT clients remember transport parameters from the session ticket. Without stored transport parameters, 0-RTT validation in `tquic_validate_zero_rtt_transport_params()` cannot properly compare old vs. new values.",
    "fix_suggestion": "** Populate `plaintext.alpn` and `plaintext.transport_params` from the connection state when storing session tickets.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "L-8",
    "title": "Slab Cache Names Are Not Module-Prefixed",
    "category": "correctness",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** Slab cache names like `\"tquic_stream_ext\"` should use a consistent prefix to avoid collisions with other kernel modules.",
    "fix_suggestion": "** Use names like `\"tquic_core_stream_ext\"` for clarity.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CORE_CORRECTNESS.md"
  },
  {
    "id": "CRITICAL-01",
    "title": "OCSP Stapling Response Accepted Without Any Verification",
    "category": "security",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Complete bypass of certificate revocation checking. A revoked certificate (e.g., due to key compromise) will be accepted as valid.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "int tquic_check_revocation(struct tquic_cert_verify_ctx *ctx,\n                           const struct tquic_x509_cert *cert)\n{\n    ...\n    /* Check OCSP stapling data if provided */\n    if (ctx->ocsp_stapling && ctx->ocsp_stapling_len > 0) {\n        /*\n         * OCSP response parsing would go here.\n         * For now, accept stapled responses as valid.\n         */\n        pr_debug(\"tquic_cert: OCSP stapling present (%u bytes)\\n\",\n                 ctx->ocsp_stapling_len);\n        return 0;  // <-- ACCEPTS ANY DATA AS VALID OCSP\n    }\n    ...\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** The OCSP response must be fully parsed per RFC 6960: verify the signature against the issuer CA or a designated OCSP responder, check the response status (good/revoked/unknown), validate thisUpdate/nextUpdate timestamps, and match the certificate serial number.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_CERT_0RTT.md"
  },
  {
    "id": "CRITICAL-02",
    "title": "Hard-Fail Revocation Mode Does Not Actually Fail",
    "category": "security",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Administrators who configure hard-fail revocation checking have a false sense of security. Revoked certificates without OCSP stapling will be accepted.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (ctx->check_revocation == TQUIC_REVOKE_HARD_FAIL) {\n        pr_warn(\"tquic_cert: Revocation check required but no OCSP stapling available\\n\");\n        /* In production, this should return an error.\n         * For now, allow to support existing deployments.\n         */\n    }\n\n    return 0;  // <-- RETURNS SUCCESS EVEN IN HARD_FAIL MODE"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** The function must return `-EKEYREVOKED` or a similar error when `TQUIC_REVOKE_HARD_FAIL` is set and revocation status cannot be determined.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_CERT_0RTT.md"
  },
  {
    "id": "CRITICAL-03",
    "title": "Client Certificate Verification Uses Server Logic (EKU Bypass)",
    "category": "security",
    "severity": "S0",
    "confidence": "high",
    "impact": "** EKU validation bypass for client certificates.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "int tquic_hs_verify_client_cert(struct tquic_handshake *hs,\n                                struct tquic_connection *conn)\n{\n    /* Client certificate verification uses same logic\n     * but checks for client auth EKU instead of server auth\n     */\n    return tquic_hs_verify_server_cert(hs, conn);\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** `tquic_hs_verify_client_cert` must call `verify_chain(ctx, false)` instead of delegating to the server verification function.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_CERT_0RTT.md"
  },
  {
    "id": "CRITICAL-04",
    "title": "Self-Signed Certificate Comparison Uses Non-Constant-Time memcmp in One Path",
    "category": "security",
    "severity": "S0",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (cert->issuer_raw && cert->subject_raw &&\n        cert->issuer_raw_len == cert->subject_raw_len &&\n        !crypto_memneq(cert->issuer_raw, cert->subject_raw, cert->issuer_raw_len)) {\n        cert->self_signed = true;\n    }",
        "if (cert->issuer_raw && cert->subject_raw &&\n        cert->issuer_raw_len == cert->subject_raw_len &&\n        memcmp(cert->issuer_raw, cert->subject_raw, cert->issuer_raw_len) == 0) {\n        ((struct tquic_x509_cert *)cert)->self_signed = true;\n    }"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Use `crypto_memneq` consistently. Remove the const-cast by refactoring to set `self_signed` during parse, not during verification.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_CERT_0RTT.md"
  },
  {
    "id": "CRITICAL-05",
    "title": "ASN.1 Time Parsing Does Not Validate Character Ranges",
    "category": "security",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Certificate validity period bypass via crafted ASN.1 time values.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "static int parse_time(const u8 *data, u32 len, s64 *time_out)\n{\n    ...\n    const char *t = (const char *)data + 1 + hdr_len;\n    year = (t[0] - '0') * 10 + (t[1] - '0');\n    year += (year < 50) ? 2000 : 1900;\n    month = (t[2] - '0') * 10 + (t[3] - '0');\n    day = (t[4] - '0') * 10 + (t[5] - '0');\n    hour = (t[6] - '0') * 10 + (t[7] - '0');\n    min = (t[8] - '0') * 10 + (t[9] - '0');\n    sec = (t[10] - '0') * 10 + (t[11] - '0');\n    ...\n    *time_out = mktime64(year, month, day, hour, min, sec);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Validate each character is an ASCII digit before arithmetic. Validate month (1-12), day (1-31), hour (0-23), minute (0-59), second (0-59).",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_CERT_0RTT.md"
  },
  {
    "id": "HIGH-01-SEC",
    "title": "RSA Signature Algorithm Hardcoded to SHA-256 Regardless of Certificate",
    "category": "security",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Certificates signed with RSA-SHA384 or RSA-SHA512 will not verify correctly. This could cause interoperability issues or, in edge cases, allow acceptance of improperly-verified signatures.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "case TQUIC_PUBKEY_ALGO_RSA:\n        alg_name = \"pkcs1pad(rsa,sha256)\";\n        break;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Construct the algorithm name dynamically from `cert->signature.hash_algo`, e.g., `\"pkcs1pad(rsa,sha384)\"` or `\"pkcs1pad(rsa,sha512)\"`.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_CERT_0RTT.md"
  },
  {
    "id": "HIGH-02-SEC",
    "title": "RSA-PSS Hash Algorithm Hardcoded to SHA-256",
    "category": "security",
    "severity": "S1",
    "confidence": "high",
    "impact": "** RSA-PSS certificates using SHA-384 or SHA-512 will have incorrect signature verification.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "} else if (oid_len == sizeof(oid_rsa_pss) &&\n               memcmp(oid, oid_rsa_pss, oid_len) == 0) {\n        /* RSA-PSS: hash algo determined from parameters */\n        *hash_algo = TQUIC_HASH_SHA256;\n        *pubkey_algo = TQUIC_PUBKEY_ALGO_RSA;\n    }"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Parse RSA-PSS AlgorithmIdentifier parameters to extract the actual hash algorithm.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_CERT_0RTT.md"
  },
  {
    "id": "HIGH-03-SEC",
    "title": "Bloom Filter Has High False Positive Rate at Scale",
    "category": "security",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Denial of service (0-RTT degradation) on busy servers. Not a security bypass but a reliability issue with security implications (users may disable anti-replay to fix performance).",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "#define TQUIC_REPLAY_BLOOM_BITS         (1 << 16)    /* 64K bits */\n#define TQUIC_REPLAY_BLOOM_HASHES       4             /* 4 hash functions */\n#define TQUIC_REPLAY_TTL_SECONDS        3600          /* 1 hour */"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Increase `TQUIC_REPLAY_BLOOM_BITS` to at least `(1 << 20)` (1M bits = 128KB) for production use, or make it configurable via sysctl.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_CERT_0RTT.md"
  },
  {
    "id": "HIGH-04-SEC",
    "title": "Ticket Store Free-After-Remove Race Condition",
    "category": "security",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Use-after-free. An attacker could trigger this by rapidly reconnecting to the same server, causing a ticket replacement while another thread reads the old ticket. In kernel context, this is exploitable for privilege escalation.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "old = ticket_store_find_locked(&global_ticket_store,\n                                   server_name, server_name_len);\n    if (old) {\n        ticket_store_remove_locked(&global_ticket_store, old);\n        ticket_free(old);  // <-- frees while refcount may be > 1\n    }",
        "static void ticket_free(struct tquic_zero_rtt_ticket *ticket)\n{\n    if (!ticket)\n        return;\n    kfree(ticket->ticket);\n    memzero_explicit(&ticket->plaintext, sizeof(ticket->plaintext));\n    kfree(ticket);  // <-- unconditional free\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** `ticket_store_remove_locked` should only remove from the tree/list. The actual free should happen via `tquic_zero_rtt_put_ticket` (refcount-based). Change `ticket_free(old)` to `tquic_zero_rtt_put_ticket(old)`.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_CERT_0RTT.md"
  },
  {
    "id": "HIGH-05-SEC",
    "title": "Session Ticket Decode Missing Bounds Check on PSK Copy",
    "category": "security",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "out->psk_len = *p++;\n    if (out->psk_len == 0 ||\n        out->psk_len > TQUIC_ZERO_RTT_SECRET_MAX_LEN) {\n        ret = -EINVAL;\n        goto out_free;\n    }\n    if (payload_len < 1 + out->psk_len + 4 + 8 + 2 + 1) {\n        ret = -EINVAL;\n        goto out_free;\n    }\n    memcpy(out->psk, p, out->psk_len);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_CERT_0RTT.md"
  },
  {
    "id": "HIGH-06-SEC",
    "title": "0-RTT Keys Derived With Empty Transcript (Not ClientHello Hash)",
    "category": "security",
    "severity": "S1",
    "confidence": "high",
    "impact": "** If two connections use the same PSK (which is the purpose of session resumption), they will have identical 0-RTT keys. Since packet numbers start from 0, the first packet of each connection will use the same nonce, causing AES-GCM nonce reuse -- a catastrophic cryptographic failure.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "/* For simplicity, we use an empty transcript here. The actual\n     * implementation should include the ClientHello hash.\n     */"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** The ClientHello hash must be included in the key derivation. Use `tquic_zero_rtt_derive_secret` (which does accept `client_hello_hash`) instead of `tquic_zero_rtt_derive_keys` for actual connections.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_CERT_0RTT.md"
  },
  {
    "id": "HIGH-07",
    "title": "Procfs trusted_cas Writable Without Privilege Check",
    "category": "security",
    "severity": "S1",
    "confidence": "high",
    "impact": "** In containerized environments, untrusted root processes might be able to add arbitrary trusted CAs, enabling MITM attacks.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "proc_create(\"trusted_cas\", 0644, tquic_cert_proc_dir,\n                &tquic_proc_trusted_cas_ops);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Add `capable(CAP_NET_ADMIN)` check in the write handler. Consider using 0600 permissions.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_CERT_0RTT.md"
  },
  {
    "id": "MEDIUM-01",
    "title": "asn1_get_length Does Not Handle Length 0x84+ (4+ byte lengths)",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "static int asn1_get_length(const u8 *data, u32 data_len, u32 *len, u32 *hdr_len)\n{\n    ...\n    } else if (data[0] == 0x83) {\n        if (data_len < 4)\n            return -EINVAL;\n        *len = (data[1] << 16) | (data[2] << 8) | data[3];\n        *hdr_len = 4;\n    } else {\n        return -EINVAL;\n    }"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_CERT_0RTT.md"
  },
  {
    "id": "MEDIUM-02",
    "title": "SAN DNS Names Not Validated for Embedded NUL Characters",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Hostname verification bypass via NUL-byte injection in SAN DNS names. This is a well-known attack vector (CVE-2009-2408 in NSS, CVE-2009-3555 variants).",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "names[name_count] = kmalloc(content_len + 1, GFP_KERNEL);\n    if (!names[name_count])\n        goto err_free;\n\n    memcpy(names[name_count], p + 1 + hdr_len, content_len);\n    names[name_count][content_len] = '\\0';"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Reject SAN DNS names containing NUL bytes (0x00). Add: `if (memchr(p + 1 + hdr_len, 0, content_len)) continue;`\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_CERT_0RTT.md"
  },
  {
    "id": "MEDIUM-03",
    "title": "Hostname Wildcard Matching Allows Wildcards in Non-Leftmost Position",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Overly permissive wildcard matching could allow a wildcard certificate to match unintended domains.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (pattern_len >= 2 && pattern[0] == '*' && pattern[1] == '.') {"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_CERT_0RTT.md"
  },
  {
    "id": "MEDIUM-04",
    "title": "Path Length Constraint Check Off-By-One",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (cert->path_len_constraint >= 0 &&\n        (int)(depth - 1) > cert->path_len_constraint) {"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_CERT_0RTT.md"
  },
  {
    "id": "MEDIUM-05",
    "title": "0-RTT Encrypt Allocates AEAD Per-Packet (Performance / Side Channel)",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Performance degradation (crypto_alloc_aead involves slab allocation, module loading checks, etc.). Minor timing side channel.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "aead = crypto_alloc_aead(tquic_cipher_to_aead_name(state->cipher_suite), 0, 0);\n    if (IS_ERR(aead))\n        return PTR_ERR(aead);\n\n    ret = crypto_aead_setkey(aead, state->keys.key, state->keys.key_len);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Allocate the AEAD transform once during key derivation and store it in `tquic_zero_rtt_keys`. Reuse for all packets.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_CERT_0RTT.md"
  },
  {
    "id": "MEDIUM-06",
    "title": "Bloom Filter Seeds Never Rotated",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "** After seed recovery, an attacker could craft tickets that always collide (causing DoS via false positives) or never collide (bypassing replay detection).",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "/*\n * Seeds are NOT rotated after initialization because rotating seeds\n * invalidates all existing bloom filter entries...\n */\nstatic u32 replay_hash_seed1 __read_mostly;\nstatic u32 replay_hash_seed2 __read_mostly;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Use 64-bit seeds (siphash instead of jhash) and rotate seeds during bucket rotation, hashing any remaining entries into the new bucket with new seeds.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_CERT_0RTT.md"
  },
  {
    "id": "MEDIUM-07",
    "title": "Key Material Not Zeroized on All Error Paths in tquic_zero_rtt_derive_keys",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Key material leak on error paths. The secret could be recovered from kernel memory dumps.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "out:\n    memzero_explicit(early_secret, sizeof(early_secret));\n    crypto_free_shash(hash);\n    return ret;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Add `if (ret) memzero_explicit(keys, sizeof(*keys));` before the `out:` label, or zeroize in the `out:` path when `ret != 0`.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_CERT_0RTT.md"
  },
  {
    "id": "MEDIUM-08",
    "title": "Certificate Chain Parsing Does Not Verify Issuer-Subject Linkage Before Trust Check",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "** A certificate that appears in the keyring but has been tampered with (different public key or extensions) could be accepted without signature verification.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "/* Check if this certificate is a trust anchor */\n    ret = find_trust_anchor(ctx, cert);\n    if (ret == 0) {\n        /* Found trust anchor, chain is valid */\n        return 0;\n    }"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_CERT_0RTT.md"
  },
  {
    "id": "LOW-01-SEC",
    "title": "parse_basic_constraints Hardcoded BOOLEAN Length",
    "category": "security",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (p < end && p[0] == 0x01) {  /* BOOLEAN */\n        if (p + 3 <= end) {\n            *is_ca = (p[2] != 0);\n            p += 3;\n        }\n    }"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_CERT_0RTT.md"
  },
  {
    "id": "LOW-02-SEC",
    "title": "server_ticket_key Is Static Global Without Rotation",
    "category": "security",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "static u8 server_ticket_key[TQUIC_SESSION_TICKET_KEY_LEN];\nstatic bool server_ticket_key_valid;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Implement periodic key rotation (e.g., every 24 hours) with support for decrypting tickets encrypted with the previous key.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_CERT_0RTT.md"
  },
  {
    "id": "LOW-03-SEC",
    "title": "Empty Hash Computed Without Algorithm Validation",
    "category": "security",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Zero-initialize `empty_hash` or use `memzero_explicit` after use.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_CERT_0RTT.md"
  },
  {
    "id": "LOW-04-SEC",
    "title": "Inconsistent Error Return From verify_chain",
    "category": "security",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_CERT_0RTT.md"
  },
  {
    "id": "LOW-05-SEC",
    "title": "SAN Parsing Capacity Limit Check Could Be Tighter",
    "category": "security",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (name_capacity >= 10000)\n        goto err_free;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Reduce limit to 1000 or add a total allocation size limit.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_CERT_0RTT.md"
  },
  {
    "id": "CRITICAL-1",
    "title": "Stack buffer overflow in `tquic_hs_build_ch_extensions` -- no bounds checking on output buffer",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Heap corruption leading to arbitrary kernel code execution.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "static int tquic_hs_build_ch_extensions(struct tquic_handshake *hs,\n                                        u8 *buf, u32 buf_len, u32 *out_len)\n{\n    u8 *p = buf;\n    // ...\n    /* Supported Versions extension */\n    *p++ = (TLS_EXT_SUPPORTED_VERSIONS >> 8) & 0xff;\n    *p++ = TLS_EXT_SUPPORTED_VERSIONS & 0xff;\n    // ... ~170 bytes of direct writes ...\n    memcpy(p, hs->key_share.public_key, 32);\n    p += 32;\n    // ... ALPN, SNI, transport params, PSK identities ..."
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The function accepts `buf_len` but **never checks it**. The pointer `p`\nis advanced with `*p++` and `memcpy()` calls throughout the entire function without a\nsingle bounds check against `buf + buf_len`. The caller in `tquic_hs_generate_client_hello`\npasses a 2048-byte buffer (`extensions = kzalloc(2048, GFP_KERNEL)`), but the actual\nwritten size depends on attacker-influenced data: ALPN strings, SNI hostname, transport\nparameters (up to 1024 bytes from a stack buffer), and PSK identities (whose\n`identity_len` is user-controlled). A long SNI + many ALPN entries + large PSK identity\ndata can exceed 2048 bytes.",
    "fix_suggestion": "** Add bounds checking throughout `tquic_hs_build_ch_extensions`. Every\nwrite to `p` must verify `p + N <= buf + buf_len` before writing. Use a macro similar to\n`TP_CHECK_SPACE` from the transport params encoder.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "CRITICAL-2",
    "title": "Stack buffer overflow in `tquic_hs_hkdf_expand_label` -- unbounded label/context write to 512-byte stack buffer",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Stack buffer overflow, kernel stack smashing, potential RCE.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "static int tquic_hs_hkdf_expand_label(struct tquic_handshake *hs,\n                                      const u8 *secret, u32 secret_len,\n                                      const char *label,\n                                      const u8 *context, u32 context_len,\n                                      u8 *out, u32 out_len)\n{\n    u8 hkdf_label[512];     // <-- stack buffer\n    u8 *p = hkdf_label;\n    u32 label_len = strlen(label);\n    u32 total_label_len = 6 + label_len;\n    // ...\n    *p++ = (out_len >> 8) & 0xff;\n    *p++ = out_len & 0xff;\n    *p++ = total_label_len;\n    memcpy(p, \"tls13 \", 6);\n    p += 6;\n    memcpy(p, label, label_len);\n    p += label_len;\n    *p++ = context_len;        // <-- truncated to u8\n    if (context_len > 0) {\n        memcpy(p, context, context_len);   // <-- no bounds check\n        p += context_len;\n    }",
        "/* Validate that hkdf_label fits in the stack buffer */\nif (3 + 6 + label_len + 1 + context_len > sizeof(hkdf_label))\n    return -EINVAL;\nif (context_len > 255)\n    return -EINVAL;  /* TLS context is at most 255 bytes */"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The `hkdf_label` stack buffer is 512 bytes. `context_len` is a `u32`\nparameter. If `context_len` exceeds approximately 500 bytes, the `memcpy` at line 762\nwrites past the end of the stack buffer. Additionally, `context_len` is written as a\nsingle byte (`*p++ = context_len`), which truncates values > 255, creating a mismatch\nbetween the written length and the actual copied data.\n\nWhile current internal callers pass small contexts (transcript hashes up to 48 bytes),",
    "fix_suggestion": "**\n```c\n/* Validate that hkdf_label fits in the stack buffer */\nif (3 + 6 + label_len + 1 + context_len > sizeof(hkdf_label))\n    return -EINVAL;\nif (context_len > 255)\n    return -EINVAL;  /* TLS context is at most 255 bytes */\n```\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "CRITICAL-3",
    "title": "No bounds checking on `buf` output in `tquic_hs_generate_client_hello`",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Heap or stack buffer overflow depending on caller's buffer allocation.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "int tquic_hs_generate_client_hello(struct tquic_handshake *hs,\n                                   u8 *buf, u32 buf_len, u32 *out_len)\n{\n    u8 *p = buf;\n    // ...\n    /* Handshake header */\n    *p++ = TLS_HS_CLIENT_HELLO;\n    msg_len_ptr = p;\n    p += 3;\n    *p++ = (TLS_LEGACY_VERSION >> 8) & 0xff;\n    *p++ = TLS_LEGACY_VERSION & 0xff;\n    memcpy(p, hs->client_random, TLS_RANDOM_LEN);  // 32 bytes\n    p += TLS_RANDOM_LEN;\n    // ... session ID (up to 32 bytes) ...\n    // ... cipher suites (8 bytes) ...\n    // ... compression (2 bytes) ...\n    memcpy(p, extensions, ext_len);  // up to 2048 bytes\n    p += ext_len;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The function writes into `buf` without ever checking `buf_len`. The\nminimum output is approximately 4 + 2 + 32 + 1 + 32 + 2 + 6 + 2 = 81 bytes plus\nextensions. If the caller provides a small buffer, this overflows. This is an exported\nsymbol (`EXPORT_SYMBOL_GPL`) so any kernel module can call it with an arbitrary buffer.",
    "fix_suggestion": "** Check `buf_len` before each write block, or compute the total\nrequired size first and validate it fits.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "CRITICAL-4",
    "title": "Integer overflow in `tquic_hs_build_ch_extensions` PSK identity length calculations",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Buffer overflow from length mismatch, malformed TLS messages.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (hs->psk_count > 0) {\n    u32 identities_len = 0;\n    u32 binders_len = 0;\n    u32 i;\n\n    for (i = 0; i < hs->psk_count; i++) {\n        identities_len += 2 + hs->psk_identities[i].identity_len + 4;\n        binders_len += 1 + hs->hash_len;\n    }\n\n    *p++ = (TLS_EXT_PRE_SHARED_KEY >> 8) & 0xff;\n    *p++ = TLS_EXT_PRE_SHARED_KEY & 0xff;\n    *p++ = ((identities_len + binders_len + 4) >> 8) & 0xff;\n    *p++ = (identities_len + binders_len + 4) & 0xff;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `identities_len` accumulates `identity_len` values from each PSK\nidentity. The field `identity_len` is `u32`. With enough PSK identities or large\nidentity lengths, `identities_len` can overflow the `u32`, wrapping to a small value.\nThis small value is then used to write the extension length header, but the actual\ndata written (in the loop at lines 1224-1234) uses the real `identity_len` values.",
    "fix_suggestion": "** Check for u32 overflow in the accumulation loop. Validate that\nthe total extension length fits in a u16.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "CRITICAL-5",
    "title": "`tquic_hs_process_certificate` -- integer underflow in `certs_len` tracking",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Out-of-bounds read from attacker-controlled packet data, potential\ninformation leak or crash.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "while (p < data + 4 + msg_len && certs_len > 0) {\n    u32 cert_len;\n    u16 ext_len;\n\n    if (p + 3 > end)\n        break;\n\n    cert_len = (p[0] << 16) | (p[1] << 8) | p[2];\n    p += 3;\n    certs_len -= 3;              // <-- can underflow if certs_len < 3\n\n    if (p + cert_len > end || cert_len > certs_len)\n        return -EINVAL;\n    // ...\n    p += cert_len;\n    certs_len -= cert_len;\n\n    /* Certificate extensions */\n    if (p + 2 > end)\n        break;\n    ext_len = (p[0] << 8) | p[1];\n    p += 2;\n    certs_len -= 2;              // <-- can underflow if certs_len < 2\n\n    if (ext_len > certs_len)\n        return -EINVAL;\n\n    p += ext_len;\n    certs_len -= ext_len;\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `certs_len` is a `u32`. The subtraction `certs_len -= 3` at line 1778\nis performed **before** the check `cert_len > certs_len` at line 1780. If `certs_len`\nis 1 or 2 at the loop entry, the subtraction wraps to a very large value (near\nUINT32_MAX). The subsequent `cert_len > certs_len` check then passes for almost any\n`cert_len`, leading to out-of-bounds reads. Similarly, `certs_len -= 2` at line 1800\ncan underflow.",
    "fix_suggestion": "** Check `certs_len >= 3` before `certs_len -= 3`, and\n`certs_len >= 2` before `certs_len -= 2`. Alternatively, track position using\npointer arithmetic against `end` only.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "CRITICAL-6",
    "title": "`tquic_hs_process_new_session_ticket` -- nonce overflow into session ticket",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "/* Ticket nonce */\nnonce_len = *p++;\nif (p + nonce_len > end)\n    return -EINVAL;\n\n/* ... allocate session_ticket ... */\n\nhs->session_ticket->nonce_len = nonce_len;\nmemcpy(hs->session_ticket->nonce, p, nonce_len);",
        "struct tquic_session_ticket {\n    // ...\n    u8 nonce[255];\n    u8 nonce_len;\n    // ...\n};"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `nonce_len` is a `u8` (max 255), and the `nonce` buffer is 255 bytes,\nso this specific copy is safe. However, `nonce_len` is read directly from untrusted\nnetwork data and the check only validates it against `end`. The RFC mandates that\nthe nonce MUST be at most 255 bytes but some implementations might send more in a\nnon-conformant way. The real issue is that the allocated `nonce[255]` exactly matches\nthe max u8 value -- if the struct ever changes to a smaller buffer, this becomes\nan overflow without any additional validation.\n\nWhile this specific case is technically safe due to type constraints, there is a\nmore serious issue below.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "CRITICAL-6-OTH",
    "title": "(actual): `tquic_hs_process_server_hello` -- missing check before cipher suite read",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Out-of-bounds read of 1-2 bytes. In kernel context, this reads from\nadjacent slab memory, potentially leaking sensitive data.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "p += session_id_len;\n\n    /* Cipher suite */\n    cipher_suite = (p[0] << 8) | p[1];\n    p += 2;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** After advancing past the session ID, there is no check that\n`p + 2 <= end` before reading the cipher suite. If the message is truncated right\nafter the session ID, this reads 2 bytes past the buffer.",
    "fix_suggestion": "** Add `if (p + 2 > end) return -EINVAL;` before the cipher suite read.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "CRITICAL-7",
    "title": "`tquic_hs_process_server_hello` -- missing bounds check before compression byte read",
    "category": "other",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Out-of-bounds read.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "/* Compression (must be null) */\n    compression = *p++;\n    if (compression != 0) {"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** No check that `p < end` before dereferencing `*p++`. If the message\nis truncated after the cipher suite, this reads one byte out of bounds.",
    "fix_suggestion": "** Add `if (p >= end) return -EINVAL;` before reading compression.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "HIGH-1",
    "title": "`tquic_hs_hkdf_expand_label` -- `context_len` truncated to u8",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Cryptographic weakness, potentially exploitable for key manipulation.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "*p++ = context_len;     // context_len is u32, written as u8",
        "if (context_len > 255)\n    return -EINVAL;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The HKDF label encodes the context length as a single byte per the TLS\nspec (HkdfLabel.context is limited to 255 bytes). But the function parameter is `u32`.\nIf `context_len > 255`, the written byte is truncated, but `memcpy` at line 762 still\ncopies the full `context_len` bytes. This means the HKDF label header says the context\nis (context_len % 256) bytes, but the actual data is context_len bytes.\n\nThis creates a cryptographically incorrect HKDF derivation -- the label structure is\nmalformed. An attacker who can influence the context data could use this to cause\nkey derivation errors or potentially create collisions.",
    "fix_suggestion": "**\n```c\nif (context_len > 255)\n    return -EINVAL;\n```\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "HIGH-2",
    "title": "`tquic_hs_generate_client_hello` -- output buffer `buf` not validated for minimum size",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** Even the fixed-size header portions (handshake type, version, random,\nsession ID, cipher suites, compression) require at least ~81 bytes. The function never\nvalidates that `buf_len >= 81` (or any minimum). A caller passing `buf_len = 0` causes\nimmediate out-of-bounds write at line 1320 (`*p++ = TLS_HS_CLIENT_HELLO`).",
    "fix_suggestion": "** Validate `buf_len` against the minimum required size at function entry.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "HIGH-3",
    "title": "`tquic_hs_process_server_hello` -- session ID comparison not fully bounds-safe",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** One-byte out-of-bounds read.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "session_id_len = *p++;\n    if (session_id_len > TLS_SESSION_ID_MAX_LEN)\n        return -EINVAL;\n    if (p + session_id_len > end)\n        return -EINVAL;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** Before reading `session_id_len` at `*p++`, there is no check that\n`p < end`. The earlier check `p + TLS_RANDOM_LEN > end` at line 1423 ensures p is\nvalid through the random bytes, but after advancing p by TLS_RANDOM_LEN (line 1426),\nif the message is exactly `4 + 2 + 32` bytes, `p` points to `end` and the `*p++`\nread is out of bounds.",
    "fix_suggestion": "** Add `if (p >= end) return -EINVAL;` before `session_id_len = *p++;`.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "HIGH-4",
    "title": "Secrets not zeroized on error paths in key derivation functions",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Kernel secret material persists on stack after error, potential information leak.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "static int tquic_hs_derive_handshake_secrets(struct tquic_handshake *hs)\n{\n    u8 derived[TLS_SECRET_MAX_LEN];\n    u8 transcript_hash[TLS_SECRET_MAX_LEN];\n    // ...\n    ret = tquic_hs_derive_secret(hs, hs->early_secret, \"derived\",\n                                 NULL, 0, derived, hash_len);\n    if (ret)\n        return ret;        // <-- derived[] left on stack with secret data\n    // ...\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** Stack-local secret buffers `derived[]` and `transcript_hash[]` are not\nzeroized on error paths. When the function returns early due to an error, these secrets",
    "fix_suggestion": "** Use `goto out_zeroize` pattern with `memzero_explicit()` on all\nlocal secret buffers before returning, even on error paths.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "HIGH-5",
    "title": "`tquic_hs_setup_psk` -- integer overflow in ticket age calculation",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Incorrect ticket age sent to server, potentially causing ticket rejection\nor replay issues.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "age = (now - ticket->creation_time) * 1000;  /* Convert to ms */\n    obfuscated_age = age + ticket->age_add;\n    psk->obfuscated_ticket_age = obfuscated_age;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `age` is `u32`. `now - ticket->creation_time` is a `u64` subtraction\nbut `age` is `u32`, so the result is truncated. Then `age * 1000` can overflow a `u32`\nif the ticket is more than about 4.3 million seconds old (approx 50 days). This is\nwithin the max ticket lifetime of 7 days (604800 seconds), where 604800 * 1000 =\n604800000 which fits in u32. However, if `ticket->lifetime` validation is bypassed\nor the ticket is from a misbehaving server with a very long lifetime, this overflows.\n\nThe `obfuscated_age = age + ticket->age_add` can also overflow, but that is expected\nper the RFC (the addition is modular).",
    "fix_suggestion": "** Use `u64` for `age` and validate the time difference before\nmultiplication. Also validate `lifetime` against RFC 8446 maximum of 604800 (7 days).\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "HIGH-6",
    "title": "`tquic_hs_build_ch_extensions` -- ALPN extension length written as 2-byte but can overflow u16",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Malformed TLS message, potential buffer overflow from length mismatch.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (hs->alpn_count > 0) {\n        u32 alpn_total_len = 0;\n\n        for (i = 0; i < hs->alpn_count; i++)\n            alpn_total_len += 1 + strlen(hs->alpn_list[i]);\n\n        *p++ = ((alpn_total_len + 2) >> 8) & 0xff;\n        *p++ = (alpn_total_len + 2) & 0xff;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `alpn_total_len` is `u32` but is written into 2-byte extension length\nfields. If many ALPN protocols are registered (e.g., > 256 protocols of 255 bytes each),\n`alpn_total_len + 2` exceeds 65535 and is silently truncated. The actual data written\nbelow uses the full count, creating a length mismatch.\n\nNo validation exists on `hs->alpn_count` in `tquic_hs_set_alpn` -- any number of\nprotocols can be set.",
    "fix_suggestion": "** Validate ALPN total length fits in u16 in `tquic_hs_set_alpn()`.\nAdd a reasonable cap on `alpn_count`.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "HIGH-7",
    "title": "`tquic_hs_process_encrypted_extensions` -- ALPN validation insufficient",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Out-of-bounds read from attacker-controlled ServerHello.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "case TLS_EXT_ALPN:\n        if (ext_data_len >= 3) {\n            u16 list_len = (p[0] << 8) | p[1];\n            u8 proto_len = p[2];\n\n            if (list_len >= proto_len + 1 && proto_len > 0) {\n                kfree(hs->alpn_selected);\n                hs->alpn_selected = kmalloc(proto_len + 1, GFP_KERNEL);\n                if (hs->alpn_selected) {\n                    memcpy(hs->alpn_selected, p + 3, proto_len);",
        "if (ext_data_len >= 3 && proto_len > 0 && 3 + proto_len <= ext_data_len) {"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The check `list_len >= proto_len + 1` validates that `proto_len`\nfits within `list_len`, but does not validate that `3 + proto_len <= ext_data_len`.\nIf `ext_data_len` is exactly 3, `proto_len` could be non-zero, and `memcpy(p + 3, proto_len)`\nreads past `p + ext_data_len`. Additionally, `list_len` is not validated against\n`ext_data_len - 2` (where the 2 bytes are for the list length field itself).",
    "fix_suggestion": "**\n```c\nif (ext_data_len >= 3 && proto_len > 0 && 3 + proto_len <= ext_data_len) {\n```\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "HIGH-8",
    "title": "`tquic_hs_cleanup` -- potential double-free of session ticket",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Double-free leading to use-after-free, heap corruption.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (hs->session_ticket) {\n        kfree(hs->session_ticket->ticket);\n        kfree(hs->session_ticket);\n    }",
        "/* Store session ticket for early data */\n    hs->session_ticket = ticket;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `tquic_hs_setup_psk()` stores a **borrowed pointer** to the caller's\n`ticket` in `hs->session_ticket`. When `tquic_hs_cleanup()` runs, it frees\n`hs->session_ticket->ticket` and `hs->session_ticket`. If the caller also frees the\nsame ticket structure, this is a double-free. Conversely, if the caller expects the\nhandshake to take ownership, this is correct -- but the API is ambiguous and error-prone.",
    "fix_suggestion": "** Either document clearly that `tquic_hs_setup_psk` takes ownership\n(and the caller must not free), or make `tquic_hs_setup_psk` copy the ticket data.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "HIGH-9",
    "title": "`tquic_hs_process_new_session_ticket` -- memory leak of old ticket data on re-entry",
    "category": "other",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Memory corruption from freeing a borrowed pointer.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (!hs->session_ticket) {\n        hs->session_ticket = kzalloc(sizeof(*hs->session_ticket), GFP_KERNEL);\n        if (!hs->session_ticket)\n            return -ENOMEM;\n    }\n    // ... writes to hs->session_ticket fields ...\n\n    kfree(hs->session_ticket->ticket);\n    hs->session_ticket->ticket = kmalloc(ticket_len, GFP_KERNEL);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** If a second NewSessionTicket arrives, the function reuses the existing\n`hs->session_ticket` but does not free the old nonce data or reset other fields. The\n`kfree(hs->session_ticket->ticket)` on line 2609 handles the ticket data, but if the\nfirst call failed after allocating the session_ticket but before setting ticket (e.g.,\n`kmalloc` for ticket fails at line 2610), and then a second NewSessionTicket arrives,\nthe session ticket structure may contain stale state.\n\nMore importantly, if `tquic_hs_setup_psk` was called first (setting `hs->session_ticket`\nto a borrowed pointer), and then a NewSessionTicket arrives, the `kfree()` on line 2609\nfrees memory that was not allocated by this code path.",
    "fix_suggestion": "** Track whether `hs->session_ticket` is owned or borrowed. Only free\nowned tickets.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "MEDIUM-1",
    "title": "`tquic_hs_generate_client_hello` -- `hkdf_label` stack buffer on sensitive crypto path",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The 512-byte `hkdf_label` stack buffer in `tquic_hs_hkdf_expand_label`\nis not zeroed after use. It contains the HKDF label structure which includes the context\n(transcript hash). While not directly a secret, it can assist an attacker in reconstructing\nthe key derivation inputs.",
    "fix_suggestion": "** Add `memzero_explicit(hkdf_label, sizeof(hkdf_label));` before return.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "MEDIUM-2",
    "title": "`hs_varint_encode` -- no bounds check on output buffer",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "static int hs_varint_encode(u64 val, u8 *buf, u32 *len)\n{\n    if (val < 0x40) {\n        buf[0] = val;\n        *len = 1;\n    } else if (val < 0x4000) {\n        buf[0] = 0x40 | (val >> 8);\n        buf[1] = val & 0xff;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The function writes up to 8 bytes to `buf` but does not know or check\nthe buffer size. All callers use `u8 varint[8]` which is exactly the maximum, so this\nis safe in current usage. But the function interface is unsafe by design.",
    "fix_suggestion": "** Add a `u32 buf_len` parameter or document the 8-byte minimum requirement.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "MEDIUM-3",
    "title": "`tquic_hs_process_server_hello` -- extension parsing loop bound mismatch",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "while (p < data + 4 + msg_len) {"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The extension parsing loop uses `data + 4 + msg_len` as the bound, but",
    "fix_suggestion": "** Use `const u8 *ext_end = p + ext_len;` and loop `while (p < ext_end)`.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "MEDIUM-4",
    "title": "`tquic_hs_process_certificate` -- unbounded certificate allocation",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Remote denial of service via memory exhaustion.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (!hs->peer_cert && cert_len > 0) {\n        hs->peer_cert = kmalloc(cert_len, GFP_KERNEL);\n        if (!hs->peer_cert)\n            return -ENOMEM;\n        memcpy(hs->peer_cert, p, cert_len);\n        hs->peer_cert_len = cert_len;\n    }",
        "if (cert_len > TLS_CERT_MAX_LEN)\n    return -EINVAL;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `cert_len` comes from network data and can be up to 16777215 (24-bit\nfield). The `TLS_CERT_MAX_LEN` constant (16384) is defined but never checked before\nthis allocation. A malicious server can force the client to allocate up to 16 MB for a\nsingle certificate.",
    "fix_suggestion": "**\n```c\nif (cert_len > TLS_CERT_MAX_LEN)\n    return -EINVAL;\n```\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "MEDIUM-5",
    "title": "`tquic_hs_process_new_session_ticket` -- `ticket_len` is u16, can be up to 65535",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `ticket_len` is parsed as a `u16` (max 65535 bytes). The function\nallocates and copies this amount. While 65535 is not extremely large, TLS 1.3 RFC 8446\nstates that tickets are typically small. There is no upper bound validation. A malicious\nserver can repeatedly send NewSessionTicket messages with 64KB tickets, consuming memory.",
    "fix_suggestion": "** Add a reasonable upper limit (e.g., 8192 bytes) for ticket length.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "MEDIUM-6",
    "title": "`tquic_hs_derive_early_secrets` -- `memzero_explicit` called before error check",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Incorrect binder key derivation (always zeroed), PSK authentication failure.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "ret = tquic_hs_derive_secret(hs, hs->early_secret,\n                                     \"ext binder\", NULL, 0,\n                                     binder_key, hash_len);\n        memzero_explicit(binder_key, sizeof(binder_key));\n        if (ret)\n            return ret;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `memzero_explicit` is called before checking `ret`. This means if\n`tquic_hs_derive_secret` succeeds, the binder key is immediately zeroed and cannot be\nused. This is likely a bug where the intent was to zero on cleanup, but the order is\nwrong.",
    "fix_suggestion": "** Move `memzero_explicit` after the binder key is no longer needed,\nor into an error/cleanup path.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "MEDIUM-7",
    "title": "`tquic_hs_process_certificate_verify` -- `content[200]` stack buffer could overflow with large hash",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "u8 content[200];\n    u8 *cp = content;\n    // ...\n    memset(cp, 0x20, 64);   // 64 bytes\n    cp += 64;\n    memcpy(cp, \"TLS 1.3, server CertificateVerify\", 33);  // 33 bytes\n    cp += 33;\n    *cp++ = 0x00;            // 1 byte = 98 total\n    memcpy(cp, transcript_hash, hash_len);  // hash_len up to 48\n    cp += hash_len;          // max = 98 + 48 = 146 bytes"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The maximum content is 64 + 33 + 1 + 48 (SHA-384) = 146 bytes, which\nfits in 200 bytes. However, if a future cipher suite with a 64-byte hash (SHA-512) is\nadded to the key schedule, `hash_len` could be 64, making the total 162 -- still safe.\nBut the margin is only 38 bytes. If the context string changes or additional data is\nadded, this could overflow.",
    "fix_suggestion": "** Compute the required size dynamically: `content_size = 64 + 33 + 1 + hash_len`\nand validate it fits, or allocate dynamically.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "MEDIUM-8",
    "title": "`tquic_hs_process_server_hello` -- `static const` inside function body",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "static const u8 hrr_random[32] = {\n        0xcf, 0x21, 0xad, 0x74, ...\n    };"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** A `static const` variable is declared inside a block scope within the\nfunction. In C, this is valid but unusual in kernel code and can confuse code analysis\ntools. Some versions of GCC/Clang may not warn about this, but it creates a data\nsection variable from within function scope.\n\nThis is a code quality issue rather than a security bug, but it could mask issues in\nstatic analysis.",
    "fix_suggestion": "** Move to file scope alongside the other static const arrays (like\n`tls12_downgrade_sentinel`).",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "LOW-1",
    "title": "`tquic_hs_cleanup` -- does not zeroize exporter_secret and resumption_secret",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "memzero_explicit(hs->early_secret, sizeof(hs->early_secret));\n    memzero_explicit(hs->handshake_secret, sizeof(hs->handshake_secret));\n    memzero_explicit(hs->master_secret, sizeof(hs->master_secret));\n    // ... other secrets ...\n    memzero_explicit(hs->shared_secret, sizeof(hs->shared_secret));"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The cleanup function zeroizes most secrets but misses:\n- `hs->exporter_secret`\n- `hs->resumption_secret`\n- `hs->client_random`\n- `hs->server_random`",
    "fix_suggestion": "** Add `memzero_explicit` calls for all remaining sensitive fields.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "LOW-2",
    "title": "`tquic_hs_get_handshake_secrets` and `tquic_hs_get_app_secrets` -- no output buffer size validation",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** These functions copy `hs->hash_len` bytes (up to 48) into caller-provided\nbuffers but do not verify the buffers are large enough. The caller must ensure at least\n`TLS_SECRET_MAX_LEN` (48) bytes are available.",
    "fix_suggestion": "** Document the minimum buffer size requirement or add a `buf_len` parameter.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "LOW-3",
    "title": "`tquic_hs_set_alpn` -- missing `hs->alpn_count = 0` on cleanup",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (hs->alpn_list) {\n        for (i = 0; i < hs->alpn_count; i++)\n            kfree(hs->alpn_list[i]);\n        kfree(hs->alpn_list);\n    }"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** When replacing the ALPN list, the old list is freed but `hs->alpn_count`\nis not set to 0 before the new allocation. If the `kcalloc` on line 2964 fails, the\nfunction returns `-ENOMEM` with `hs->alpn_list = NULL` but `hs->alpn_count` still has\nthe old value. A subsequent call to cleanup or extension building would iterate over\nthe stale count with a NULL list pointer.",
    "fix_suggestion": "** Set `hs->alpn_count = 0` after freeing the old list.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "LOW-4",
    "title": "`tquic_hs_generate_client_hello` -- client random not checked for all-zero",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `get_random_bytes()` in the kernel is reliable, but defense-in-depth\nwould suggest verifying the random is not all zeros (which would indicate a catastrophic\nRNG failure).",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "LOW-5",
    "title": "`tquic_hs_process_certificate_verify` hardcodes \"server CertificateVerify\" string",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "** If used for client cert verification (not currently implemented), signature\nverification would always fail, causing a denial of service against client authentication.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The context string is hardcoded as `\"TLS 1.3, server CertificateVerify\"`.\nIf this function is ever used on the server side to verify a client's CertificateVerify,\nthe string should be `\"TLS 1.3, client CertificateVerify\"`. The current code does not\ncheck `hs->is_server` to select the correct string.",
    "fix_suggestion": "** Use `hs->is_server ? \"TLS 1.3, client CertificateVerify\" : \"TLS 1.3, server CertificateVerify\"`.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "LOW-6",
    "title": "`tquic_hs_process_new_session_ticket` -- ignores extensions",
    "category": "other",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "/* Parse extensions (early_data max size, etc.) */\n    /* Skip for now */"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The `early_data` extension in NewSessionTicket specifies the maximum\namount of 0-RTT data the server will accept. By ignoring this, the client may attempt\nto send more 0-RTT data than the server allows, causing connection failures.",
    "fix_suggestion": "",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_HANDSHAKE_AUDIT.md"
  },
  {
    "id": "C1",
    "title": "Buffer Overflow in ClientHello Extension Building",
    "category": "security",
    "severity": "S0",
    "confidence": "high",
    "impact": "** A stack or heap buffer overflow, exploitable by triggering specific extension combinations. An attacker who controls which extensions are negotiated (e.g., via a malicious server that triggers retry with specific parameters) could achieve remote code execution in kernel context.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "// Extensions are written sequentially without cumulative bounds checking\n  // Each individual write may check, but total is not validated"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The function `tquic_hs_build_ch_extensions()` writes extension data into `buf` without consistently checking against `buf_len`. When multiple extensions are enabled (supported_versions, key_share, ALPN, SNI, transport parameters, PSK), the cumulative writes can overflow the provided buffer.",
    "fix_suggestion": "** Add a running `offset` tracker and validate `offset + needed_bytes <= buf_len` before every write operation. Return `-ENOSPC` if insufficient space.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CRYPTO_SECURITY.md"
  },
  {
    "id": "C2",
    "title": "Stack Buffer Overflow in HKDF-Expand-Label (handshake.c)",
    "category": "security",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Kernel stack buffer overflow, potentially leading to stack smashing and kernel code execution. The handshake context processes data from untrusted peers.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The function uses a 512-byte stack buffer `hkdf_label` but does not adequately validate the combined size of `label_len + context_len` before writing into it. While TLS 1.3 label lengths are typically small, an attacker-controlled label from a malicious peer could exceed the buffer.",
    "fix_suggestion": "** Add explicit bounds check: `if (label_len + context_len + 10 > sizeof(hkdf_label)) return -EINVAL;` before any writes to the buffer. Note: the zero_rtt.c implementation at line ~238 correctly has this check (`if (label_len > 245 || context_len > 245 || (10 + label_len + context_len) > sizeof(hkdf_label)) return -EINVAL;`).",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CRYPTO_SECURITY.md"
  },
  {
    "id": "C3",
    "title": "Fragile Hardcoded Offset for Key Update State Access",
    "category": "security",
    "severity": "S0",
    "confidence": "high",
    "impact": "** Reading arbitrary memory as a pointer, leading to dereferencing wild pointers. This is a latent kernel memory corruption vulnerability triggered by any structure layout change (e.g., adding a field, changing compiler, changing config options that affect padding).",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "struct tquic_key_update_state *tquic_crypto_get_key_update_state(void *crypto_state)\n  {\n      // Hardcoded offset 304 bytes into opaque structure\n      return *(struct tquic_key_update_state **)((u8 *)crypto_state + 304);\n  }"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The function `tquic_crypto_get_key_update_state()` uses a hardcoded byte offset (304 bytes) to access the `key_update` pointer from an opaque `void *crypto_state`. This is extremely fragile and will silently read the wrong memory if the crypto_state structure layout changes.",
    "fix_suggestion": "** Use a proper typed structure with a named field, or use `container_of()` macro. Never use raw byte offsets to access structure members. Define a proper interface header that both the crypto state creator and this function share.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CRYPTO_SECURITY.md"
  },
  {
    "id": "H1",
    "title": "Per-Call crypto_aead_setkey in Encrypt/Decrypt Hot Path",
    "category": "security",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Beyond the performance impact, calling `setkey` repeatedly may interact poorly with hardware crypto accelerators that cache expanded keys. Some implementations may leak timing information if the key schedule is not constant-time. Additionally, if the crypto driver implementation is not reentrant for concurrent setkey calls on a shared tfm, this creates a race condition.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `crypto_aead_setkey()` is called on every encrypt and decrypt operation. In the kernel crypto API, `setkey` may trigger key expansion (AES key schedule), which involves non-trivial computation and potentially sleeping allocations.",
    "fix_suggestion": "** Set the key once when it changes (at key installation time), not on every packet. Store the AEAD transform with the key pre-set in `tquic_key_generation`.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CRYPTO_SECURITY.md"
  },
  {
    "id": "H2",
    "title": "Per-Call crypto_alloc_aead in 0-RTT Encrypt/Decrypt",
    "category": "security",
    "severity": "S1",
    "confidence": "high",
    "impact": "** `crypto_alloc_aead()` performs module loading, memory allocation, and initialization. Under load, this will cause significant latency spikes and memory pressure. Under memory pressure, GFP_ATOMIC allocations may fail, causing packet drops.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** Both `tquic_zero_rtt_encrypt()` and `tquic_zero_rtt_decrypt()` call `crypto_alloc_aead()` on every invocation. This allocates a new crypto transform, sets the key, performs the operation, then frees it. This is extremely expensive in the hot path.",
    "fix_suggestion": "** Pre-allocate the AEAD transform during `tquic_zero_rtt_init()` or `tquic_zero_rtt_attempt()` and reuse it for the lifetime of the 0-RTT state.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CRYPTO_SECURITY.md"
  },
  {
    "id": "H3",
    "title": "Custom ASN.1 Parser - High Attack Surface",
    "category": "security",
    "severity": "S1",
    "confidence": "high",
    "impact": "** While the current parser appears to have basic bounds checking, the complexity of X.509 parsing means subtle bugs are likely. Historical CVEs in ASN.1 parsers (across all implementations) demonstrate this is a high-risk area.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The certificate verification module implements a custom ASN.1/DER parser rather than using the kernel's existing ASN.1 infrastructure (`lib/asn1_decoder.c`). Custom parsers for complex formats like ASN.1 are a known source of security vulnerabilities. The parser processes attacker-controlled certificate data from the network.",
    "fix_suggestion": "** Consider using the kernel's built-in ASN.1 decoder (`lib/asn1_decoder.c`) and the x509 certificate parser (`crypto/asymmetric_keys/x509_cert_parser.c`) which have been battle-tested. If the custom parser must be retained, add fuzzing tests targeting all parsing entry points.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CRYPTO_SECURITY.md"
  },
  {
    "id": "H4",
    "title": "OCSP Stapling Accepted Without Verification",
    "category": "security",
    "severity": "S1",
    "confidence": "high",
    "impact": "** An attacker with a revoked certificate can include arbitrary OCSP stapling data to bypass revocation checking. This completely defeats the purpose of revocation checking when OCSP stapling is present.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "if (ctx->ocsp_stapling && ctx->ocsp_stapling_len > 0) {\n      /* OCSP response parsing would go here. */\n      pr_debug(\"tquic_cert: OCSP stapling present (%u bytes)\\n\",\n               ctx->ocsp_stapling_len);\n      return 0;  // Accepts without verification!\n  }"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** When OCSP stapling data is present, the function immediately returns success without parsing or verifying the OCSP response. The comment says \"For now, accept stapled responses as valid.\"",
    "fix_suggestion": "** Either implement OCSP response verification or remove the early return so that the \"no OCSP available\" path is taken, which at least logs warnings in hard-fail mode.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CRYPTO_SECURITY.md"
  },
  {
    "id": "H5",
    "title": "Race Condition in Key Update Secret Installation",
    "category": "security",
    "severity": "S1",
    "confidence": "high",
    "impact": "** A concurrent reader could attempt to use secrets for which AEAD keys have not yet been derived, leading to use of zero-initialized or stale key material. This could result in plaintext exposure or authentication bypass.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The function installs secrets under the spinlock, then drops the lock to perform key derivation (which may sleep), then re-acquires the lock to update state. Between the lock release and re-acquisition, another thread could observe partially-installed state (secrets set but keys not yet derived).",
    "fix_suggestion": "** Use a state flag (e.g., `keys_installing`) that prevents concurrent use during the derivation window. Set the flag under the first lock acquisition, derive keys, then clear it under the second lock acquisition.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CRYPTO_SECURITY.md"
  },
  {
    "id": "H6",
    "title": "Client Certificate Verification Uses Server Logic",
    "category": "security",
    "severity": "S1",
    "confidence": "high",
    "impact": "** Client certificates with only clientAuth EKU would be rejected. Conversely, certificates with only serverAuth EKU would be incorrectly accepted for client authentication.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "int tquic_hs_verify_client_cert(struct tquic_handshake *hs,\n                                  struct tquic_connection *conn)\n  {\n      return tquic_hs_verify_server_cert(hs, conn);\n  }"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `tquic_hs_verify_client_cert()` directly calls `tquic_hs_verify_server_cert()`, which always passes `true` for `is_server` in the chain verification. This means client certificates are checked for serverAuth EKU instead of clientAuth EKU.",
    "fix_suggestion": "** Add a `bool is_server` parameter to the internal `verify_chain()` call path, or refactor so that client cert verification passes `is_server=false`.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CRYPTO_SECURITY.md"
  },
  {
    "id": "M1",
    "title": "Transcript Buffer Not Zeroized Before Free",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "** After `kfree()`, the transcript data remains in the slab cache and could be read by a local attacker with kernel memory access.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The handshake cleanup function zeroizes most cryptographic secrets but does not zeroize the transcript buffer before freeing it. The transcript contains the full handshake, including encrypted data and potentially sensitive parameters.",
    "fix_suggestion": "** Use `kfree_sensitive()` or call `memzero_explicit()` on the transcript buffer before freeing.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CRYPTO_SECURITY.md"
  },
  {
    "id": "M2",
    "title": "Bloom Filter False Negatives Allow Replay",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "** A replay attack timed to coincide with bloom filter rotation could succeed. The window is TTL/2 (30 minutes by default).",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The bloom filter anti-replay mechanism is probabilistic. With a 64K-bit filter and 4 hash functions, the false positive rate is reasonable, but rotation clears half the filter, creating a window where replays are not detected (false negatives during the rotation boundary).",
    "fix_suggestion": "** This is an inherent limitation of bloom filters. Document this as a known limitation. Consider augmenting with a small exact-match cache for recent tickets (last N tickets stored exactly) to eliminate the rotation window for the most common case.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CRYPTO_SECURITY.md"
  },
  {
    "id": "M3",
    "title": "Per-Call crypto_alloc_shash in Stateless Reset Token Generation",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "** An attacker sending many short packets to trigger stateless reset processing could cause memory pressure through repeated crypto_alloc_shash calls.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `tquic_stateless_reset_generate_token()` allocates a new `crypto_shash` transform on every call. Under a stateless reset flood attack, this creates excessive memory allocation pressure.",
    "fix_suggestion": "** Pre-allocate a per-CPU or global HMAC transform and reuse it.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CRYPTO_SECURITY.md"
  },
  {
    "id": "M4",
    "title": "RSA-PSS Hash Algorithm Always Defaults to SHA-256",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Certificates using RSA-PSS with SHA-384 or SHA-512 will have incorrect signature verification (wrong hash computed over TBSCertificate), causing valid certificates to be rejected.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** When an RSA-PSS signature algorithm OID is detected, the hash algorithm always defaults to SHA-256 without parsing the RSA-PSS parameters that specify the actual hash algorithm.",
    "fix_suggestion": "** Parse the RSA-PSS AlgorithmIdentifier parameters to extract the actual hash algorithm.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CRYPTO_SECURITY.md"
  },
  {
    "id": "M5",
    "title": "Time Parsing Does Not Validate Digit Characters",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "** A malformed certificate with non-digit time values could cause incorrect validity period computation, potentially allowing expired or not-yet-valid certificates to pass validation.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The `parse_time()` function converts ASCII digit characters to integers using subtraction (`t[0] - '0'`) without verifying the characters are actually digits. Non-digit characters would produce incorrect values without detection.",
    "fix_suggestion": "** Add `isdigit()` checks for all time component characters before conversion.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CRYPTO_SECURITY.md"
  },
  {
    "id": "M6",
    "title": "Missing Bounds Check on tbs Pointer in Signature Parse",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "** An integer underflow on `remaining` passed to `parse_signature()` could cause out-of-bounds reads during signature parsing.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** After `parse_tbs_certificate()`, the code computes `after_tbs = cert->tbs + cert->tbs_len` and `remaining = content_len - (after_tbs - p)`. The `cert->tbs` pointer points into the original `data` buffer (not the copy in `cert->raw`). If `tbs_len` exceeds `content_len`, the subtraction wraps to a large value.",
    "fix_suggestion": "** Validate that `cert->tbs + cert->tbs_len <= data + total_len` before computing `remaining`.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CRYPTO_SECURITY.md"
  },
  {
    "id": "M7",
    "title": "EKU Request ID Increment Outside Lock",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "** While not directly exploitable, this creates a TOCTOU window where two concurrent callers may get sequential IDs but their requests are not guaranteed to be enqueued in order. This is a correctness issue rather than a direct security vulnerability.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The `next_request_id` is incremented under the lock, but then the lock is dropped before the request is fully constructed and re-inserted. Between the unlock at line 440 and re-lock at line 451, another thread could also increment `next_request_id`, potentially causing request ID ordering issues.",
    "fix_suggestion": "** Keep the lock held through request allocation and insertion, or use an atomic increment for the request ID.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CRYPTO_SECURITY.md"
  },
  {
    "id": "M8",
    "title": "QAT Encrypt Sets Key on Every Call",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Negates the performance benefit of hardware offload by adding per-packet key setup overhead.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `tquic_qat_encrypt()` calls `crypto_aead_setkey()` on every encryption operation. For QAT hardware, key setup involves sending the key to the hardware accelerator, which is expensive.",
    "fix_suggestion": "** Set the key once during context initialization and only re-set on key update.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CRYPTO_SECURITY.md"
  },
  {
    "id": "M9",
    "title": "Shared Exporter and Resumption Secrets Not Zeroized",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Key material persists in kernel memory longer than necessary, increasing the window for extraction via kernel memory vulnerabilities.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The `exporter_secret` and `resumption_secret` derived during the handshake are stored for later use but are not zeroized in the cleanup path after they are no longer needed. These secrets could enable session hijacking if leaked.",
    "fix_suggestion": "** Zeroize these secrets using `memzero_explicit()` as soon as they have been consumed (after key derivation and ticket issuance).",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CRYPTO_SECURITY.md"
  },
  {
    "id": "M10",
    "title": "Self-Signed Certificate Check Uses memcmp Instead of crypto_memneq",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "** The timing difference is minor for DN comparison (not a secret), but the inconsistency suggests potential for similar mistakes in security-critical comparisons.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The self-signed detection in `tquic_x509_verify_signature()` uses `memcmp()` for comparing issuer and subject DNs, while the same check in `tquic_x509_cert_parse()` at line 1628 correctly uses `crypto_memneq()`. Inconsistent use of constant-time comparison.",
    "fix_suggestion": "** Use `crypto_memneq()` consistently for all comparisons, or use `memcmp()` consistently for non-secret data. The key point is to be consistent and use constant-time comparison for any data whose equality/inequality should not leak timing information.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CRYPTO_SECURITY.md"
  },
  {
    "id": "L1",
    "title": "Unused HKDF-Expand Output in Extended Key Update",
    "category": "security",
    "severity": "S3",
    "confidence": "high",
    "impact": "** The PSK injection feature does not actually mix PSK material into the key derivation. The resulting keys are identical regardless of whether a PSK is injected, defeating the purpose of the feature.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** When PSK is included, the function derives a `mixed_secret` via HKDF-Extract but then zeroizes it immediately without actually using it in the key derivation. The comment says \"Now we need to use this mixed_secret\" but the code does not actually do so.",
    "fix_suggestion": "** Actually use the `mixed_secret` as input to the subsequent key derivation rather than the standard derivation path.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CRYPTO_SECURITY.md"
  },
  {
    "id": "L2",
    "title": "Header Protection Mask Not Zeroized in All Error Paths",
    "category": "security",
    "severity": "S3",
    "confidence": "high",
    "impact": "** Minimal - mask data is not directly sensitive (it is derived from public packet data), but defense-in-depth suggests cleanup.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** While the main code path properly zeroizes the mask buffer after use, some error return paths may leave partial mask data on the stack.",
    "fix_suggestion": "** Ensure `memzero_explicit()` is called on the mask buffer in all return paths, including error paths.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CRYPTO_SECURITY.md"
  },
  {
    "id": "L3",
    "title": "Per-CPU Stats Not Protected Against Torn Reads on 32-bit",
    "category": "security",
    "severity": "S3",
    "confidence": "high",
    "impact": "** Statistics may show incorrect values on 32-bit systems. This is an informational issue with no security impact.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The 64-bit per-CPU statistics are read with `READ_ONCE()` but on 32-bit architectures, a 64-bit read is not atomic and can produce torn values.",
    "fix_suggestion": "** Use `u64_stats_sync` infrastructure for proper 64-bit stats on 32-bit architectures.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CRYPTO_SECURITY.md"
  },
  {
    "id": "L4",
    "title": "Procfs trusted_cas File Writable Without Capability Check",
    "category": "security",
    "severity": "S3",
    "confidence": "high",
    "impact": "** Any process running as root can modify the trusted CA store. While root has broad permissions, adding a capability check provides defense-in-depth.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The `/proc/net/tquic_cert/trusted_cas` file is created with mode 0644, making it writable by root. However, there is no explicit capability check (e.g., `CAP_NET_ADMIN`) in the write handler.",
    "fix_suggestion": "** Add `capable(CAP_NET_ADMIN)` check at the start of `tquic_proc_trusted_cas_write()`.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CRYPTO_SECURITY.md"
  },
  {
    "id": "L5",
    "title": "Module Parameters Expose Security Configuration",
    "category": "security",
    "severity": "S3",
    "confidence": "high",
    "impact": "** Defense-in-depth concern. Root can already bypass most security, but making it easy to silently disable cert verification is risky.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** Security-critical parameters like `tquic_cert_verify_mode` and `tquic_cert_revocation_mode` are controlled via sysctl. A privileged attacker could disable certificate verification entirely by setting `tquic_cert_verify_mode = 0`.",
    "fix_suggestion": "** Log a prominent warning when verification mode is set to NONE. Consider requiring a special flag to disable verification in production builds.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CRYPTO_SECURITY.md"
  },
  {
    "id": "L6",
    "title": "Batch Crypto Allocates Per-Packet Temporary Buffer",
    "category": "security",
    "severity": "S3",
    "confidence": "high",
    "impact": "** Performance issue. Memory allocation per packet in the batch path adds latency and memory pressure.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The batch encryption function allocates a temporary `ct_buf` via `kmalloc(GFP_ATOMIC)` for each packet in the batch, then copies the result back. This defeats the purpose of batch processing.",
    "fix_suggestion": "** Perform in-place encryption if the caller's buffer has sufficient space (the `data_buf_len` check already exists), or pre-allocate a shared temporary buffer.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CRYPTO_SECURITY.md"
  },
  {
    "id": "L7",
    "title": "Key Update Timeout Revert Could Race With Concurrent Update",
    "category": "security",
    "severity": "S3",
    "confidence": "high",
    "impact": "** The spinlock should prevent data corruption, but the logical state could be inconsistent (timeout reverts keys while the peer has already adopted the new keys).",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The key update timeout/revert mechanism (3*PTO timeout) could race with a legitimate late key phase acknowledgment from the peer. If the timeout fires just as the peer's response arrives, both paths may modify the key state concurrently.",
    "fix_suggestion": "** Add a generation counter or sequence number to the key update so the timeout handler can detect if a response arrived between the timeout firing and the lock acquisition.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CRYPTO_SECURITY.md"
  },
  {
    "id": "L8",
    "title": "Certificate Chain Length Limit Checked Late",
    "category": "security",
    "severity": "S3",
    "confidence": "high",
    "impact": "** Minor resource waste - one extra certificate is parsed and allocated before the limit check triggers. Not a security vulnerability since the limit is still enforced.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The certificate chain parsing loop checks `TQUIC_MAX_CERT_CHAIN_LEN` at the end of the loop body, meaning it will parse and allocate one certificate beyond the limit before breaking.",
    "fix_suggestion": "** Move the chain length check to the beginning of the loop iteration.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: AUDIT_CRYPTO_SECURITY.md"
  },
  {
    "id": "C1-SEC",
    "title": "Hardcoded Struct Offset to Access Key Update State -- Memory Corruption Risk",
    "category": "security",
    "severity": "S0",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "struct tquic_crypto_state_ku_accessor {\n    char _before_key_update[304];    /* Approximate offset */\n    struct tquic_key_update_state *key_update;\n} *accessor;\n\nif (!crypto_state)\n    return NULL;\n\nif (header->cipher_suite == 0)\n    return NULL;\n\naccessor = crypto_state;\nreturn accessor->key_update;",
        "/* In tls.c, where tquic_crypto_state is fully defined: */\nstruct tquic_key_update_state *tquic_crypto_get_key_update_state(\n    struct tquic_crypto_state *crypto)\n{\n    return crypto ? crypto->key_update : NULL;\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Export a proper accessor function from `tls.c` that has visibility into\nthe actual `tquic_crypto_state` definition:\n```c\n/* In tls.c, where tquic_crypto_state is fully defined: */\nstruct tquic_key_update_state *tquic_crypto_get_key_update_state(\n    struct tquic_crypto_state *crypto)\n{\n    return crypto ? crypto->key_update : NULL;\n}\n```\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_KEYS_TLS.md"
  },
  {
    "id": "C2-SEC",
    "title": "Per-Packet crypto_aead_setkey on Shared AEAD Handle -- Race Condition",
    "category": "security",
    "severity": "S0",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "/* In tquic_encrypt_packet(), line 622: */\nret = crypto_aead_setkey(crypto->aead, keys->key, keys->key_len);\n\n/* In tquic_decrypt_packet(), line 679: */\nret = crypto_aead_setkey(crypto->aead, keys->key, keys->key_len);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Use separate AEAD transform handles for TX and RX, each with the key\nset once during key installation (not per-packet). The `quic_crypto.c` file\nalready does this correctly with `tx_aead` and `rx_aead` -- the `tls.c`\nimplementation should follow the same pattern.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_KEYS_TLS.md"
  },
  {
    "id": "C3-SEC",
    "title": "Install Secrets Accesses State Without Lock After Unlock",
    "category": "security",
    "severity": "S0",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "spin_unlock_irqrestore(&state->lock, flags);    /* line 878 */\n\n/* Derive keys from secrets -- NO LOCK HELD */\nret = tquic_ku_derive_keys(state, &state->current_read);   /* line 881 */\nif (ret)\n    return ret;\n\nret = tquic_ku_derive_keys(state, &state->current_write);  /* line 885 */\nif (ret)\n    return ret;\n\n/* Pre-compute next generation keys -- NO LOCK HELD */\nret = tquic_ku_derive_next_generation(state, &state->current_read,\n                                      &state->next_read);   /* line 890 */"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Copy the secrets into local variables under the lock, then derive from\nthe local copies (the pattern already used correctly in\n`tquic_initiate_key_update` at lines 392-405). The results should be committed\nback under the lock.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_KEYS_TLS.md"
  },
  {
    "id": "H1-SEC",
    "title": "EKU Derives Keys Using KU hash_tfm Without KU Lock",
    "category": "security",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "spin_unlock_irqrestore(&state->lock, flags);    /* line 821 */\n\n/* Access ku_state->hash_tfm WITHOUT ku_state->lock */\nif (ku_state->hash_tfm) {                       /* line 829 */\n    ret = eku_hkdf_extract(ku_state->hash_tfm,  /* line 830 */\n                           current_secret, secret_len,\n                           state->injected_psk,\n                           state->injected_psk_len,\n                           mixed_secret, secret_len);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Either (a) hold the KU lock around `hash_tfm` access, or (b) copy\n`hash_tfm` under the KU lock and use the copy (though crypto transforms are\nnot reference-counted, so this requires ensuring the transform outlives usage).\nFor the PSK, copy it under the EKU lock before releasing.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_KEYS_TLS.md"
  },
  {
    "id": "H2-SEC",
    "title": "EKU Semantic Mismatch: get_current_keys Returns Key, Not Secret",
    "category": "security",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "size_t secret_len = 32;  /* SHA-256 default */\nu8 current_secret[48];\nu32 key_len;\n\n/* Get current secret from base key update state */\nret = tquic_key_update_get_current_keys(ku_state, 1,\n                                        current_secret, &key_len,\n                                        NULL, NULL);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Add and use a function to retrieve the current traffic secret (not the\nderived key) from `tquic_key_update_state`. Derive `secret_len` from the\ncipher suite.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_KEYS_TLS.md"
  },
  {
    "id": "H3-SEC",
    "title": "memset Instead of memzero_explicit for Old Key Material",
    "category": "security",
    "severity": "S1",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "/* Line 435: After key rotation in tquic_initiate_key_update */\nmemset(&state->next_write, 0, sizeof(state->next_write));\n\n/* Lines 627-628: After peer key phase change */\nmemset(&state->next_read, 0, sizeof(state->next_read));\nmemset(&state->next_write, 0, sizeof(state->next_write));"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Replace all `memset(..., 0, ...)` clearing key material with\n`memzero_explicit()`.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_KEYS_TLS.md"
  },
  {
    "id": "M1-SEC",
    "title": "Per-Call skcipher_request Allocation in HP Mask Hot Path",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "/* AES path, line 164: */\nreq = skcipher_request_alloc(hp_key->tfm, GFP_ATOMIC);\nif (!req)\n    return -ENOMEM;\n\n/* ChaCha20 path, line 211: */\nreq = skcipher_request_alloc(hp_key->tfm, GFP_ATOMIC);\nif (!req)\n    return -ENOMEM;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Pre-allocate the `skcipher_request` in the `tquic_hp_key` structure\nduring key setup. Use a per-CPU or per-connection pre-allocated request to\navoid hot-path allocations.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_KEYS_TLS.md"
  },
  {
    "id": "M2-SEC",
    "title": "Per-Packet kmalloc in Batch Encrypt/Decrypt",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "/* Encrypt path, line 708: */\nct_buf = kmalloc(ct_buf_len, GFP_ATOMIC);\nif (!ct_buf) {\n    pkt->result = -ENOMEM;\n    continue;\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Allocate a single buffer sized for the largest packet in the batch, or\nuse a pre-allocated per-CPU bounce buffer. Alternatively, encrypt in-place if\nthe caller guarantees sufficient tail room (the `data_buf_len` check at line\n703 already validates this -- the temporary buffer is unnecessary).\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_KEYS_TLS.md"
  },
  {
    "id": "M3-SEC",
    "title": "Hardcoded 8-Byte CID in Short Header Unprotect",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "/* Short header - DCID starts at byte 1 */\n*pn_offset = 1 + 8;  /* Assume 8-byte connection ID */"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Pass the known local CID length to the unprotection function. The\nreceiver knows the length of its own CIDs.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_KEYS_TLS.md"
  },
  {
    "id": "M4-SEC",
    "title": "HP Key Rotation Swaps Old Keys Without Zeroization",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "/* Rotate read key */\ntmp = ctx->read_keys[TQUIC_HP_LEVEL_APPLICATION];\nctx->read_keys[TQUIC_HP_LEVEL_APPLICATION] = ctx->next_read_key;\nctx->next_read_key = tmp;    /* Old key is now \"next\" -- not zeroized */\n\n/* Rotate write key */\ntmp = ctx->write_keys[TQUIC_HP_LEVEL_APPLICATION];\nctx->write_keys[TQUIC_HP_LEVEL_APPLICATION] = ctx->next_write_key;\nctx->next_write_key = tmp;   /* Old key is now \"next\" -- not zeroized */"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** After the swap, zeroize the key bytes in the now-\"next\" slots (which\nhold old keys) using `memzero_explicit()` on the key material fields. The\n`tfm` pointer should be freed separately if the old cipher context is no longer\nneeded.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_KEYS_TLS.md"
  },
  {
    "id": "M5-SEC",
    "title": "Token Key Rotation Does Not Zeroize Old Key",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "int tquic_token_rotate_key(struct tquic_token_key *old_key,\n                           struct tquic_token_key *new_key)\n{\n    if (!new_key)\n        return -EINVAL;\n\n    get_random_bytes(new_key->key, TQUIC_TOKEN_KEY_LEN);\n    new_key->generation = old_key ? old_key->generation + 1 : 1;\n    new_key->valid = true;\n\n    return 0;\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Zeroize `old_key->key` with `memzero_explicit()` and set\n`old_key->valid = false` inside this function, making the API self-cleaning.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_KEYS_TLS.md"
  },
  {
    "id": "M6-SEC",
    "title": "No Token Replay Protection Beyond Timestamp",
    "category": "security",
    "severity": "S2",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Implement a token replay cache (e.g., a bloom filter or hash set of\nrecently seen token nonces) similar to the 0-RTT anti-replay mechanism already\ndefined in `zero_rtt.h`.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_KEYS_TLS.md"
  },
  {
    "id": "L1-SEC",
    "title": "Lock Drop/Re-acquire Pattern in Key Derivation",
    "category": "security",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "staged_cur_write = state->current_write;           /* Copy under lock */\nmemset(&staged_next, 0, sizeof(staged_next));\nspin_unlock_irqrestore(&state->lock, flags);       /* Drop lock */\n\nret = tquic_ku_derive_next_generation(state,       /* Derive unlocked */\n                                      &staged_cur_write,\n                                      &staged_next);\nmemzero_explicit(&staged_cur_write, sizeof(staged_cur_write));\nif (ret) {\n    memzero_explicit(&staged_next, sizeof(staged_next));\n    return ret;\n}\n\nspin_lock_irqsave(&state->lock, flags);            /* Re-acquire */\n\n/* Re-check state for concurrent modification */\nif (state->update_pending || state->next_write.valid) {\n    memzero_explicit(&staged_next, sizeof(staged_next));\n    ret = -EINPROGRESS;\n    goto out_unlock;\n}"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Pass `hash_tfm` as a separate parameter copied under the lock, rather\nthan passing the entire state.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_KEYS_TLS.md"
  },
  {
    "id": "L2-SEC",
    "title": "CRYPTO_TFM_REQ_MAY_BACKLOG in Atomic Context",
    "category": "security",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "skcipher_request_set_callback(req, CRYPTO_TFM_REQ_MAY_BACKLOG,\n                              crypto_req_done, &wait);"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Either (a) ensure callers never hold spinlocks when calling HP mask\ngeneration, or (b) use `CRYPTO_TFM_REQ_MAY_SLEEP` only when in process context\nand remove `MAY_BACKLOG` in atomic context, or (c) document the sleeping\nrequirement clearly.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_KEYS_TLS.md"
  },
  {
    "id": "L3-SEC",
    "title": "crypto_wait_req May Sleep in Encrypt/Decrypt Hot Path",
    "category": "security",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "ret = crypto_wait_req(crypto_aead_encrypt(req), &wait);  /* line 637 */\nret = crypto_wait_req(crypto_aead_decrypt(req), &wait);  /* line 694 */"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Ensure the encrypt/decrypt paths are only called from process context\n(e.g., in a workqueue), or use async completion callbacks instead of\n`crypto_wait_req`.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_KEYS_TLS.md"
  },
  {
    "id": "L4-SEC",
    "title": "Multipath Nonce Construction -- Potential Nonce Reuse Across Paths",
    "category": "security",
    "severity": "S3",
    "confidence": "high",
    "impact": "",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "/* XOR path_id into nonce bytes 4..7 for path separation */\nfor (i = 0; i < 4; i++)\n    nonce[7 - i] ^= (path_id >> (i * 8)) & 0xff;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "",
    "fix_suggestion": "** Verify that path_id allocation is monotonically increasing per\nconnection and never reuses IDs within a key phase.",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_CRYPTO_KEYS_TLS.md"
  },
  {
    "id": "MEDIUM-01",
    "title": "Request ID Truncation from u64 to int",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** After ~2 billion requests, the function will return negative values that callers interpret as errno codes, causing spurious failures. Request ID 0xFFFFFFFF would be truncated to -1 (EPERM), 0xFFFFFFF2 would be -14 (EFAULT), etc.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "return (int)request_id;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The function `tquic_connect_ip_request_address()` returns the request_id as `(int)request_id`, truncating the u64 value. For request IDs > INT_MAX, this returns a negative value that the caller will interpret as an error code.\n\n**Code (connect_ip.c:931):**\n```c\nreturn (int)request_id;\n```",
    "fix_suggestion": "** Change the return type to `s64` or return 0 for success and pass the request_id through an output pointer parameter.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_MASQUE_TUNNEL_AUDIT.md"
  },
  {
    "id": "MEDIUM-02",
    "title": "Constant-Time CID Validation Leaks Length via Branch",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Timing side-channel that reveals whether a connection ID has the expected length. While CID length alone may have limited value, it degrades the security guarantee that this function claims to provide.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "/* Use the larger length to ensure constant-time */\nmax_len = cid_len > expected_len ? cid_len : expected_len;"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The function `tquic_ct_validate_cid()` is documented as constant-time but contains a data-dependent branch on line 394 (`cid_len > expected_len ? cid_len : expected_len`). The ternary operator compiles to a conditional branch on most architectures, leaking whether the CID length matches the expected length through timing.\n\n**Code (quic_exfil.c:394):**\n```c\n/* Use the larger length to ensure constant-time */\nmax_len = cid_len > expected_len ? cid_len : expected_len;\n```",
    "fix_suggestion": "** Use `max_len = cid_len | expected_len;` (works if lengths are small enough) or use a branchless max: `max_len = cid_len ^ ((cid_len ^ expected_len) & -(cid_len < expected_len));`.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_MASQUE_TUNNEL_AUDIT.md"
  },
  {
    "id": "MEDIUM-03",
    "title": "No Flow Count Limit in HTTP Datagram Manager",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Memory exhaustion via flow allocation. Each flow consumes `sizeof(struct http_datagram_flow)` from the slab cache.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The HTTP Datagram manager tracks `num_flows` as a `u32` but never enforces a maximum. An attacker can create an unbounded number of flows, each consuming memory from the kmem_cache.",
    "fix_suggestion": "** Add a configurable `max_flows` limit to the manager and reject new flow creation when the limit is reached.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_MASQUE_TUNNEL_AUDIT.md"
  },
  {
    "id": "MEDIUM-04",
    "title": "Decoy Traffic Uses Easily Fingerprinted All-Zero Padding",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** The entire decoy traffic subsystem provides a false sense of security. An observer on the network path can identify and strip decoy packets, restoring the original traffic pattern.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The traffic shaper generates decoy packets using QUIC PADDING frames, which are all-zero bytes. A network observer can trivially distinguish decoy traffic from real traffic by checking if the decrypted payload is all zeros, completely negating the traffic analysis protection.",
    "fix_suggestion": "** Fill decoy packets with cryptographically random data, or better yet, use the same encryption layer as real packets so decoy traffic is indistinguishable at the wire level.\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_MASQUE_TUNNEL_AUDIT.md"
  },
  {
    "id": "MEDIUM-05",
    "title": "Missing skb->dev Assignment in Packet Injection",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** Netfilter bypass for interface-based rules. Security-critical firewall rules that filter based on input interface will not match packets injected through this path.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [
        "skb->dev = NULL;  /* Would be set to virtual interface */"
      ],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** `tquic_connect_ip_inject_packet()` sets `skb->dev = NULL` before calling `netif_rx()`. This means the injected packet has no associated network device, which bypasses netfilter rules that match on input interface (`-i` flag in iptables). It also means conntrack cannot properly track the connection's originating interface.\n\n**Code (connect_ip.c:2064):**\n```c\nskb->dev = NULL;  /* Would be set to virtual interface */\n```",
    "fix_suggestion": "** Set `skb->dev` to the tunnel's virtual network device (`iface->net_device` from the tunnel's interface structure).\n\n---",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_MASQUE_TUNNEL_AUDIT.md"
  },
  {
    "id": "MEDIUM-06",
    "title": "Gaussian Random Approximation Produces Biased Distribution",
    "category": "other",
    "severity": "S2",
    "confidence": "high",
    "impact": "** The jitter distribution is predictable and distinguishable from true Gaussian jitter. An attacker performing traffic analysis can detect the characteristic triangular distribution and partially reconstruct timing patterns.",
    "evidence": {
      "file_paths": [],
      "symbols": [],
      "line_ranges": [],
      "snippets": [],
      "logs_or_errors": []
    },
    "repro": {
      "steps": [],
      "expected": "",
      "actual": ""
    },
    "root_cause_hypothesis": "** The `gaussian_random()` function uses a poor approximation of the Box-Muller transform. Instead of proper Box-Muller (which requires log and trigonometric functions), it sums two uniform random values modulo 1000 and subtracts 1000. This produces a triangular distribution, not Gaussian. The `(u32)max_t(s64, 0, ...)` clamp further truncates the distribution at zero, creating a half-triangular distribution.",
    "fix_suggestion": "** If Gaussian jitter is required, use a proper implementation. For kernel context where floating-point is unavailable, consider using the Ziggurat method with integer arithmetic, or use a larger sum of uniform random variables for better CLT approximation (sum of 12 uniform randoms is a common choice).",
    "tests_to_add": [],
    "dependencies": [],
    "notes": "Source: DEEP_MASQUE_TUNNEL_AUDIT.md"
  }
]
